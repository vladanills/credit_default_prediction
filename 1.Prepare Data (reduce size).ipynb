{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dae138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d08a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = Path(\"../credit_default_prediction/input_data/train_data.csv\")\n",
    "TRAIN_LABELS_CSV = Path(\n",
    "    \"../credit_default_prediction//input_data/train_labels.csv\")\n",
    "TEST_CSV = Path('../credit_default_prediction//input_data/test_data.csv')\n",
    "CHUNKSIZE = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4e51cd",
   "metadata": {},
   "source": [
    "**Описание задачи**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977104e5",
   "metadata": {},
   "source": [
    "American Express — глобальная интегрированная платежная компания. Являясь крупнейшим эмитентом платежных карт в мире, они предоставляют клиентам доступ к продуктам, информации и опыту, которые обогащают жизнь и способствуют успеху в бизнесе.\n",
    "\n",
    "Целью этой задачи является прогнозирование вероятности того, что клиент не выплатит сумму остатка по кредитной карте в будущем, на основе его ежемесячного профиля клиента.\n",
    "\n",
    "Набор данных содержит агрегированные характеристики профиля для каждого клиента на каждую дату выписки. Функции анонимизированы и нормализованы и делятся на следующие общие категории:\n",
    "\n",
    "D_* = переменные просроченной задолженности\n",
    "S_* = Расходные переменные\n",
    "P_* = Платежные переменные\n",
    "B_* = Балансовые переменные\n",
    "R_* = Переменные риска\n",
    "Следующие признаки, являются категоричными:\n",
    "\n",
    "['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "\n",
    "Задача состоит в том, чтобы предсказать для каждого customer_ID вероятность невыполнения платежа в будущем (target = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d123cb3",
   "metadata": {},
   "source": [
    "Весь набор данных весит около 50 ГБ, поэтому просто прочитать их с помощью Pandas не выйдет. И требуется предварительно уменьшить размер данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d1e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_CSV, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9802024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938469</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>1.006838</td>\n",
       "      <td>0.009228</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.008771</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>1.000653</td>\n",
       "      <td>0.006151</td>\n",
       "      <td>0.126750</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009576</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.009217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954180</td>\n",
       "      <td>0.091505</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>1.009672</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>1.002700</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.004516</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947248</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>1.000727</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.117325</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.009827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-03-09  0.938469   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-04-07  0.936665   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-05-28  0.954180   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-06-13  0.960384   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  2017-07-16  0.947248   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.001733  0.008724  1.006838  0.009228  0.124035  0.008771  0.004709  ...   \n",
       "1  0.005775  0.004923  1.000653  0.006151  0.126750  0.000798  0.002714  ...   \n",
       "2  0.091505  0.021655  1.009672  0.006815  0.123977  0.007598  0.009423  ...   \n",
       "3  0.002455  0.013683  1.002700  0.001373  0.117169  0.000685  0.005531  ...   \n",
       "4  0.002483  0.015193  1.000727  0.007605  0.117325  0.004653  0.009312  ...   \n",
       "\n",
       "   D_136  D_137  D_138     D_139     D_140     D_141  D_142     D_143  \\\n",
       "0    NaN    NaN    NaN  0.002427  0.003706  0.003818    NaN  0.000569   \n",
       "1    NaN    NaN    NaN  0.003954  0.003167  0.005032    NaN  0.009576   \n",
       "2    NaN    NaN    NaN  0.003269  0.007329  0.000427    NaN  0.003429   \n",
       "3    NaN    NaN    NaN  0.006117  0.004516  0.003200    NaN  0.008419   \n",
       "4    NaN    NaN    NaN  0.003671  0.004946  0.008889    NaN  0.001670   \n",
       "\n",
       "      D_144     D_145  \n",
       "0  0.000610  0.002674  \n",
       "1  0.005492  0.009217  \n",
       "2  0.006986  0.002603  \n",
       "3  0.006527  0.009600  \n",
       "4  0.008126  0.009827  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b9e2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Columns: 190 entries, customer_ID to D_145\n",
      "dtypes: float64(185), int64(1), object(4)\n",
      "memory usage: 15.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7a76e",
   "metadata": {},
   "source": [
    "При предварительном осмотре данных видно:\n",
    "- customer_ID хранится в виде кэша и занимает много места\n",
    "- числовые данные с типом float64(185) можно уменьшить заменим на float32\n",
    "- S2 - это дата, требует преобразования в соответствующий тип\n",
    "- а также можно перевести категориальные данные, которые нам известны из описания датасета, в тип category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44792c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_vars = df.select_dtypes('float64').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d5ae5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117',\n",
    "                'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "694da4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepair(input_path, output_path, chunksize=CHUNKSIZE):\n",
    "    \"\"\"\n",
    "    Уменьшение размера датасета за счёт смены типа данных с 64 бит на 32,\n",
    "    конвертации в parquet и других преобразований\n",
    "    params:\n",
    "    - input_path: str\n",
    "    - output_path: str\n",
    "    - chunksize: integer\n",
    "    return: None\n",
    "    \"\"\"\n",
    "\n",
    "    pq_writer = None\n",
    "\n",
    "    for idx, chunk in enumerate(pd.read_csv(input_path, chunksize=chunksize)):\n",
    "        print(f\"id: {idx} Chunk size {chunk.shape}\")\n",
    "\n",
    "        chunk[float_vars] = chunk[float_vars].astype('float32')\n",
    "\n",
    "        chunk['customer_ID'] = chunk['customer_ID'].str[-16:].apply(\n",
    "            int, base=16).astype('int64')\n",
    "\n",
    "        chunk[cat_features] = chunk[cat_features].astype('category')\n",
    "\n",
    "        chunk['S_2'] = pd.to_datetime(chunk['S_2'])\n",
    "\n",
    "        table = pa.Table.from_pandas(chunk)\n",
    "        if idx == 0:\n",
    "            pq_writer = pq.ParquetWriter(\n",
    "                output_path, table.schema, compression='snappy')\n",
    "\n",
    "        pq_writer.write_table(table)\n",
    "\n",
    "        del chunk\n",
    "        del table\n",
    "        gc.collect()\n",
    "\n",
    "    if pq_writer:\n",
    "        pq_writer.close()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eff5aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0 Chunk size (15000, 190)\n",
      "id: 1 Chunk size (15000, 190)\n",
      "id: 2 Chunk size (15000, 190)\n",
      "id: 3 Chunk size (15000, 190)\n",
      "id: 4 Chunk size (15000, 190)\n",
      "id: 5 Chunk size (15000, 190)\n",
      "id: 6 Chunk size (15000, 190)\n",
      "id: 7 Chunk size (15000, 190)\n",
      "id: 8 Chunk size (15000, 190)\n",
      "id: 9 Chunk size (15000, 190)\n",
      "id: 10 Chunk size (15000, 190)\n",
      "id: 11 Chunk size (15000, 190)\n",
      "id: 12 Chunk size (15000, 190)\n",
      "id: 13 Chunk size (15000, 190)\n",
      "id: 14 Chunk size (15000, 190)\n",
      "id: 15 Chunk size (15000, 190)\n",
      "id: 16 Chunk size (15000, 190)\n",
      "id: 17 Chunk size (15000, 190)\n",
      "id: 18 Chunk size (15000, 190)\n",
      "id: 19 Chunk size (15000, 190)\n",
      "id: 20 Chunk size (15000, 190)\n",
      "id: 21 Chunk size (15000, 190)\n",
      "id: 22 Chunk size (15000, 190)\n",
      "id: 23 Chunk size (15000, 190)\n",
      "id: 24 Chunk size (15000, 190)\n",
      "id: 25 Chunk size (15000, 190)\n",
      "id: 26 Chunk size (15000, 190)\n",
      "id: 27 Chunk size (15000, 190)\n",
      "id: 28 Chunk size (15000, 190)\n",
      "id: 29 Chunk size (15000, 190)\n",
      "id: 30 Chunk size (15000, 190)\n",
      "id: 31 Chunk size (15000, 190)\n",
      "id: 32 Chunk size (15000, 190)\n",
      "id: 33 Chunk size (15000, 190)\n",
      "id: 34 Chunk size (15000, 190)\n",
      "id: 35 Chunk size (15000, 190)\n",
      "id: 36 Chunk size (15000, 190)\n",
      "id: 37 Chunk size (15000, 190)\n",
      "id: 38 Chunk size (15000, 190)\n",
      "id: 39 Chunk size (15000, 190)\n",
      "id: 40 Chunk size (15000, 190)\n",
      "id: 41 Chunk size (15000, 190)\n",
      "id: 42 Chunk size (15000, 190)\n",
      "id: 43 Chunk size (15000, 190)\n",
      "id: 44 Chunk size (15000, 190)\n",
      "id: 45 Chunk size (15000, 190)\n",
      "id: 46 Chunk size (15000, 190)\n",
      "id: 47 Chunk size (15000, 190)\n",
      "id: 48 Chunk size (15000, 190)\n",
      "id: 49 Chunk size (15000, 190)\n",
      "id: 50 Chunk size (15000, 190)\n",
      "id: 51 Chunk size (15000, 190)\n",
      "id: 52 Chunk size (15000, 190)\n",
      "id: 53 Chunk size (15000, 190)\n",
      "id: 54 Chunk size (15000, 190)\n",
      "id: 55 Chunk size (15000, 190)\n",
      "id: 56 Chunk size (15000, 190)\n",
      "id: 57 Chunk size (15000, 190)\n",
      "id: 58 Chunk size (15000, 190)\n",
      "id: 59 Chunk size (15000, 190)\n",
      "id: 60 Chunk size (15000, 190)\n",
      "id: 61 Chunk size (15000, 190)\n",
      "id: 62 Chunk size (15000, 190)\n",
      "id: 63 Chunk size (15000, 190)\n",
      "id: 64 Chunk size (15000, 190)\n",
      "id: 65 Chunk size (15000, 190)\n",
      "id: 66 Chunk size (15000, 190)\n",
      "id: 67 Chunk size (15000, 190)\n",
      "id: 68 Chunk size (15000, 190)\n",
      "id: 69 Chunk size (15000, 190)\n",
      "id: 70 Chunk size (15000, 190)\n",
      "id: 71 Chunk size (15000, 190)\n",
      "id: 72 Chunk size (15000, 190)\n",
      "id: 73 Chunk size (15000, 190)\n",
      "id: 74 Chunk size (15000, 190)\n",
      "id: 75 Chunk size (15000, 190)\n",
      "id: 76 Chunk size (15000, 190)\n",
      "id: 77 Chunk size (15000, 190)\n",
      "id: 78 Chunk size (15000, 190)\n",
      "id: 79 Chunk size (15000, 190)\n",
      "id: 80 Chunk size (15000, 190)\n",
      "id: 81 Chunk size (15000, 190)\n",
      "id: 82 Chunk size (15000, 190)\n",
      "id: 83 Chunk size (15000, 190)\n",
      "id: 84 Chunk size (15000, 190)\n",
      "id: 85 Chunk size (15000, 190)\n",
      "id: 86 Chunk size (15000, 190)\n",
      "id: 87 Chunk size (15000, 190)\n",
      "id: 88 Chunk size (15000, 190)\n",
      "id: 89 Chunk size (15000, 190)\n",
      "id: 90 Chunk size (15000, 190)\n",
      "id: 91 Chunk size (15000, 190)\n",
      "id: 92 Chunk size (15000, 190)\n",
      "id: 93 Chunk size (15000, 190)\n",
      "id: 94 Chunk size (15000, 190)\n",
      "id: 95 Chunk size (15000, 190)\n",
      "id: 96 Chunk size (15000, 190)\n",
      "id: 97 Chunk size (15000, 190)\n",
      "id: 98 Chunk size (15000, 190)\n",
      "id: 99 Chunk size (15000, 190)\n",
      "id: 100 Chunk size (15000, 190)\n",
      "id: 101 Chunk size (15000, 190)\n",
      "id: 102 Chunk size (15000, 190)\n",
      "id: 103 Chunk size (15000, 190)\n",
      "id: 104 Chunk size (15000, 190)\n",
      "id: 105 Chunk size (15000, 190)\n",
      "id: 106 Chunk size (15000, 190)\n",
      "id: 107 Chunk size (15000, 190)\n",
      "id: 108 Chunk size (15000, 190)\n",
      "id: 109 Chunk size (15000, 190)\n",
      "id: 110 Chunk size (15000, 190)\n",
      "id: 111 Chunk size (15000, 190)\n",
      "id: 112 Chunk size (15000, 190)\n",
      "id: 113 Chunk size (15000, 190)\n",
      "id: 114 Chunk size (15000, 190)\n",
      "id: 115 Chunk size (15000, 190)\n",
      "id: 116 Chunk size (15000, 190)\n",
      "id: 117 Chunk size (15000, 190)\n",
      "id: 118 Chunk size (15000, 190)\n",
      "id: 119 Chunk size (15000, 190)\n",
      "id: 120 Chunk size (15000, 190)\n",
      "id: 121 Chunk size (15000, 190)\n",
      "id: 122 Chunk size (15000, 190)\n",
      "id: 123 Chunk size (15000, 190)\n",
      "id: 124 Chunk size (15000, 190)\n",
      "id: 125 Chunk size (15000, 190)\n",
      "id: 126 Chunk size (15000, 190)\n",
      "id: 127 Chunk size (15000, 190)\n",
      "id: 128 Chunk size (15000, 190)\n",
      "id: 129 Chunk size (15000, 190)\n",
      "id: 130 Chunk size (15000, 190)\n",
      "id: 131 Chunk size (15000, 190)\n",
      "id: 132 Chunk size (15000, 190)\n",
      "id: 133 Chunk size (15000, 190)\n",
      "id: 134 Chunk size (15000, 190)\n",
      "id: 135 Chunk size (15000, 190)\n",
      "id: 136 Chunk size (15000, 190)\n",
      "id: 137 Chunk size (15000, 190)\n",
      "id: 138 Chunk size (15000, 190)\n",
      "id: 139 Chunk size (15000, 190)\n",
      "id: 140 Chunk size (15000, 190)\n",
      "id: 141 Chunk size (15000, 190)\n",
      "id: 142 Chunk size (15000, 190)\n",
      "id: 143 Chunk size (15000, 190)\n",
      "id: 144 Chunk size (15000, 190)\n",
      "id: 145 Chunk size (15000, 190)\n",
      "id: 146 Chunk size (15000, 190)\n",
      "id: 147 Chunk size (15000, 190)\n",
      "id: 148 Chunk size (15000, 190)\n",
      "id: 149 Chunk size (15000, 190)\n",
      "id: 150 Chunk size (15000, 190)\n",
      "id: 151 Chunk size (15000, 190)\n",
      "id: 152 Chunk size (15000, 190)\n",
      "id: 153 Chunk size (15000, 190)\n",
      "id: 154 Chunk size (15000, 190)\n",
      "id: 155 Chunk size (15000, 190)\n",
      "id: 156 Chunk size (15000, 190)\n",
      "id: 157 Chunk size (15000, 190)\n",
      "id: 158 Chunk size (15000, 190)\n",
      "id: 159 Chunk size (15000, 190)\n",
      "id: 160 Chunk size (15000, 190)\n",
      "id: 161 Chunk size (15000, 190)\n",
      "id: 162 Chunk size (15000, 190)\n",
      "id: 163 Chunk size (15000, 190)\n",
      "id: 164 Chunk size (15000, 190)\n",
      "id: 165 Chunk size (15000, 190)\n",
      "id: 166 Chunk size (15000, 190)\n",
      "id: 167 Chunk size (15000, 190)\n",
      "id: 168 Chunk size (15000, 190)\n",
      "id: 169 Chunk size (15000, 190)\n",
      "id: 170 Chunk size (15000, 190)\n",
      "id: 171 Chunk size (15000, 190)\n",
      "id: 172 Chunk size (15000, 190)\n",
      "id: 173 Chunk size (15000, 190)\n",
      "id: 174 Chunk size (15000, 190)\n",
      "id: 175 Chunk size (15000, 190)\n",
      "id: 176 Chunk size (15000, 190)\n",
      "id: 177 Chunk size (15000, 190)\n",
      "id: 178 Chunk size (15000, 190)\n",
      "id: 179 Chunk size (15000, 190)\n",
      "id: 180 Chunk size (15000, 190)\n",
      "id: 181 Chunk size (15000, 190)\n",
      "id: 182 Chunk size (15000, 190)\n",
      "id: 183 Chunk size (15000, 190)\n",
      "id: 184 Chunk size (15000, 190)\n",
      "id: 185 Chunk size (15000, 190)\n",
      "id: 186 Chunk size (15000, 190)\n",
      "id: 187 Chunk size (15000, 190)\n",
      "id: 188 Chunk size (15000, 190)\n",
      "id: 189 Chunk size (15000, 190)\n",
      "id: 190 Chunk size (15000, 190)\n",
      "id: 191 Chunk size (15000, 190)\n",
      "id: 192 Chunk size (15000, 190)\n",
      "id: 193 Chunk size (15000, 190)\n",
      "id: 194 Chunk size (15000, 190)\n",
      "id: 195 Chunk size (15000, 190)\n",
      "id: 196 Chunk size (15000, 190)\n",
      "id: 197 Chunk size (15000, 190)\n",
      "id: 198 Chunk size (15000, 190)\n",
      "id: 199 Chunk size (15000, 190)\n",
      "id: 200 Chunk size (15000, 190)\n",
      "id: 201 Chunk size (15000, 190)\n",
      "id: 202 Chunk size (15000, 190)\n",
      "id: 203 Chunk size (15000, 190)\n",
      "id: 204 Chunk size (15000, 190)\n",
      "id: 205 Chunk size (15000, 190)\n",
      "id: 206 Chunk size (15000, 190)\n",
      "id: 207 Chunk size (15000, 190)\n",
      "id: 208 Chunk size (15000, 190)\n",
      "id: 209 Chunk size (15000, 190)\n",
      "id: 210 Chunk size (15000, 190)\n",
      "id: 211 Chunk size (15000, 190)\n",
      "id: 212 Chunk size (15000, 190)\n",
      "id: 213 Chunk size (15000, 190)\n",
      "id: 214 Chunk size (15000, 190)\n",
      "id: 215 Chunk size (15000, 190)\n",
      "id: 216 Chunk size (15000, 190)\n",
      "id: 217 Chunk size (15000, 190)\n",
      "id: 218 Chunk size (15000, 190)\n",
      "id: 219 Chunk size (15000, 190)\n",
      "id: 220 Chunk size (15000, 190)\n",
      "id: 221 Chunk size (15000, 190)\n",
      "id: 222 Chunk size (15000, 190)\n",
      "id: 223 Chunk size (15000, 190)\n",
      "id: 224 Chunk size (15000, 190)\n",
      "id: 225 Chunk size (15000, 190)\n",
      "id: 226 Chunk size (15000, 190)\n",
      "id: 227 Chunk size (15000, 190)\n",
      "id: 228 Chunk size (15000, 190)\n",
      "id: 229 Chunk size (15000, 190)\n",
      "id: 230 Chunk size (15000, 190)\n",
      "id: 231 Chunk size (15000, 190)\n",
      "id: 232 Chunk size (15000, 190)\n",
      "id: 233 Chunk size (15000, 190)\n",
      "id: 234 Chunk size (15000, 190)\n",
      "id: 235 Chunk size (15000, 190)\n",
      "id: 236 Chunk size (15000, 190)\n",
      "id: 237 Chunk size (15000, 190)\n",
      "id: 238 Chunk size (15000, 190)\n",
      "id: 239 Chunk size (15000, 190)\n",
      "id: 240 Chunk size (15000, 190)\n",
      "id: 241 Chunk size (15000, 190)\n",
      "id: 242 Chunk size (15000, 190)\n",
      "id: 243 Chunk size (15000, 190)\n",
      "id: 244 Chunk size (15000, 190)\n",
      "id: 245 Chunk size (15000, 190)\n",
      "id: 246 Chunk size (15000, 190)\n",
      "id: 247 Chunk size (15000, 190)\n",
      "id: 248 Chunk size (15000, 190)\n",
      "id: 249 Chunk size (15000, 190)\n",
      "id: 250 Chunk size (15000, 190)\n",
      "id: 251 Chunk size (15000, 190)\n",
      "id: 252 Chunk size (15000, 190)\n",
      "id: 253 Chunk size (15000, 190)\n",
      "id: 254 Chunk size (15000, 190)\n",
      "id: 255 Chunk size (15000, 190)\n",
      "id: 256 Chunk size (15000, 190)\n",
      "id: 257 Chunk size (15000, 190)\n",
      "id: 258 Chunk size (15000, 190)\n",
      "id: 259 Chunk size (15000, 190)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 260 Chunk size (15000, 190)\n",
      "id: 261 Chunk size (15000, 190)\n",
      "id: 262 Chunk size (15000, 190)\n",
      "id: 263 Chunk size (15000, 190)\n",
      "id: 264 Chunk size (15000, 190)\n",
      "id: 265 Chunk size (15000, 190)\n",
      "id: 266 Chunk size (15000, 190)\n",
      "id: 267 Chunk size (15000, 190)\n",
      "id: 268 Chunk size (15000, 190)\n",
      "id: 269 Chunk size (15000, 190)\n",
      "id: 270 Chunk size (15000, 190)\n",
      "id: 271 Chunk size (15000, 190)\n",
      "id: 272 Chunk size (15000, 190)\n",
      "id: 273 Chunk size (15000, 190)\n",
      "id: 274 Chunk size (15000, 190)\n",
      "id: 275 Chunk size (15000, 190)\n",
      "id: 276 Chunk size (15000, 190)\n",
      "id: 277 Chunk size (15000, 190)\n",
      "id: 278 Chunk size (15000, 190)\n",
      "id: 279 Chunk size (15000, 190)\n",
      "id: 280 Chunk size (15000, 190)\n",
      "id: 281 Chunk size (15000, 190)\n",
      "id: 282 Chunk size (15000, 190)\n",
      "id: 283 Chunk size (15000, 190)\n",
      "id: 284 Chunk size (15000, 190)\n",
      "id: 285 Chunk size (15000, 190)\n",
      "id: 286 Chunk size (15000, 190)\n",
      "id: 287 Chunk size (15000, 190)\n",
      "id: 288 Chunk size (15000, 190)\n",
      "id: 289 Chunk size (15000, 190)\n",
      "id: 290 Chunk size (15000, 190)\n",
      "id: 291 Chunk size (15000, 190)\n",
      "id: 292 Chunk size (15000, 190)\n",
      "id: 293 Chunk size (15000, 190)\n",
      "id: 294 Chunk size (15000, 190)\n",
      "id: 295 Chunk size (15000, 190)\n",
      "id: 296 Chunk size (15000, 190)\n",
      "id: 297 Chunk size (15000, 190)\n",
      "id: 298 Chunk size (15000, 190)\n",
      "id: 299 Chunk size (15000, 190)\n",
      "id: 300 Chunk size (15000, 190)\n",
      "id: 301 Chunk size (15000, 190)\n",
      "id: 302 Chunk size (15000, 190)\n",
      "id: 303 Chunk size (15000, 190)\n",
      "id: 304 Chunk size (15000, 190)\n",
      "id: 305 Chunk size (15000, 190)\n",
      "id: 306 Chunk size (15000, 190)\n",
      "id: 307 Chunk size (15000, 190)\n",
      "id: 308 Chunk size (15000, 190)\n",
      "id: 309 Chunk size (15000, 190)\n",
      "id: 310 Chunk size (15000, 190)\n",
      "id: 311 Chunk size (15000, 190)\n",
      "id: 312 Chunk size (15000, 190)\n",
      "id: 313 Chunk size (15000, 190)\n",
      "id: 314 Chunk size (15000, 190)\n",
      "id: 315 Chunk size (15000, 190)\n",
      "id: 316 Chunk size (15000, 190)\n",
      "id: 317 Chunk size (15000, 190)\n",
      "id: 318 Chunk size (15000, 190)\n",
      "id: 319 Chunk size (15000, 190)\n",
      "id: 320 Chunk size (15000, 190)\n",
      "id: 321 Chunk size (15000, 190)\n",
      "id: 322 Chunk size (15000, 190)\n",
      "id: 323 Chunk size (15000, 190)\n",
      "id: 324 Chunk size (15000, 190)\n",
      "id: 325 Chunk size (15000, 190)\n",
      "id: 326 Chunk size (15000, 190)\n",
      "id: 327 Chunk size (15000, 190)\n",
      "id: 328 Chunk size (15000, 190)\n",
      "id: 329 Chunk size (15000, 190)\n",
      "id: 330 Chunk size (15000, 190)\n",
      "id: 331 Chunk size (15000, 190)\n",
      "id: 332 Chunk size (15000, 190)\n",
      "id: 333 Chunk size (15000, 190)\n",
      "id: 334 Chunk size (15000, 190)\n",
      "id: 335 Chunk size (15000, 190)\n",
      "id: 336 Chunk size (15000, 190)\n",
      "id: 337 Chunk size (15000, 190)\n",
      "id: 338 Chunk size (15000, 190)\n",
      "id: 339 Chunk size (15000, 190)\n",
      "id: 340 Chunk size (15000, 190)\n",
      "id: 341 Chunk size (15000, 190)\n",
      "id: 342 Chunk size (15000, 190)\n",
      "id: 343 Chunk size (15000, 190)\n",
      "id: 344 Chunk size (15000, 190)\n",
      "id: 345 Chunk size (15000, 190)\n",
      "id: 346 Chunk size (15000, 190)\n",
      "id: 347 Chunk size (15000, 190)\n",
      "id: 348 Chunk size (15000, 190)\n",
      "id: 349 Chunk size (15000, 190)\n",
      "id: 350 Chunk size (15000, 190)\n",
      "id: 351 Chunk size (15000, 190)\n",
      "id: 352 Chunk size (15000, 190)\n",
      "id: 353 Chunk size (15000, 190)\n",
      "id: 354 Chunk size (15000, 190)\n",
      "id: 355 Chunk size (15000, 190)\n",
      "id: 356 Chunk size (15000, 190)\n",
      "id: 357 Chunk size (15000, 190)\n",
      "id: 358 Chunk size (15000, 190)\n",
      "id: 359 Chunk size (15000, 190)\n",
      "id: 360 Chunk size (15000, 190)\n",
      "id: 361 Chunk size (15000, 190)\n",
      "id: 362 Chunk size (15000, 190)\n",
      "id: 363 Chunk size (15000, 190)\n",
      "id: 364 Chunk size (15000, 190)\n",
      "id: 365 Chunk size (15000, 190)\n",
      "id: 366 Chunk size (15000, 190)\n",
      "id: 367 Chunk size (15000, 190)\n",
      "id: 368 Chunk size (11451, 190)\n"
     ]
    }
   ],
   "source": [
    "prepair(input_path=TRAIN_CSV, output_path='./train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15103eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepair(input_path=TEST_CSV, output_path='./test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cde2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(TRAIN_LABELS_CSV)\n",
    "train_labels['customer_ID'] = train_labels['customer_ID'].str[-16:].apply(\n",
    "    int, base=16).astype('int64')\n",
    "train_labels.to_parquet('./train_labels.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
