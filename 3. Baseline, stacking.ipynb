{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a73eb9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import optuna\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n",
    "    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n",
    "    precision_recall_curve, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "208f95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FOLDS = 5\n",
    "RAND = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "805510cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test: np.ndarray, y_pred: np.ndarray, y_score: np.ndarray, name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Вывод метрик классификации\n",
    "    \"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "\n",
    "    df_metrics['Accuracy'] = [accuracy_score(y_test, y_pred)]\n",
    "    df_metrics['ROC_AUC'] = [roc_auc_score(y_test, y_score[:, 1])]\n",
    "    df_metrics['Precision'] = [precision_score(y_test, y_pred)]\n",
    "    df_metrics['Recall'] = [recall_score(y_test, y_pred)]\n",
    "    df_metrics['f1'] = [f1_score(y_test, y_pred)]\n",
    "    df_metrics['Logloss'] = [log_loss(y_test, y_score)]\n",
    "    df_metrics['amex'] = [amex_metric(y_test, y_score[:, 1])]\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a588ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Вычисление метрики соревнования\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(y_true, np.ndarray):\n",
    "        y_true = pd.DataFrame(y_true, columns=[\"target\"])\n",
    "\n",
    "    if isinstance(y_pred, np.ndarray):\n",
    "        y_pred = pd.DataFrame(y_pred, columns=[\"prediction\"])\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "\n",
    "        df['weight'] = df[\"target\"].apply(lambda x: 20 if x == 0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df[\"target\"] == 1).sum()\n",
    "\n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df[\"target\"].apply(lambda x: 20 if x == 0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df[\"target\"] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df[\"target\"] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31238086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_xg_amex_metric(y_pred: np.ndarray, dtrain):\n",
    "    \"\"\"\n",
    "    eval metric для xgboost\n",
    "    \"\"\"\n",
    "    y_true = dtrain.get_label()\n",
    "    score = amex_metric(y_true, y_pred)\n",
    "    return 'amex', -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "521f9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_lg_amex_metric(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    eval metric для lgbm\n",
    "    \"\"\"\n",
    "    score = amex_metric(y_true, y_pred)\n",
    "    return 'custom_lg_amex_metric', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e60a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatBoostEvalMetricCustom(object):\n",
    "    \"\"\"\n",
    "    eval metric для catbost\n",
    "    \"\"\"\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        # the larger metric value the better\n",
    "        return True\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "        preds = np.array(approxes[0])\n",
    "        target = np.array(target)\n",
    "        score = amex_metric(target, preds)\n",
    "        return score, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76b9a5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_overfitting(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Проверка на overfitting\n",
    "    \"\"\"\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_score_train = model.predict_proba(X_train)\n",
    "    y_score_test = model.predict_proba(X_test)\n",
    "\n",
    "    print(f'f1 train: %.3f' % f1_score(y_train, y_pred_train))\n",
    "    print(f'f1 test: %.3f' % f1_score(y_test, y_pred_test))\n",
    "\n",
    "    print(f'roc-auc train: %.3f' % roc_auc_score(y_train, y_score_train[:, 1]))\n",
    "    print(f'roc-auc test: %.3f' % roc_auc_score(y_test, y_score_test[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "928f82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bin = pd.read_parquet('train_bin_3.parquet')\n",
    "train_data_grouped = pd.read_parquet('train_data_grouped_3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76abc11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bin.fillna(method=\"ffill\", inplace=True)\n",
    "train_bin.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40735a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_grouped.fillna(method=\"ffill\", inplace=True)\n",
    "train_data_grouped.fillna(method=\"bfill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23ca6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# бинаризованные данные\n",
    "X_bin = train_bin.drop(columns='target')\n",
    "y = train_bin['target']\n",
    "X_train_bin, X_test_bin, y_train, y_test = train_test_split(\n",
    "    X_bin, y,\n",
    "    stratify=y,\n",
    "    shuffle=True,\n",
    "    test_size=0.25,\n",
    "    random_state=RAND)\n",
    "X_train_bin_, X_val_bin, y_train_, y_val = train_test_split(X_train_bin,\n",
    "                                                            y_train,\n",
    "                                                            shuffle=True,\n",
    "                                                            test_size=0.16,\n",
    "                                                            random_state=RAND)\n",
    "\n",
    "\n",
    "# без бинаризации\n",
    "X = train_data_grouped.drop(columns='target')\n",
    "X_train = X.loc[X_train_bin.index]\n",
    "X_test = X.loc[X_test_bin.index]\n",
    "X_train_ = X_train.loc[X_train_bin_.index]\n",
    "X_val = X_train.loc[X_val_bin.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fa7726",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d9cab3",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9bf6383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.95423</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.79935</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy  ROC_AUC  Precision    Recall  \\\n",
       "0  LogisticRegression_Baseline  0.883787  0.95423   0.722824  0.893998   \n",
       "\n",
       "        f1   Logloss      amex  \n",
       "0  0.79935  0.282031  0.764476  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', random_state=RAND)\n",
    "lr.fit(X_train_bin, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_bin)\n",
    "y_score = lr.predict_proba(X_test_bin)\n",
    "\n",
    "metrics = get_metrics(y_test.values, y_pred,\n",
    "                      y_score, name='LogisticRegression_Baseline')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c627dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.797\n",
      "f1 test: 0.799\n",
      "roc-auc train: 0.954\n",
      "roc-auc test: 0.954\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(lr, X_train_bin, y_train, X_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765635f",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e91f3f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>0.892451</td>\n",
       "      <td>0.953522</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.264326</td>\n",
       "      <td>0.757461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0  LogisticRegression_Baseline  0.883787  0.954230   0.722824  0.893998   \n",
       "0        RandomForest_Baseline  0.892451  0.953522   0.816657  0.753896   \n",
       "\n",
       "         f1   Logloss      amex  \n",
       "0  0.799350  0.282031  0.764476  \n",
       "0  0.784023  0.264326  0.757461  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    random_state=RAND, class_weight='balanced', n_jobs=-1)\n",
    "rf.fit(X_train_bin, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test_bin)\n",
    "y_score = rf.predict_proba(X_test_bin)\n",
    "\n",
    "metrics = metrics.append(get_metrics(y_test.values, y_pred,\n",
    "                                     y_score, name='RandomForest_Baseline'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f470942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 1.000\n",
      "f1 test: 0.784\n",
      "roc-auc train: 1.000\n",
      "roc-auc test: 0.954\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(rf, X_train_bin, y_train, X_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a520530",
   "metadata": {},
   "source": [
    "По метрикам можно заметить явное переобучение у Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c926898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0120\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                P_2_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0032\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                P_2_min\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0023\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                P_2_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.36%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0020\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_9_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.66%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_1_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.66%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0014\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                P_2_max\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0013\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                D_44_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0012\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_2_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_7_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.08%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                R_1_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_3_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.62%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                R_3_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0004\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                R_1_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                D_48_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                D_45_max\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0001\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_10_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_4_diff\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.51%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_2_min\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.57%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_2_mean\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0003\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                B_4_last\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 98.58%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 230 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = PermutationImportance(rf, random_state=RAND, n_iter=2)\n",
    "perm.fit(X_train_bin, y_train)\n",
    "eli5.show_weights(perm, feature_names=X_train_bin.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63472ec",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46387ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = float(np.sum(\n",
    "    train_bin['target'] == 0)) / np.sum(train_bin['target'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7690f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:40:19] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>0.892451</td>\n",
       "      <td>0.953522</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.264326</td>\n",
       "      <td>0.757461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_Baseline</td>\n",
       "      <td>0.884022</td>\n",
       "      <td>0.957920</td>\n",
       "      <td>0.717815</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>0.776851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0  LogisticRegression_Baseline  0.883787  0.954230   0.722824  0.893998   \n",
       "0        RandomForest_Baseline  0.892451  0.953522   0.816657  0.753896   \n",
       "0             XGBoost_Baseline  0.884022  0.957920   0.717815  0.909718   \n",
       "\n",
       "         f1   Logloss      amex  \n",
       "0  0.799350  0.282031  0.764476  \n",
       "0  0.784023  0.264326  0.757461  \n",
       "0  0.802453  0.260512  0.776851  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = XGBClassifier(scale_pos_weight=ratio, random_state=RAND)\n",
    "eval_set = [(X_val_bin, y_val)]\n",
    "xg.fit(X_train_bin_, y_train_,\n",
    "       eval_set=eval_set,\n",
    "       verbose=False,\n",
    "       eval_metric=custom_xg_amex_metric,\n",
    "       early_stopping_rounds=100)\n",
    "\n",
    "y_pred = xg.predict(X_test_bin)\n",
    "y_score = xg.predict_proba(X_test_bin)\n",
    "\n",
    "metrics = metrics.append(get_metrics(y_test.values, y_pred,\n",
    "                                     y_score, name='XGBoost_Baseline'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77a1d9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.821\n",
      "f1 test: 0.802\n",
      "roc-auc train: 0.968\n",
      "roc-auc test: 0.958\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(xg, X_train_bin, y_train, X_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03a881",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa5ec09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [(X_val, y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96daf889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>0.892451</td>\n",
       "      <td>0.953522</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.264326</td>\n",
       "      <td>0.757461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_Baseline</td>\n",
       "      <td>0.884022</td>\n",
       "      <td>0.957920</td>\n",
       "      <td>0.717815</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>0.776851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM_Baseline</td>\n",
       "      <td>0.881181</td>\n",
       "      <td>0.959101</td>\n",
       "      <td>0.708026</td>\n",
       "      <td>0.920860</td>\n",
       "      <td>0.800538</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.783520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0  LogisticRegression_Baseline  0.883787  0.954230   0.722824  0.893998   \n",
       "0        RandomForest_Baseline  0.892451  0.953522   0.816657  0.753896   \n",
       "0             XGBoost_Baseline  0.884022  0.957920   0.717815  0.909718   \n",
       "0                LGBM_Baseline  0.881181  0.959101   0.708026  0.920860   \n",
       "\n",
       "         f1   Logloss      amex  \n",
       "0  0.799350  0.282031  0.764476  \n",
       "0  0.784023  0.264326  0.757461  \n",
       "0  0.802453  0.260512  0.776851  \n",
       "0  0.800538  0.261274  0.783520  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LGBMClassifier(scale_pos_weight=ratio, random_state=RAND)\n",
    "lg.fit(X_train_, y_train_,\n",
    "       eval_set=eval_set,\n",
    "       verbose=False,\n",
    "       eval_metric=custom_lg_amex_metric,\n",
    "       early_stopping_rounds=100)\n",
    "\n",
    "y_pred = lg.predict(X_test)\n",
    "y_score = lg.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(get_metrics(y_test.values, y_pred,\n",
    "                                     y_score, name='LGBM_Baseline'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b19c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.805\n",
      "f1 test: 0.801\n",
      "roc-auc train: 0.963\n",
      "roc-auc test: 0.959\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(lg, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac7ad4",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ea4a7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feat = X_train.select_dtypes('category').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eee8b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>0.892451</td>\n",
       "      <td>0.953522</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.264326</td>\n",
       "      <td>0.757461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_Baseline</td>\n",
       "      <td>0.884022</td>\n",
       "      <td>0.957920</td>\n",
       "      <td>0.717815</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>0.776851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM_Baseline</td>\n",
       "      <td>0.881181</td>\n",
       "      <td>0.959101</td>\n",
       "      <td>0.708026</td>\n",
       "      <td>0.920860</td>\n",
       "      <td>0.800538</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.783520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_Baseline</td>\n",
       "      <td>0.887884</td>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.725380</td>\n",
       "      <td>0.912445</td>\n",
       "      <td>0.808230</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0  LogisticRegression_Baseline  0.883787  0.954230   0.722824  0.893998   \n",
       "0        RandomForest_Baseline  0.892451  0.953522   0.816657  0.753896   \n",
       "0             XGBoost_Baseline  0.884022  0.957920   0.717815  0.909718   \n",
       "0                LGBM_Baseline  0.881181  0.959101   0.708026  0.920860   \n",
       "0            CatBoost_Baseline  0.887884  0.959946   0.725380  0.912445   \n",
       "\n",
       "         f1   Logloss      amex  \n",
       "0  0.799350  0.282031  0.764476  \n",
       "0  0.784023  0.264326  0.757461  \n",
       "0  0.802453  0.260512  0.776851  \n",
       "0  0.800538  0.261274  0.783520  \n",
       "0  0.808230  0.253600  0.784212  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = CatBoostClassifier(random_state=RAND,\n",
    "                         scale_pos_weight=ratio,\n",
    "                         eval_metric=CatBoostEvalMetricCustom(),\n",
    "                         cat_features=cat_feat)\n",
    "cat.fit(X_train_, y_train_,\n",
    "        eval_set=eval_set,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=100)\n",
    "\n",
    "y_pred = cat.predict(X_test)\n",
    "y_score = cat.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(get_metrics(y_test.values, y_pred,\n",
    "                                     y_score, name='CatBoost_Baseline'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cda676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.829\n",
      "f1 test: 0.808\n",
      "roc-auc train: 0.970\n",
      "roc-auc test: 0.960\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(cat, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606a303",
   "metadata": {},
   "source": [
    "### Подбор параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e7858",
   "metadata": {},
   "source": [
    "После получения бейзлайна было принято решение подобрать параметры для Catboost и LGBM, а затем сделать ручной стекинг моделей catboost, lgbm c финальной моделью logistic regression. \n",
    "\n",
    "Подбор параметров осуществлялся с помощью библиотеки Optuna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899b231",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5889146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 6000, step=500),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical(\"scale_pos_weight\", [2.7971]),\n",
    "        \"eval_metric\": CatBoostEvalMetricCustom(),\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_data,\n",
    "                  eval_set=eval_data,\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0)\n",
    "\n",
    "        preds = model.predict_proba(X_test.values)\n",
    "        cv_predicts[idx] = amex_metric(y_test.values, preds[:, 1])\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f9a1706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-03 15:51:11,443]\u001b[0m A new study created in memory with name: CAT\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c33abd940f4f7f9610eb0cdec9ccb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-03 16:22:21,107]\u001b[0m Trial 0 finished with value: 0.7860718073265622 and parameters: {'n_estimators': 1500, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7860718073265622.\u001b[0m\n",
      "\u001b[32m[I 2022-09-03 17:01:06,704]\u001b[0m Trial 1 finished with value: 0.7857187833739177 and parameters: {'n_estimators': 6000, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7860718073265622.\u001b[0m\n",
      "\u001b[32m[I 2022-09-03 17:32:42,856]\u001b[0m Trial 2 finished with value: 0.7860718073265622 and parameters: {'n_estimators': 1500, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7860718073265622.\u001b[0m\n",
      "\u001b[32m[I 2022-09-03 18:16:31,229]\u001b[0m Trial 3 finished with value: 0.785470297957661 and parameters: {'n_estimators': 5000, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7860718073265622.\u001b[0m\n",
      "\u001b[32m[I 2022-09-03 18:55:35,692]\u001b[0m Trial 4 finished with value: 0.7858459120487378 and parameters: {'n_estimators': 5500, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7860718073265622.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"CAT\")\n",
    "\n",
    "\n",
    "def func(trial): return objective_cat(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND, cat_feat=cat_feat)\n",
    "\n",
    "\n",
    "study_cat.optimize(func, n_trials=5, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb6aecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (amex): 0.78607\n",
      "\tBest params:\n",
      "\t\tn_estimators: 1500\n",
      "\t\tscale_pos_weight: 2.7971\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value (amex): {study_cat.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_cat.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3efc153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial, X, y, N_FOLDS, random_state, cat_feat):\n",
    "    params = {\n",
    "        \"n_estimators\":\n",
    "        trial.suggest_categorical(\"n_estimators\", [1500]),\n",
    "        \"learning_rate\":\n",
    "        trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"l2_leaf_reg\":\n",
    "        trial.suggest_uniform(\"l2_leaf_reg\", 1e-5, 1e2),\n",
    "        \"scale_pos_weight\":\n",
    "        trial.suggest_categorical(\"scale_pos_weight\", [2.7971]),\n",
    "        \"eval_metric\": CatBoostEvalMetricCustom(),\n",
    "        \"random_state\":\n",
    "        random_state\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        train_data = Pool(data=X_train, label=y_train, cat_features=cat_feat)\n",
    "        eval_data = Pool(data=X_test, label=y_test, cat_features=cat_feat)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_data, eval_set=eval_data,\n",
    "                  early_stopping_rounds=100, verbose=0)\n",
    "\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_predicts[idx] = amex_metric(y_test.values, preds[:, 1])\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "288fa7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-05 10:15:08,709]\u001b[0m A new study created in memory with name: CAT\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9152114081d1442c89971ff71a007e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-05 10:30:27,020]\u001b[0m Trial 0 finished with value: 0.7825432442587201 and parameters: {'n_estimators': 1500, 'learning_rate': 0.29380977563146177, 'l2_leaf_reg': 47.76055040187856, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7825432442587201.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 10:45:53,028]\u001b[0m Trial 1 finished with value: 0.7827937261676883 and parameters: {'n_estimators': 1500, 'learning_rate': 0.27786553073545717, 'l2_leaf_reg': 6.417439662214108, 'scale_pos_weight': 2.7971}. Best is trial 1 with value: 0.7827937261676883.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 11:01:22,502]\u001b[0m Trial 2 finished with value: 0.7839691607606913 and parameters: {'n_estimators': 1500, 'learning_rate': 0.24638367391819627, 'l2_leaf_reg': 44.18256107098331, 'scale_pos_weight': 2.7971}. Best is trial 2 with value: 0.7839691607606913.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 11:22:17,201]\u001b[0m Trial 3 finished with value: 0.7853368307235217 and parameters: {'n_estimators': 1500, 'learning_rate': 0.14368320308892796, 'l2_leaf_reg': 10.141225895492633, 'scale_pos_weight': 2.7971}. Best is trial 3 with value: 0.7853368307235217.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 11:45:29,699]\u001b[0m Trial 4 finished with value: 0.7858385930063767 and parameters: {'n_estimators': 1500, 'learning_rate': 0.16065208553271068, 'l2_leaf_reg': 13.877659749322707, 'scale_pos_weight': 2.7971}. Best is trial 4 with value: 0.7858385930063767.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 12:43:47,818]\u001b[0m Trial 5 finished with value: 0.7860954610908688 and parameters: {'n_estimators': 1500, 'learning_rate': 0.03880660425195467, 'l2_leaf_reg': 79.87185969430031, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7860954610908688.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_cat = optuna.create_study(direction=\"maximize\", study_name=\"CAT\")\n",
    "\n",
    "\n",
    "def func(trial): return objective_cat(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND, cat_feat=cat_feat)\n",
    "\n",
    "\n",
    "study_cat.optimize(func, n_trials=6, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae8d8fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c18dfa2068489abdf31a00d92014c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-05 13:02:03,157]\u001b[0m Trial 6 finished with value: 0.7831263764665102 and parameters: {'n_estimators': 1500, 'learning_rate': 0.269021853975694, 'l2_leaf_reg': 24.495710830253117, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7860954610908688.\u001b[0m\n",
      "\u001b[32m[I 2022-09-05 13:28:55,872]\u001b[0m Trial 7 finished with value: 0.7852732100477003 and parameters: {'n_estimators': 1500, 'learning_rate': 0.12450714908433726, 'l2_leaf_reg': 13.883620088800601, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7860954610908688.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_cat.optimize(func, n_trials=2, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0225f405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (amex metric): 0.78626\n",
      "\tBest params:\n",
      "\t\tn_estimators: 1500\n",
      "\t\tlearning_rate: 0.131187922183935\n",
      "\t\tl2_leaf_reg: 12.752475266490995\n",
      "\t\tleaf_estimation_iterations: 6\n",
      "\t\tscale_pos_weight: 2.7971\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value (amex metric): {study_cat.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_cat.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c22ea894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1500,\n",
       " 'learning_rate': 0.03880660425195467,\n",
       " 'l2_leaf_reg': 79.87185969430031,\n",
       " 'scale_pos_weight': 2.7971}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_cat.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1feef366",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'learning_rate': 0.03880660425195467,\n",
    "    'l2_leaf_reg': 79.87185969430031,\n",
    "    'scale_pos_weight': 2.861,\n",
    "    'eval_metric': CatBoostEvalMetricCustom(),\n",
    "    'random_state': RAND\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5456e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_optuna = CatBoostClassifier(**cat_params)\n",
    "                               \n",
    "cat_optuna.fit(X_train_,\n",
    "               y_train_,\n",
    "               cat_features=cat_feat,\n",
    "               eval_set=eval_set,\n",
    "               verbose=False,\n",
    "               early_stopping_rounds=100)\n",
    "\n",
    "y_pred = cat_optuna.predict(X_test)\n",
    "y_score = cat_optuna.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(get_metrics(y_test.values, y_pred, \n",
    "                                     y_score, name='CatBoost_Optuna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f76d20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>0.892451</td>\n",
       "      <td>0.953522</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.264326</td>\n",
       "      <td>0.757461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_Baseline</td>\n",
       "      <td>0.884022</td>\n",
       "      <td>0.957920</td>\n",
       "      <td>0.717815</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>0.776851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM_Baseline</td>\n",
       "      <td>0.881181</td>\n",
       "      <td>0.959101</td>\n",
       "      <td>0.708026</td>\n",
       "      <td>0.920860</td>\n",
       "      <td>0.800538</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.783520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_Baseline</td>\n",
       "      <td>0.887884</td>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.725380</td>\n",
       "      <td>0.912445</td>\n",
       "      <td>0.808230</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_Optuna</td>\n",
       "      <td>0.884388</td>\n",
       "      <td>0.960060</td>\n",
       "      <td>0.714857</td>\n",
       "      <td>0.920793</td>\n",
       "      <td>0.804861</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>0.786262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0  LogisticRegression_Baseline  0.883787  0.954230   0.722824  0.893998   \n",
       "0        RandomForest_Baseline  0.892451  0.953522   0.816657  0.753896   \n",
       "0             XGBoost_Baseline  0.884022  0.957920   0.717815  0.909718   \n",
       "0                LGBM_Baseline  0.881181  0.959101   0.708026  0.920860   \n",
       "0            CatBoost_Baseline  0.887884  0.959946   0.725380  0.912445   \n",
       "0              CatBoost_Optuna  0.884388  0.960060   0.714857  0.920793   \n",
       "\n",
       "         f1   Logloss      amex  \n",
       "0  0.799350  0.282031  0.764476  \n",
       "0  0.784023  0.264326  0.757461  \n",
       "0  0.802453  0.260512  0.776851  \n",
       "0  0.800538  0.261274  0.783520  \n",
       "0  0.808230  0.253600  0.784212  \n",
       "0  0.804861  0.258429  0.786262  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b84c0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'cat_optuna.sav'\n",
    "pickle.dump(cat_optuna, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "79c280f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.808\n",
      "f1 test: 0.805\n",
      "roc-auc train: 0.962\n",
      "roc-auc test: 0.960\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(cat_optuna, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af268847",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e3eda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgb(trial, X, y, N_FOLDS, random_state):\n",
    "    lgb_params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 6000, step=500),\n",
    "        \"scale_pos_weight\": trial.suggest_categorical(\"scale_pos_weight\", [2.7971]),\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True,\n",
    "                         random_state=random_state)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        lg = LGBMClassifier(**lgb_params)\n",
    "        lg.fit(X_train,\n",
    "               y_train,\n",
    "               eval_metric=custom_lg_amex_metric,\n",
    "               eval_set=[(X_test, y_test)],\n",
    "               early_stopping_rounds=100,\n",
    "               verbose=0)\n",
    "\n",
    "        preds = lg.predict_proba(X_test)\n",
    "        cv_predicts[idx] = amex_metric(y_test.values, preds[:, 1])\n",
    "\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b20dd36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 14:48:00,115]\u001b[0m A new study created in memory with name: lgb\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b4a47423c74c4dac2254026f4ac4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 14:51:10,888]\u001b[0m Trial 0 finished with value: 0.7839919517601184 and parameters: {'n_estimators': 2500, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7839919517601184.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 14:54:19,658]\u001b[0m Trial 1 finished with value: 0.7839919517601184 and parameters: {'n_estimators': 4000, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7839919517601184.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgb = optuna.create_study(direction=\"maximize\", study_name=\"lgb\")\n",
    "\n",
    "\n",
    "def func(trial): return objective_lgb(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "\n",
    "\n",
    "study_lgb.optimize(func, n_trials=2, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72523855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (amex): 0.78399\n",
      "\tBest params:\n",
      "\t\tn_estimators: 2500\n",
      "\t\tscale_pos_weight: 2.7971\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value (amex): {study_lgb.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbee1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgb(trial, X, y, N_FOLDS, random_state):\n",
    "    lgb_params = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1500]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"scale_pos_weight\":\n",
    "        trial.suggest_categorical(\"scale_pos_weight\", [2.7971]),\n",
    "        \"random_state\": random_state\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True,\n",
    "                         random_state=random_state)\n",
    "\n",
    "    cv_predicts = np.empty(N_FOLDS)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        lg = LGBMClassifier(**lgb_params, n_jobs=-1)\n",
    "        lg.fit(X_train,\n",
    "               y_train,\n",
    "               eval_metric=custom_lg_amex_metric,\n",
    "               eval_set=[(X_test, y_test)],\n",
    "               early_stopping_rounds=100,\n",
    "               verbose=0)\n",
    "\n",
    "        preds = lg.predict_proba(X_test)\n",
    "        cv_predicts[idx] = amex_metric(y_test.values, preds[:, 1])\n",
    "    return np.mean(cv_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec5f83df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 14:55:36,470]\u001b[0m A new study created in memory with name: lgb\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7346f4fe78ed4de5963204f4c400b786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.991756062643026, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.991756062643026\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.991756062643026, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.991756062643026\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.991756062643026, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.991756062643026\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.991756062643026, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.991756062643026\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.991756062643026, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.991756062643026\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 14:58:48,216]\u001b[0m Trial 0 finished with value: 0.7774589162213543 and parameters: {'n_estimators': 1500, 'learning_rate': 0.2906812123100373, 'num_leaves': 2500, 'max_depth': 11, 'min_data_in_leaf': 6400, 'max_bin': 253, 'lambda_l1': 95, 'lambda_l2': 35, 'min_gain_to_split': 9.991756062643026, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.8, 'scale_pos_weight': 2.7971}. Best is trial 0 with value: 0.7774589162213543.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.717431079246522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.717431079246522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.717431079246522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.717431079246522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.717431079246522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.717431079246522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.717431079246522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.717431079246522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.717431079246522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.717431079246522\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 15:02:26,914]\u001b[0m Trial 1 finished with value: 0.7792480683185289 and parameters: {'n_estimators': 1500, 'learning_rate': 0.20408781484167854, 'num_leaves': 3000, 'max_depth': 7, 'min_data_in_leaf': 3100, 'max_bin': 271, 'lambda_l1': 85, 'lambda_l2': 60, 'min_gain_to_split': 14.717431079246522, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.4, 'scale_pos_weight': 2.7971}. Best is trial 1 with value: 0.7792480683185289.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.979518692104142, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.979518692104142\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.979518692104142, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.979518692104142\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.979518692104142, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.979518692104142\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.979518692104142, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.979518692104142\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.979518692104142, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.979518692104142\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:06:30,368]\u001b[0m Trial 2 finished with value: 0.7786708966750441 and parameters: {'n_estimators': 1500, 'learning_rate': 0.1606220192794014, 'num_leaves': 60, 'max_depth': 7, 'min_data_in_leaf': 7900, 'max_bin': 284, 'lambda_l1': 45, 'lambda_l2': 20, 'min_gain_to_split': 12.979518692104142, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.5, 'scale_pos_weight': 2.7971}. Best is trial 1 with value: 0.7792480683185289.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.599800997237139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.599800997237139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.599800997237139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.599800997237139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.599800997237139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.599800997237139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.599800997237139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.599800997237139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.599800997237139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.599800997237139\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:13:52,336]\u001b[0m Trial 3 finished with value: 0.7840331143942321 and parameters: {'n_estimators': 1500, 'learning_rate': 0.04766138222880641, 'num_leaves': 1460, 'max_depth': 9, 'min_data_in_leaf': 7700, 'max_bin': 227, 'lambda_l1': 40, 'lambda_l2': 60, 'min_gain_to_split': 4.599800997237139, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.2, 'scale_pos_weight': 2.7971}. Best is trial 3 with value: 0.7840331143942321.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.2392398301358345, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.2392398301358345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.2392398301358345, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.2392398301358345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.2392398301358345, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.2392398301358345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.2392398301358345, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.2392398301358345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.2392398301358345, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.2392398301358345\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:22:11,023]\u001b[0m Trial 4 finished with value: 0.7838209906125501 and parameters: {'n_estimators': 1500, 'learning_rate': 0.04876875843081777, 'num_leaves': 2980, 'max_depth': 4, 'min_data_in_leaf': 8600, 'max_bin': 240, 'lambda_l1': 20, 'lambda_l2': 40, 'min_gain_to_split': 0.2392398301358345, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.4, 'scale_pos_weight': 2.7971}. Best is trial 3 with value: 0.7840331143942321.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:28:16,993]\u001b[0m Trial 5 finished with value: 0.7845067564405482 and parameters: {'n_estimators': 1500, 'learning_rate': 0.060637787392848454, 'num_leaves': 1400, 'max_depth': 7, 'min_data_in_leaf': 1800, 'max_bin': 250, 'lambda_l1': 35, 'lambda_l2': 55, 'min_gain_to_split': 8.858659446060356, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.2, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7845067564405482.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.212955298075196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.212955298075196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.212955298075196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.212955298075196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.212955298075196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.212955298075196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.212955298075196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.212955298075196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8500\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.212955298075196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.212955298075196\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:37:44,780]\u001b[0m Trial 6 finished with value: 0.7787462167197505 and parameters: {'n_estimators': 1500, 'learning_rate': 0.03752961385280169, 'num_leaves': 1640, 'max_depth': 10, 'min_data_in_leaf': 8500, 'max_bin': 207, 'lambda_l1': 60, 'lambda_l2': 35, 'min_gain_to_split': 11.212955298075196, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.9, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7845067564405482.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.989552229413193, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.989552229413193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.989552229413193, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.989552229413193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.989552229413193, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.989552229413193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.989552229413193, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.989552229413193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900\n",
      "[LightGBM] [Warning] min_gain_to_split is set=2.989552229413193, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.989552229413193\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:42:40,968]\u001b[0m Trial 7 finished with value: 0.7787050390569223 and parameters: {'n_estimators': 1500, 'learning_rate': 0.10895225335220222, 'num_leaves': 2500, 'max_depth': 3, 'min_data_in_leaf': 6900, 'max_bin': 242, 'lambda_l1': 80, 'lambda_l2': 35, 'min_gain_to_split': 2.989552229413193, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.2, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7845067564405482.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.625931297378965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.625931297378965\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.625931297378965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.625931297378965\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.625931297378965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.625931297378965\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.625931297378965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.625931297378965\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.625931297378965, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.625931297378965\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:47:19,285]\u001b[0m Trial 8 finished with value: 0.7793250171989528 and parameters: {'n_estimators': 1500, 'learning_rate': 0.15290548615771435, 'num_leaves': 2160, 'max_depth': 6, 'min_data_in_leaf': 6600, 'max_bin': 243, 'lambda_l1': 40, 'lambda_l2': 60, 'min_gain_to_split': 10.625931297378965, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.2, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7845067564405482.\u001b[0m\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.116791589891137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.116791589891137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.116791589891137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.116791589891137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.116791589891137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.116791589891137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.116791589891137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.116791589891137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.116791589891137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.116791589891137\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\u001b[32m[I 2022-09-06 15:51:23,013]\u001b[0m Trial 9 finished with value: 0.7836614757243543 and parameters: {'n_estimators': 1500, 'learning_rate': 0.1400361195952957, 'num_leaves': 2180, 'max_depth': 12, 'min_data_in_leaf': 3400, 'max_bin': 236, 'lambda_l1': 35, 'lambda_l2': 15, 'min_gain_to_split': 5.116791589891137, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.5, 'scale_pos_weight': 2.7971}. Best is trial 5 with value: 0.7845067564405482.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_lgb = optuna.create_study(direction=\"maximize\", study_name=\"lgb\")\n",
    "\n",
    "\n",
    "def func(trial): return objective_lgb(\n",
    "    trial, X_train, y_train, N_FOLDS=N_FOLDS, random_state=RAND)\n",
    "\n",
    "\n",
    "study_lgb.optimize(func, n_trials=10, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "722824d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (amex): 0.78451\n",
      "\tBest params:\n",
      "\t\tn_estimators: 1500\n",
      "\t\tlearning_rate: 0.060637787392848454\n",
      "\t\tnum_leaves: 1400\n",
      "\t\tmax_depth: 7\n",
      "\t\tmin_data_in_leaf: 1800\n",
      "\t\tmax_bin: 250\n",
      "\t\tlambda_l1: 35\n",
      "\t\tlambda_l2: 55\n",
      "\t\tmin_gain_to_split: 8.858659446060356\n",
      "\t\tbagging_fraction: 0.8\n",
      "\t\tbagging_freq: 1\n",
      "\t\tfeature_fraction: 0.2\n",
      "\t\tscale_pos_weight: 2.7971\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\tBest value (amex): {study_lgb.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study_lgb.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e89c1f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1500,\n",
       " 'learning_rate': 0.060637787392848454,\n",
       " 'num_leaves': 1400,\n",
       " 'max_depth': 7,\n",
       " 'min_data_in_leaf': 1800,\n",
       " 'max_bin': 250,\n",
       " 'lambda_l1': 35,\n",
       " 'lambda_l2': 55,\n",
       " 'min_gain_to_split': 8.858659446060356,\n",
       " 'bagging_fraction': 0.8,\n",
       " 'bagging_freq': 1,\n",
       " 'feature_fraction': 0.2,\n",
       " 'scale_pos_weight': 2.7971}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_lgb.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c3d9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_params = {\n",
    "    'n_estimators': 1500,\n",
    "    'learning_rate': 0.060637787392848454,\n",
    "    'num_leaves': 1400,\n",
    "    'max_depth': 7,\n",
    "    'min_data_in_leaf': 1800,\n",
    "    'max_bin': 250,\n",
    "    'lambda_l1': 35,\n",
    "    'lambda_l2': 55,\n",
    "    'min_gain_to_split': 8.858659446060356,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'feature_fraction': 0.2,\n",
    "    'scale_pos_weight': 2.7971\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "155570bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>0.892451</td>\n",
       "      <td>0.953522</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.264326</td>\n",
       "      <td>0.757461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost_Baseline</td>\n",
       "      <td>0.884022</td>\n",
       "      <td>0.957920</td>\n",
       "      <td>0.717815</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>0.776851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM_Baseline</td>\n",
       "      <td>0.881181</td>\n",
       "      <td>0.959101</td>\n",
       "      <td>0.708026</td>\n",
       "      <td>0.920860</td>\n",
       "      <td>0.800538</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.783520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_Baseline</td>\n",
       "      <td>0.887884</td>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.725380</td>\n",
       "      <td>0.912445</td>\n",
       "      <td>0.808230</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_Optuna</td>\n",
       "      <td>0.884388</td>\n",
       "      <td>0.960060</td>\n",
       "      <td>0.714857</td>\n",
       "      <td>0.920793</td>\n",
       "      <td>0.804861</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>0.786262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM_Optuna</td>\n",
       "      <td>0.883953</td>\n",
       "      <td>0.959533</td>\n",
       "      <td>0.714821</td>\n",
       "      <td>0.918100</td>\n",
       "      <td>0.803808</td>\n",
       "      <td>0.258686</td>\n",
       "      <td>0.783749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0  LogisticRegression_Baseline  0.883787  0.954230   0.722824  0.893998   \n",
       "0        RandomForest_Baseline  0.892451  0.953522   0.816657  0.753896   \n",
       "0             XGBoost_Baseline  0.884022  0.957920   0.717815  0.909718   \n",
       "0                LGBM_Baseline  0.881181  0.959101   0.708026  0.920860   \n",
       "0            CatBoost_Baseline  0.887884  0.959946   0.725380  0.912445   \n",
       "0              CatBoost_Optuna  0.884388  0.960060   0.714857  0.920793   \n",
       "0                  LGBM_Optuna  0.883953  0.959533   0.714821  0.918100   \n",
       "\n",
       "         f1   Logloss      amex  \n",
       "0  0.799350  0.282031  0.764476  \n",
       "0  0.784023  0.264326  0.757461  \n",
       "0  0.802453  0.260512  0.776851  \n",
       "0  0.800538  0.261274  0.783520  \n",
       "0  0.808230  0.253600  0.784212  \n",
       "0  0.804861  0.258429  0.786262  \n",
       "0  0.803808  0.258686  0.783749  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg_optuna = LGBMClassifier(**lg_params)\n",
    "lg_optuna.fit(X_train_, y_train_,\n",
    "              eval_set=eval_set,\n",
    "              verbose=False,\n",
    "              eval_metric=custom_lg_amex_metric,\n",
    "              early_stopping_rounds=100)\n",
    "\n",
    "y_pred = lg_optuna.predict(X_test)\n",
    "y_score = lg_optuna.predict_proba(X_test)\n",
    "\n",
    "metrics = metrics.append(get_metrics(y_test.values, y_pred,\n",
    "                                     y_score, name='LGBM_Optuna'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af6a5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'lg_optuna.sav'\n",
    "pickle.dump(lg_optuna, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c555aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.806\n",
      "f1 test: 0.804\n",
      "roc-auc train: 0.961\n",
      "roc-auc test: 0.960\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(lg_optuna, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4befd0fc",
   "metadata": {},
   "source": [
    "### Стекинг"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b09976",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91ed506a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 amex 0.785\n",
      "---\n",
      "Fold: 2 amex 0.781\n",
      "---\n",
      "Fold: 3 amex 0.786\n",
      "---\n",
      "Fold: 4 amex 0.784\n",
      "---\n",
      "Fold: 5 amex 0.788\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "meta_X = pd.DataFrame()\n",
    "meta_X_test = pd.DataFrame()\n",
    "\n",
    "pred_val = []\n",
    "pred_score_val = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RAND)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_, X_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_, y_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    model = CatBoostClassifier(**cat_params, cat_features=cat_feat)\n",
    "\n",
    "    train_data = Pool(data=X_train_, label=y_train_, cat_features=cat_feat)\n",
    "    eval_data = Pool(data=X_val, label=y_val, cat_features=cat_feat)\n",
    "\n",
    "    model.fit(train_data,\n",
    "              eval_set=eval_data,\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_score_val = model.predict_proba(X_val)\n",
    "\n",
    "    print(\"Fold:\", fold + 1,\n",
    "          \"amex %.3f\" % amex_metric(y_val.values, y_score_val[:, 1]))\n",
    "    print(\"---\")\n",
    "\n",
    "    # holdout list\n",
    "    pred_val.append(y_pred_val)\n",
    "    pred_score_val.append(y_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed413f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6540242\ttotal: 748ms\tremaining: 18m 41s\n",
      "1:\tlearn: 0.6820336\ttotal: 1.43s\tremaining: 17m 51s\n",
      "2:\tlearn: 0.6924801\ttotal: 2.12s\tremaining: 17m 36s\n",
      "3:\tlearn: 0.6988763\ttotal: 2.81s\tremaining: 17m 30s\n",
      "4:\tlearn: 0.7074218\ttotal: 3.53s\tremaining: 17m 34s\n",
      "5:\tlearn: 0.7065983\ttotal: 4.25s\tremaining: 17m 37s\n",
      "6:\tlearn: 0.7137614\ttotal: 4.95s\tremaining: 17m 36s\n",
      "7:\tlearn: 0.7185483\ttotal: 5.65s\tremaining: 17m 33s\n",
      "8:\tlearn: 0.7223040\ttotal: 6.35s\tremaining: 17m 32s\n",
      "9:\tlearn: 0.7250234\ttotal: 7.07s\tremaining: 17m 32s\n",
      "10:\tlearn: 0.7283030\ttotal: 7.78s\tremaining: 17m 32s\n",
      "11:\tlearn: 0.7290827\ttotal: 8.49s\tremaining: 17m 33s\n",
      "12:\tlearn: 0.7306880\ttotal: 9.21s\tremaining: 17m 33s\n",
      "13:\tlearn: 0.7324371\ttotal: 9.92s\tremaining: 17m 32s\n",
      "14:\tlearn: 0.7326194\ttotal: 10.6s\tremaining: 17m 31s\n",
      "15:\tlearn: 0.7329800\ttotal: 11.3s\tremaining: 17m 30s\n",
      "16:\tlearn: 0.7336731\ttotal: 12s\tremaining: 17m 30s\n",
      "17:\tlearn: 0.7345077\ttotal: 12.8s\tremaining: 17m 32s\n",
      "18:\tlearn: 0.7352006\ttotal: 13.5s\tremaining: 17m 32s\n",
      "19:\tlearn: 0.7353854\ttotal: 14.2s\tremaining: 17m 31s\n",
      "20:\tlearn: 0.7368800\ttotal: 14.9s\tremaining: 17m 30s\n",
      "21:\tlearn: 0.7379641\ttotal: 15.6s\tremaining: 17m 29s\n",
      "22:\tlearn: 0.7381667\ttotal: 16.3s\tremaining: 17m 28s\n",
      "23:\tlearn: 0.7390420\ttotal: 17s\tremaining: 17m 27s\n",
      "24:\tlearn: 0.7392877\ttotal: 17.7s\tremaining: 17m 25s\n",
      "25:\tlearn: 0.7396910\ttotal: 18.4s\tremaining: 17m 25s\n",
      "26:\tlearn: 0.7396346\ttotal: 19.2s\tremaining: 17m 25s\n",
      "27:\tlearn: 0.7403129\ttotal: 19.9s\tremaining: 17m 24s\n",
      "28:\tlearn: 0.7408577\ttotal: 20.6s\tremaining: 17m 23s\n",
      "29:\tlearn: 0.7422226\ttotal: 21.3s\tremaining: 17m 23s\n",
      "30:\tlearn: 0.7433434\ttotal: 22s\tremaining: 17m 23s\n",
      "31:\tlearn: 0.7436591\ttotal: 22.7s\tremaining: 17m 22s\n",
      "32:\tlearn: 0.7443325\ttotal: 23.4s\tremaining: 17m 21s\n",
      "33:\tlearn: 0.7450601\ttotal: 24.1s\tremaining: 17m 20s\n",
      "34:\tlearn: 0.7450428\ttotal: 24.8s\tremaining: 17m 18s\n",
      "35:\tlearn: 0.7460434\ttotal: 25.5s\tremaining: 17m 17s\n",
      "36:\tlearn: 0.7468401\ttotal: 26.2s\tremaining: 17m 17s\n",
      "37:\tlearn: 0.7479066\ttotal: 26.9s\tremaining: 17m 15s\n",
      "38:\tlearn: 0.7484576\ttotal: 27.6s\tremaining: 17m 14s\n",
      "39:\tlearn: 0.7487569\ttotal: 28.3s\tremaining: 17m 13s\n",
      "40:\tlearn: 0.7488226\ttotal: 29s\tremaining: 17m 12s\n",
      "41:\tlearn: 0.7494967\ttotal: 29.7s\tremaining: 17m 11s\n",
      "42:\tlearn: 0.7501552\ttotal: 30.4s\tremaining: 17m 10s\n",
      "43:\tlearn: 0.7507108\ttotal: 31.1s\tremaining: 17m 10s\n",
      "44:\tlearn: 0.7510373\ttotal: 31.9s\tremaining: 17m 9s\n",
      "45:\tlearn: 0.7518075\ttotal: 32.5s\tremaining: 17m 8s\n",
      "46:\tlearn: 0.7521162\ttotal: 33.2s\tremaining: 17m 7s\n",
      "47:\tlearn: 0.7527305\ttotal: 33.9s\tremaining: 17m 6s\n",
      "48:\tlearn: 0.7529867\ttotal: 34.6s\tremaining: 17m 5s\n",
      "49:\tlearn: 0.7532647\ttotal: 35.3s\tremaining: 17m 4s\n",
      "50:\tlearn: 0.7534763\ttotal: 36s\tremaining: 17m 3s\n",
      "51:\tlearn: 0.7537112\ttotal: 36.7s\tremaining: 17m 3s\n",
      "52:\tlearn: 0.7543306\ttotal: 37.4s\tremaining: 17m 2s\n",
      "53:\tlearn: 0.7546246\ttotal: 38.1s\tremaining: 17m 1s\n",
      "54:\tlearn: 0.7553704\ttotal: 38.8s\tremaining: 17m\n",
      "55:\tlearn: 0.7559984\ttotal: 39.6s\tremaining: 17m\n",
      "56:\tlearn: 0.7558814\ttotal: 40.3s\tremaining: 16m 59s\n",
      "57:\tlearn: 0.7562658\ttotal: 41s\tremaining: 16m 58s\n",
      "58:\tlearn: 0.7565072\ttotal: 41.7s\tremaining: 16m 58s\n",
      "59:\tlearn: 0.7572961\ttotal: 42.4s\tremaining: 16m 58s\n",
      "60:\tlearn: 0.7573291\ttotal: 43.1s\tremaining: 16m 57s\n",
      "61:\tlearn: 0.7576305\ttotal: 43.8s\tremaining: 16m 56s\n",
      "62:\tlearn: 0.7580470\ttotal: 44.5s\tremaining: 16m 55s\n",
      "63:\tlearn: 0.7582959\ttotal: 45.2s\tremaining: 16m 54s\n",
      "64:\tlearn: 0.7585795\ttotal: 45.9s\tremaining: 16m 53s\n",
      "65:\tlearn: 0.7589759\ttotal: 46.6s\tremaining: 16m 53s\n",
      "66:\tlearn: 0.7591901\ttotal: 47.4s\tremaining: 16m 52s\n",
      "67:\tlearn: 0.7594298\ttotal: 48.1s\tremaining: 16m 52s\n",
      "68:\tlearn: 0.7598175\ttotal: 48.8s\tremaining: 16m 52s\n",
      "69:\tlearn: 0.7600343\ttotal: 49.5s\tremaining: 16m 51s\n",
      "70:\tlearn: 0.7601911\ttotal: 50.2s\tremaining: 16m 50s\n",
      "71:\tlearn: 0.7605581\ttotal: 50.9s\tremaining: 16m 49s\n",
      "72:\tlearn: 0.7605619\ttotal: 51.6s\tremaining: 16m 48s\n",
      "73:\tlearn: 0.7609982\ttotal: 52.3s\tremaining: 16m 47s\n",
      "74:\tlearn: 0.7611025\ttotal: 53s\tremaining: 16m 47s\n",
      "75:\tlearn: 0.7614629\ttotal: 53.7s\tremaining: 16m 46s\n",
      "76:\tlearn: 0.7618362\ttotal: 54.4s\tremaining: 16m 45s\n",
      "77:\tlearn: 0.7619456\ttotal: 55.2s\tremaining: 16m 45s\n",
      "78:\tlearn: 0.7621619\ttotal: 55.9s\tremaining: 16m 45s\n",
      "79:\tlearn: 0.7621542\ttotal: 56.6s\tremaining: 16m 44s\n",
      "80:\tlearn: 0.7625616\ttotal: 57.3s\tremaining: 16m 43s\n",
      "81:\tlearn: 0.7629301\ttotal: 58s\tremaining: 16m 42s\n",
      "82:\tlearn: 0.7630426\ttotal: 58.7s\tremaining: 16m 41s\n",
      "83:\tlearn: 0.7631404\ttotal: 59.4s\tremaining: 16m 40s\n",
      "84:\tlearn: 0.7634469\ttotal: 1m\tremaining: 16m 39s\n",
      "85:\tlearn: 0.7638156\ttotal: 1m\tremaining: 16m 40s\n",
      "86:\tlearn: 0.7640145\ttotal: 1m 1s\tremaining: 16m 40s\n",
      "87:\tlearn: 0.7643268\ttotal: 1m 2s\tremaining: 16m 39s\n",
      "88:\tlearn: 0.7642833\ttotal: 1m 3s\tremaining: 16m 38s\n",
      "89:\tlearn: 0.7645442\ttotal: 1m 3s\tremaining: 16m 38s\n",
      "90:\tlearn: 0.7647638\ttotal: 1m 4s\tremaining: 16m 37s\n",
      "91:\tlearn: 0.7649014\ttotal: 1m 5s\tremaining: 16m 36s\n",
      "92:\tlearn: 0.7650894\ttotal: 1m 5s\tremaining: 16m 35s\n",
      "93:\tlearn: 0.7653209\ttotal: 1m 6s\tremaining: 16m 34s\n",
      "94:\tlearn: 0.7654376\ttotal: 1m 7s\tremaining: 16m 33s\n",
      "95:\tlearn: 0.7657225\ttotal: 1m 7s\tremaining: 16m 32s\n",
      "96:\tlearn: 0.7657515\ttotal: 1m 8s\tremaining: 16m 31s\n",
      "97:\tlearn: 0.7659653\ttotal: 1m 9s\tremaining: 16m 30s\n",
      "98:\tlearn: 0.7658128\ttotal: 1m 9s\tremaining: 16m 29s\n",
      "99:\tlearn: 0.7662237\ttotal: 1m 10s\tremaining: 16m 29s\n",
      "100:\tlearn: 0.7664420\ttotal: 1m 11s\tremaining: 16m 28s\n",
      "101:\tlearn: 0.7665748\ttotal: 1m 12s\tremaining: 16m 28s\n",
      "102:\tlearn: 0.7667736\ttotal: 1m 12s\tremaining: 16m 27s\n",
      "103:\tlearn: 0.7669008\ttotal: 1m 13s\tremaining: 16m 26s\n",
      "104:\tlearn: 0.7670537\ttotal: 1m 14s\tremaining: 16m 25s\n",
      "105:\tlearn: 0.7673024\ttotal: 1m 14s\tremaining: 16m 25s\n",
      "106:\tlearn: 0.7673795\ttotal: 1m 15s\tremaining: 16m 24s\n",
      "107:\tlearn: 0.7675085\ttotal: 1m 16s\tremaining: 16m 23s\n",
      "108:\tlearn: 0.7676904\ttotal: 1m 17s\tremaining: 16m 22s\n",
      "109:\tlearn: 0.7677585\ttotal: 1m 17s\tremaining: 16m 21s\n",
      "110:\tlearn: 0.7677555\ttotal: 1m 18s\tremaining: 16m 21s\n",
      "111:\tlearn: 0.7678821\ttotal: 1m 19s\tremaining: 16m 20s\n",
      "112:\tlearn: 0.7679490\ttotal: 1m 19s\tremaining: 16m 19s\n",
      "113:\tlearn: 0.7680796\ttotal: 1m 20s\tremaining: 16m 18s\n",
      "114:\tlearn: 0.7682474\ttotal: 1m 21s\tremaining: 16m 17s\n",
      "115:\tlearn: 0.7684811\ttotal: 1m 21s\tremaining: 16m 17s\n",
      "116:\tlearn: 0.7686982\ttotal: 1m 22s\tremaining: 16m 16s\n",
      "117:\tlearn: 0.7687922\ttotal: 1m 23s\tremaining: 16m 15s\n",
      "118:\tlearn: 0.7689871\ttotal: 1m 24s\tremaining: 16m 15s\n",
      "119:\tlearn: 0.7692338\ttotal: 1m 24s\tremaining: 16m 14s\n",
      "120:\tlearn: 0.7694234\ttotal: 1m 25s\tremaining: 16m 13s\n",
      "121:\tlearn: 0.7694458\ttotal: 1m 26s\tremaining: 16m 13s\n",
      "122:\tlearn: 0.7696359\ttotal: 1m 26s\tremaining: 16m 12s\n",
      "123:\tlearn: 0.7695829\ttotal: 1m 27s\tremaining: 16m 11s\n",
      "124:\tlearn: 0.7697494\ttotal: 1m 28s\tremaining: 16m 11s\n",
      "125:\tlearn: 0.7698858\ttotal: 1m 29s\tremaining: 16m 11s\n",
      "126:\tlearn: 0.7701224\ttotal: 1m 29s\tremaining: 16m 11s\n",
      "127:\tlearn: 0.7704434\ttotal: 1m 30s\tremaining: 16m 10s\n",
      "128:\tlearn: 0.7704641\ttotal: 1m 31s\tremaining: 16m 9s\n",
      "129:\tlearn: 0.7705272\ttotal: 1m 31s\tremaining: 16m 9s\n",
      "130:\tlearn: 0.7708446\ttotal: 1m 32s\tremaining: 16m 8s\n",
      "131:\tlearn: 0.7709529\ttotal: 1m 33s\tremaining: 16m 7s\n",
      "132:\tlearn: 0.7710294\ttotal: 1m 34s\tremaining: 16m 7s\n",
      "133:\tlearn: 0.7710087\ttotal: 1m 34s\tremaining: 16m 6s\n",
      "134:\tlearn: 0.7711758\ttotal: 1m 35s\tremaining: 16m 5s\n",
      "135:\tlearn: 0.7713592\ttotal: 1m 36s\tremaining: 16m 4s\n",
      "136:\tlearn: 0.7714998\ttotal: 1m 36s\tremaining: 16m 3s\n",
      "137:\tlearn: 0.7715379\ttotal: 1m 37s\tremaining: 16m 2s\n",
      "138:\tlearn: 0.7717363\ttotal: 1m 38s\tremaining: 16m 2s\n",
      "139:\tlearn: 0.7719233\ttotal: 1m 38s\tremaining: 16m 1s\n",
      "140:\tlearn: 0.7719740\ttotal: 1m 39s\tremaining: 16m\n",
      "141:\tlearn: 0.7720905\ttotal: 1m 40s\tremaining: 15m 59s\n",
      "142:\tlearn: 0.7721005\ttotal: 1m 41s\tremaining: 15m 59s\n",
      "143:\tlearn: 0.7721208\ttotal: 1m 41s\tremaining: 15m 58s\n",
      "144:\tlearn: 0.7721730\ttotal: 1m 42s\tremaining: 15m 57s\n",
      "145:\tlearn: 0.7724210\ttotal: 1m 43s\tremaining: 15m 56s\n",
      "146:\tlearn: 0.7725535\ttotal: 1m 43s\tremaining: 15m 55s\n",
      "147:\tlearn: 0.7727976\ttotal: 1m 44s\tremaining: 15m 55s\n",
      "148:\tlearn: 0.7729401\ttotal: 1m 45s\tremaining: 15m 54s\n",
      "149:\tlearn: 0.7731467\ttotal: 1m 45s\tremaining: 15m 53s\n",
      "150:\tlearn: 0.7733119\ttotal: 1m 46s\tremaining: 15m 52s\n",
      "151:\tlearn: 0.7732404\ttotal: 1m 47s\tremaining: 15m 52s\n",
      "152:\tlearn: 0.7733379\ttotal: 1m 48s\tremaining: 15m 51s\n",
      "153:\tlearn: 0.7733829\ttotal: 1m 48s\tremaining: 15m 50s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154:\tlearn: 0.7736080\ttotal: 1m 49s\tremaining: 15m 49s\n",
      "155:\tlearn: 0.7734806\ttotal: 1m 50s\tremaining: 15m 48s\n",
      "156:\tlearn: 0.7737769\ttotal: 1m 50s\tremaining: 15m 48s\n",
      "157:\tlearn: 0.7737959\ttotal: 1m 51s\tremaining: 15m 47s\n",
      "158:\tlearn: 0.7738639\ttotal: 1m 52s\tremaining: 15m 46s\n",
      "159:\tlearn: 0.7739926\ttotal: 1m 52s\tremaining: 15m 45s\n",
      "160:\tlearn: 0.7738215\ttotal: 1m 53s\tremaining: 15m 45s\n",
      "161:\tlearn: 0.7739630\ttotal: 1m 54s\tremaining: 15m 44s\n",
      "162:\tlearn: 0.7741361\ttotal: 1m 55s\tremaining: 15m 43s\n",
      "163:\tlearn: 0.7741465\ttotal: 1m 55s\tremaining: 15m 42s\n",
      "164:\tlearn: 0.7741608\ttotal: 1m 56s\tremaining: 15m 42s\n",
      "165:\tlearn: 0.7741282\ttotal: 1m 57s\tremaining: 15m 41s\n",
      "166:\tlearn: 0.7741847\ttotal: 1m 57s\tremaining: 15m 40s\n",
      "167:\tlearn: 0.7743962\ttotal: 1m 58s\tremaining: 15m 39s\n",
      "168:\tlearn: 0.7744340\ttotal: 1m 59s\tremaining: 15m 39s\n",
      "169:\tlearn: 0.7746007\ttotal: 1m 59s\tremaining: 15m 38s\n",
      "170:\tlearn: 0.7746075\ttotal: 2m\tremaining: 15m 37s\n",
      "171:\tlearn: 0.7746883\ttotal: 2m 1s\tremaining: 15m 36s\n",
      "172:\tlearn: 0.7749658\ttotal: 2m 2s\tremaining: 15m 35s\n",
      "173:\tlearn: 0.7751285\ttotal: 2m 2s\tremaining: 15m 35s\n",
      "174:\tlearn: 0.7751334\ttotal: 2m 3s\tremaining: 15m 34s\n",
      "175:\tlearn: 0.7752094\ttotal: 2m 4s\tremaining: 15m 33s\n",
      "176:\tlearn: 0.7750910\ttotal: 2m 4s\tremaining: 15m 32s\n",
      "177:\tlearn: 0.7752135\ttotal: 2m 5s\tremaining: 15m 31s\n",
      "178:\tlearn: 0.7751030\ttotal: 2m 6s\tremaining: 15m 31s\n",
      "179:\tlearn: 0.7751979\ttotal: 2m 6s\tremaining: 15m 30s\n",
      "180:\tlearn: 0.7751581\ttotal: 2m 7s\tremaining: 15m 29s\n",
      "181:\tlearn: 0.7752578\ttotal: 2m 8s\tremaining: 15m 28s\n",
      "182:\tlearn: 0.7754179\ttotal: 2m 8s\tremaining: 15m 27s\n",
      "183:\tlearn: 0.7755463\ttotal: 2m 9s\tremaining: 15m 27s\n",
      "184:\tlearn: 0.7755400\ttotal: 2m 10s\tremaining: 15m 26s\n",
      "185:\tlearn: 0.7759177\ttotal: 2m 11s\tremaining: 15m 25s\n",
      "186:\tlearn: 0.7760063\ttotal: 2m 11s\tremaining: 15m 25s\n",
      "187:\tlearn: 0.7761280\ttotal: 2m 12s\tremaining: 15m 24s\n",
      "188:\tlearn: 0.7761504\ttotal: 2m 13s\tremaining: 15m 23s\n",
      "189:\tlearn: 0.7761454\ttotal: 2m 13s\tremaining: 15m 23s\n",
      "190:\tlearn: 0.7763311\ttotal: 2m 14s\tremaining: 15m 22s\n",
      "191:\tlearn: 0.7763202\ttotal: 2m 15s\tremaining: 15m 21s\n",
      "192:\tlearn: 0.7762902\ttotal: 2m 15s\tremaining: 15m 20s\n",
      "193:\tlearn: 0.7763823\ttotal: 2m 16s\tremaining: 15m 20s\n",
      "194:\tlearn: 0.7764791\ttotal: 2m 17s\tremaining: 15m 19s\n",
      "195:\tlearn: 0.7764768\ttotal: 2m 18s\tremaining: 15m 18s\n",
      "196:\tlearn: 0.7767139\ttotal: 2m 18s\tremaining: 15m 17s\n",
      "197:\tlearn: 0.7768608\ttotal: 2m 19s\tremaining: 15m 17s\n",
      "198:\tlearn: 0.7770478\ttotal: 2m 20s\tremaining: 15m 16s\n",
      "199:\tlearn: 0.7771162\ttotal: 2m 20s\tremaining: 15m 15s\n",
      "200:\tlearn: 0.7772006\ttotal: 2m 21s\tremaining: 15m 14s\n",
      "201:\tlearn: 0.7772765\ttotal: 2m 22s\tremaining: 15m 14s\n",
      "202:\tlearn: 0.7773440\ttotal: 2m 22s\tremaining: 15m 13s\n",
      "203:\tlearn: 0.7774128\ttotal: 2m 23s\tremaining: 15m 12s\n",
      "204:\tlearn: 0.7776050\ttotal: 2m 24s\tremaining: 15m 11s\n",
      "205:\tlearn: 0.7775608\ttotal: 2m 25s\tremaining: 15m 11s\n",
      "206:\tlearn: 0.7775419\ttotal: 2m 25s\tremaining: 15m 10s\n",
      "207:\tlearn: 0.7775403\ttotal: 2m 26s\tremaining: 15m 9s\n",
      "208:\tlearn: 0.7776536\ttotal: 2m 27s\tremaining: 15m 8s\n",
      "209:\tlearn: 0.7778284\ttotal: 2m 27s\tremaining: 15m 8s\n",
      "210:\tlearn: 0.7778851\ttotal: 2m 28s\tremaining: 15m 7s\n",
      "211:\tlearn: 0.7780657\ttotal: 2m 29s\tremaining: 15m 6s\n",
      "212:\tlearn: 0.7779709\ttotal: 2m 29s\tremaining: 15m 6s\n",
      "213:\tlearn: 0.7781988\ttotal: 2m 30s\tremaining: 15m 5s\n",
      "214:\tlearn: 0.7783139\ttotal: 2m 31s\tremaining: 15m 4s\n",
      "215:\tlearn: 0.7783806\ttotal: 2m 32s\tremaining: 15m 3s\n",
      "216:\tlearn: 0.7784282\ttotal: 2m 32s\tremaining: 15m 3s\n",
      "217:\tlearn: 0.7784225\ttotal: 2m 33s\tremaining: 15m 2s\n",
      "218:\tlearn: 0.7784043\ttotal: 2m 34s\tremaining: 15m 1s\n",
      "219:\tlearn: 0.7784392\ttotal: 2m 34s\tremaining: 15m 1s\n",
      "220:\tlearn: 0.7785997\ttotal: 2m 35s\tremaining: 15m\n",
      "221:\tlearn: 0.7785826\ttotal: 2m 36s\tremaining: 14m 59s\n",
      "222:\tlearn: 0.7785863\ttotal: 2m 37s\tremaining: 14m 59s\n",
      "223:\tlearn: 0.7787409\ttotal: 2m 37s\tremaining: 14m 58s\n",
      "224:\tlearn: 0.7788224\ttotal: 2m 38s\tremaining: 14m 57s\n",
      "225:\tlearn: 0.7790163\ttotal: 2m 39s\tremaining: 14m 57s\n",
      "226:\tlearn: 0.7790659\ttotal: 2m 39s\tremaining: 14m 56s\n",
      "227:\tlearn: 0.7791146\ttotal: 2m 40s\tremaining: 14m 55s\n",
      "228:\tlearn: 0.7792159\ttotal: 2m 41s\tremaining: 14m 54s\n",
      "229:\tlearn: 0.7792808\ttotal: 2m 41s\tremaining: 14m 54s\n",
      "230:\tlearn: 0.7793160\ttotal: 2m 42s\tremaining: 14m 53s\n",
      "231:\tlearn: 0.7793924\ttotal: 2m 43s\tremaining: 14m 52s\n",
      "232:\tlearn: 0.7793523\ttotal: 2m 44s\tremaining: 14m 52s\n",
      "233:\tlearn: 0.7794619\ttotal: 2m 44s\tremaining: 14m 51s\n",
      "234:\tlearn: 0.7796101\ttotal: 2m 45s\tremaining: 14m 50s\n",
      "235:\tlearn: 0.7795848\ttotal: 2m 46s\tremaining: 14m 49s\n",
      "236:\tlearn: 0.7798211\ttotal: 2m 46s\tremaining: 14m 49s\n",
      "237:\tlearn: 0.7798074\ttotal: 2m 47s\tremaining: 14m 48s\n",
      "238:\tlearn: 0.7797483\ttotal: 2m 48s\tremaining: 14m 47s\n",
      "239:\tlearn: 0.7798210\ttotal: 2m 48s\tremaining: 14m 47s\n",
      "240:\tlearn: 0.7798784\ttotal: 2m 49s\tremaining: 14m 46s\n",
      "241:\tlearn: 0.7798711\ttotal: 2m 50s\tremaining: 14m 45s\n",
      "242:\tlearn: 0.7801685\ttotal: 2m 51s\tremaining: 14m 45s\n",
      "243:\tlearn: 0.7801709\ttotal: 2m 51s\tremaining: 14m 44s\n",
      "244:\tlearn: 0.7803031\ttotal: 2m 52s\tremaining: 14m 43s\n",
      "245:\tlearn: 0.7802266\ttotal: 2m 53s\tremaining: 14m 43s\n",
      "246:\tlearn: 0.7802964\ttotal: 2m 53s\tremaining: 14m 42s\n",
      "247:\tlearn: 0.7802638\ttotal: 2m 54s\tremaining: 14m 41s\n",
      "248:\tlearn: 0.7804238\ttotal: 2m 55s\tremaining: 14m 41s\n",
      "249:\tlearn: 0.7803217\ttotal: 2m 56s\tremaining: 14m 40s\n",
      "250:\tlearn: 0.7803837\ttotal: 2m 56s\tremaining: 14m 39s\n",
      "251:\tlearn: 0.7805425\ttotal: 2m 57s\tremaining: 14m 38s\n",
      "252:\tlearn: 0.7807004\ttotal: 2m 58s\tremaining: 14m 38s\n",
      "253:\tlearn: 0.7805712\ttotal: 2m 58s\tremaining: 14m 37s\n",
      "254:\tlearn: 0.7806449\ttotal: 2m 59s\tremaining: 14m 36s\n",
      "255:\tlearn: 0.7806308\ttotal: 3m\tremaining: 14m 35s\n",
      "256:\tlearn: 0.7805833\ttotal: 3m\tremaining: 14m 35s\n",
      "257:\tlearn: 0.7806079\ttotal: 3m 1s\tremaining: 14m 34s\n",
      "258:\tlearn: 0.7806223\ttotal: 3m 2s\tremaining: 14m 33s\n",
      "259:\tlearn: 0.7807187\ttotal: 3m 3s\tremaining: 14m 33s\n",
      "260:\tlearn: 0.7807902\ttotal: 3m 3s\tremaining: 14m 32s\n",
      "261:\tlearn: 0.7808066\ttotal: 3m 4s\tremaining: 14m 32s\n",
      "262:\tlearn: 0.7807869\ttotal: 3m 5s\tremaining: 14m 32s\n",
      "263:\tlearn: 0.7807753\ttotal: 3m 6s\tremaining: 14m 31s\n",
      "264:\tlearn: 0.7808085\ttotal: 3m 7s\tremaining: 14m 31s\n",
      "265:\tlearn: 0.7808323\ttotal: 3m 7s\tremaining: 14m 31s\n",
      "266:\tlearn: 0.7808989\ttotal: 3m 8s\tremaining: 14m 30s\n",
      "267:\tlearn: 0.7808921\ttotal: 3m 9s\tremaining: 14m 30s\n",
      "268:\tlearn: 0.7808574\ttotal: 3m 10s\tremaining: 14m 29s\n",
      "269:\tlearn: 0.7809022\ttotal: 3m 10s\tremaining: 14m 29s\n",
      "270:\tlearn: 0.7810811\ttotal: 3m 11s\tremaining: 14m 28s\n",
      "271:\tlearn: 0.7812106\ttotal: 3m 12s\tremaining: 14m 28s\n",
      "272:\tlearn: 0.7812433\ttotal: 3m 13s\tremaining: 14m 27s\n",
      "273:\tlearn: 0.7813391\ttotal: 3m 13s\tremaining: 14m 27s\n",
      "274:\tlearn: 0.7813813\ttotal: 3m 14s\tremaining: 14m 26s\n",
      "275:\tlearn: 0.7814338\ttotal: 3m 15s\tremaining: 14m 25s\n",
      "276:\tlearn: 0.7814767\ttotal: 3m 16s\tremaining: 14m 25s\n",
      "277:\tlearn: 0.7816039\ttotal: 3m 16s\tremaining: 14m 25s\n",
      "278:\tlearn: 0.7815815\ttotal: 3m 17s\tremaining: 14m 24s\n",
      "279:\tlearn: 0.7815642\ttotal: 3m 18s\tremaining: 14m 24s\n",
      "280:\tlearn: 0.7816562\ttotal: 3m 19s\tremaining: 14m 23s\n",
      "281:\tlearn: 0.7818055\ttotal: 3m 19s\tremaining: 14m 22s\n",
      "282:\tlearn: 0.7817521\ttotal: 3m 20s\tremaining: 14m 21s\n",
      "283:\tlearn: 0.7817391\ttotal: 3m 21s\tremaining: 14m 21s\n",
      "284:\tlearn: 0.7817993\ttotal: 3m 21s\tremaining: 14m 20s\n",
      "285:\tlearn: 0.7818911\ttotal: 3m 22s\tremaining: 14m 19s\n",
      "286:\tlearn: 0.7820144\ttotal: 3m 23s\tremaining: 14m 19s\n",
      "287:\tlearn: 0.7820435\ttotal: 3m 23s\tremaining: 14m 18s\n",
      "288:\tlearn: 0.7821265\ttotal: 3m 24s\tremaining: 14m 17s\n",
      "289:\tlearn: 0.7822036\ttotal: 3m 25s\tremaining: 14m 16s\n",
      "290:\tlearn: 0.7823329\ttotal: 3m 26s\tremaining: 14m 16s\n",
      "291:\tlearn: 0.7822559\ttotal: 3m 26s\tremaining: 14m 15s\n",
      "292:\tlearn: 0.7824986\ttotal: 3m 27s\tremaining: 14m 14s\n",
      "293:\tlearn: 0.7825007\ttotal: 3m 28s\tremaining: 14m 14s\n",
      "294:\tlearn: 0.7825388\ttotal: 3m 28s\tremaining: 14m 13s\n",
      "295:\tlearn: 0.7826455\ttotal: 3m 29s\tremaining: 14m 12s\n",
      "296:\tlearn: 0.7827165\ttotal: 3m 30s\tremaining: 14m 12s\n",
      "297:\tlearn: 0.7827838\ttotal: 3m 31s\tremaining: 14m 11s\n",
      "298:\tlearn: 0.7828444\ttotal: 3m 31s\tremaining: 14m 11s\n",
      "299:\tlearn: 0.7827951\ttotal: 3m 32s\tremaining: 14m 10s\n",
      "300:\tlearn: 0.7829226\ttotal: 3m 33s\tremaining: 14m 9s\n",
      "301:\tlearn: 0.7827284\ttotal: 3m 34s\tremaining: 14m 8s\n",
      "302:\tlearn: 0.7828020\ttotal: 3m 34s\tremaining: 14m 8s\n",
      "303:\tlearn: 0.7829037\ttotal: 3m 35s\tremaining: 14m 7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304:\tlearn: 0.7829044\ttotal: 3m 36s\tremaining: 14m 6s\n",
      "305:\tlearn: 0.7829507\ttotal: 3m 36s\tremaining: 14m 5s\n",
      "306:\tlearn: 0.7830015\ttotal: 3m 37s\tremaining: 14m 5s\n",
      "307:\tlearn: 0.7831026\ttotal: 3m 38s\tremaining: 14m 4s\n",
      "308:\tlearn: 0.7831376\ttotal: 3m 38s\tremaining: 14m 3s\n",
      "309:\tlearn: 0.7831596\ttotal: 3m 39s\tremaining: 14m 2s\n",
      "310:\tlearn: 0.7831945\ttotal: 3m 40s\tremaining: 14m 2s\n",
      "311:\tlearn: 0.7833035\ttotal: 3m 40s\tremaining: 14m 1s\n",
      "312:\tlearn: 0.7831950\ttotal: 3m 41s\tremaining: 14m\n",
      "313:\tlearn: 0.7832648\ttotal: 3m 42s\tremaining: 13m 59s\n",
      "314:\tlearn: 0.7833729\ttotal: 3m 43s\tremaining: 13m 59s\n",
      "315:\tlearn: 0.7834154\ttotal: 3m 43s\tremaining: 13m 58s\n",
      "316:\tlearn: 0.7835063\ttotal: 3m 44s\tremaining: 13m 57s\n",
      "317:\tlearn: 0.7834660\ttotal: 3m 45s\tremaining: 13m 56s\n",
      "318:\tlearn: 0.7835672\ttotal: 3m 45s\tremaining: 13m 56s\n",
      "319:\tlearn: 0.7836898\ttotal: 3m 46s\tremaining: 13m 55s\n",
      "320:\tlearn: 0.7837277\ttotal: 3m 47s\tremaining: 13m 54s\n",
      "321:\tlearn: 0.7837881\ttotal: 3m 47s\tremaining: 13m 53s\n",
      "322:\tlearn: 0.7838620\ttotal: 3m 48s\tremaining: 13m 53s\n",
      "323:\tlearn: 0.7839107\ttotal: 3m 49s\tremaining: 13m 52s\n",
      "324:\tlearn: 0.7839108\ttotal: 3m 50s\tremaining: 13m 51s\n",
      "325:\tlearn: 0.7839801\ttotal: 3m 50s\tremaining: 13m 51s\n",
      "326:\tlearn: 0.7839052\ttotal: 3m 51s\tremaining: 13m 50s\n",
      "327:\tlearn: 0.7839127\ttotal: 3m 52s\tremaining: 13m 49s\n",
      "328:\tlearn: 0.7839167\ttotal: 3m 52s\tremaining: 13m 48s\n",
      "329:\tlearn: 0.7840081\ttotal: 3m 53s\tremaining: 13m 47s\n",
      "330:\tlearn: 0.7839352\ttotal: 3m 54s\tremaining: 13m 47s\n",
      "331:\tlearn: 0.7839886\ttotal: 3m 54s\tremaining: 13m 46s\n",
      "332:\tlearn: 0.7839596\ttotal: 3m 55s\tremaining: 13m 45s\n",
      "333:\tlearn: 0.7839474\ttotal: 3m 56s\tremaining: 13m 45s\n",
      "334:\tlearn: 0.7840918\ttotal: 3m 57s\tremaining: 13m 44s\n",
      "335:\tlearn: 0.7842138\ttotal: 3m 57s\tremaining: 13m 43s\n",
      "336:\tlearn: 0.7842033\ttotal: 3m 58s\tremaining: 13m 42s\n",
      "337:\tlearn: 0.7842487\ttotal: 3m 59s\tremaining: 13m 42s\n",
      "338:\tlearn: 0.7843681\ttotal: 3m 59s\tremaining: 13m 41s\n",
      "339:\tlearn: 0.7842669\ttotal: 4m\tremaining: 13m 40s\n",
      "340:\tlearn: 0.7843330\ttotal: 4m 1s\tremaining: 13m 39s\n",
      "341:\tlearn: 0.7845076\ttotal: 4m 1s\tremaining: 13m 39s\n",
      "342:\tlearn: 0.7846325\ttotal: 4m 2s\tremaining: 13m 38s\n",
      "343:\tlearn: 0.7846477\ttotal: 4m 3s\tremaining: 13m 37s\n",
      "344:\tlearn: 0.7847577\ttotal: 4m 4s\tremaining: 13m 37s\n",
      "345:\tlearn: 0.7847822\ttotal: 4m 4s\tremaining: 13m 36s\n",
      "346:\tlearn: 0.7848317\ttotal: 4m 5s\tremaining: 13m 35s\n",
      "347:\tlearn: 0.7848657\ttotal: 4m 6s\tremaining: 13m 34s\n",
      "348:\tlearn: 0.7849250\ttotal: 4m 6s\tremaining: 13m 34s\n",
      "349:\tlearn: 0.7849412\ttotal: 4m 7s\tremaining: 13m 33s\n",
      "350:\tlearn: 0.7849223\ttotal: 4m 8s\tremaining: 13m 32s\n",
      "351:\tlearn: 0.7849516\ttotal: 4m 8s\tremaining: 13m 32s\n",
      "352:\tlearn: 0.7849091\ttotal: 4m 9s\tremaining: 13m 31s\n",
      "353:\tlearn: 0.7849119\ttotal: 4m 10s\tremaining: 13m 30s\n",
      "354:\tlearn: 0.7849898\ttotal: 4m 11s\tremaining: 13m 29s\n",
      "355:\tlearn: 0.7850104\ttotal: 4m 11s\tremaining: 13m 29s\n",
      "356:\tlearn: 0.7850138\ttotal: 4m 12s\tremaining: 13m 28s\n",
      "357:\tlearn: 0.7851241\ttotal: 4m 13s\tremaining: 13m 27s\n",
      "358:\tlearn: 0.7852460\ttotal: 4m 13s\tremaining: 13m 26s\n",
      "359:\tlearn: 0.7852893\ttotal: 4m 14s\tremaining: 13m 26s\n",
      "360:\tlearn: 0.7852753\ttotal: 4m 15s\tremaining: 13m 25s\n",
      "361:\tlearn: 0.7853193\ttotal: 4m 15s\tremaining: 13m 24s\n",
      "362:\tlearn: 0.7853967\ttotal: 4m 16s\tremaining: 13m 24s\n",
      "363:\tlearn: 0.7854163\ttotal: 4m 17s\tremaining: 13m 23s\n",
      "364:\tlearn: 0.7854196\ttotal: 4m 18s\tremaining: 13m 22s\n",
      "365:\tlearn: 0.7854701\ttotal: 4m 18s\tremaining: 13m 21s\n",
      "366:\tlearn: 0.7854696\ttotal: 4m 19s\tremaining: 13m 21s\n",
      "367:\tlearn: 0.7855750\ttotal: 4m 20s\tremaining: 13m 20s\n",
      "368:\tlearn: 0.7856135\ttotal: 4m 20s\tremaining: 13m 19s\n",
      "369:\tlearn: 0.7856981\ttotal: 4m 21s\tremaining: 13m 18s\n",
      "370:\tlearn: 0.7857801\ttotal: 4m 22s\tremaining: 13m 18s\n",
      "371:\tlearn: 0.7857972\ttotal: 4m 23s\tremaining: 13m 17s\n",
      "372:\tlearn: 0.7858032\ttotal: 4m 23s\tremaining: 13m 16s\n",
      "373:\tlearn: 0.7858465\ttotal: 4m 24s\tremaining: 13m 16s\n",
      "374:\tlearn: 0.7860281\ttotal: 4m 25s\tremaining: 13m 15s\n",
      "375:\tlearn: 0.7859876\ttotal: 4m 25s\tremaining: 13m 14s\n",
      "376:\tlearn: 0.7859685\ttotal: 4m 26s\tremaining: 13m 13s\n",
      "377:\tlearn: 0.7860095\ttotal: 4m 27s\tremaining: 13m 13s\n",
      "378:\tlearn: 0.7859861\ttotal: 4m 27s\tremaining: 13m 12s\n",
      "379:\tlearn: 0.7860350\ttotal: 4m 28s\tremaining: 13m 11s\n",
      "380:\tlearn: 0.7860780\ttotal: 4m 29s\tremaining: 13m 10s\n",
      "381:\tlearn: 0.7861205\ttotal: 4m 29s\tremaining: 13m 10s\n",
      "382:\tlearn: 0.7861400\ttotal: 4m 30s\tremaining: 13m 9s\n",
      "383:\tlearn: 0.7860830\ttotal: 4m 31s\tremaining: 13m 8s\n",
      "384:\tlearn: 0.7862114\ttotal: 4m 32s\tremaining: 13m 8s\n",
      "385:\tlearn: 0.7863037\ttotal: 4m 32s\tremaining: 13m 7s\n",
      "386:\tlearn: 0.7863024\ttotal: 4m 33s\tremaining: 13m 6s\n",
      "387:\tlearn: 0.7864133\ttotal: 4m 34s\tremaining: 13m 5s\n",
      "388:\tlearn: 0.7864216\ttotal: 4m 34s\tremaining: 13m 5s\n",
      "389:\tlearn: 0.7865457\ttotal: 4m 35s\tremaining: 13m 4s\n",
      "390:\tlearn: 0.7864641\ttotal: 4m 36s\tremaining: 13m 3s\n",
      "391:\tlearn: 0.7864353\ttotal: 4m 36s\tremaining: 13m 2s\n",
      "392:\tlearn: 0.7863657\ttotal: 4m 37s\tremaining: 13m 2s\n",
      "393:\tlearn: 0.7864442\ttotal: 4m 38s\tremaining: 13m 1s\n",
      "394:\tlearn: 0.7865211\ttotal: 4m 39s\tremaining: 13m\n",
      "395:\tlearn: 0.7864914\ttotal: 4m 39s\tremaining: 12m 59s\n",
      "396:\tlearn: 0.7865473\ttotal: 4m 40s\tremaining: 12m 59s\n",
      "397:\tlearn: 0.7866414\ttotal: 4m 41s\tremaining: 12m 58s\n",
      "398:\tlearn: 0.7866190\ttotal: 4m 41s\tremaining: 12m 57s\n",
      "399:\tlearn: 0.7867136\ttotal: 4m 42s\tremaining: 12m 56s\n",
      "400:\tlearn: 0.7866598\ttotal: 4m 43s\tremaining: 12m 56s\n",
      "401:\tlearn: 0.7868044\ttotal: 4m 43s\tremaining: 12m 55s\n",
      "402:\tlearn: 0.7868765\ttotal: 4m 44s\tremaining: 12m 54s\n",
      "403:\tlearn: 0.7868225\ttotal: 4m 45s\tremaining: 12m 53s\n",
      "404:\tlearn: 0.7869656\ttotal: 4m 45s\tremaining: 12m 53s\n",
      "405:\tlearn: 0.7869405\ttotal: 4m 46s\tremaining: 12m 52s\n",
      "406:\tlearn: 0.7869948\ttotal: 4m 47s\tremaining: 12m 51s\n",
      "407:\tlearn: 0.7869831\ttotal: 4m 48s\tremaining: 12m 51s\n",
      "408:\tlearn: 0.7871410\ttotal: 4m 48s\tremaining: 12m 50s\n",
      "409:\tlearn: 0.7872405\ttotal: 4m 49s\tremaining: 12m 49s\n",
      "410:\tlearn: 0.7872466\ttotal: 4m 50s\tremaining: 12m 48s\n",
      "411:\tlearn: 0.7873379\ttotal: 4m 50s\tremaining: 12m 48s\n",
      "412:\tlearn: 0.7873014\ttotal: 4m 51s\tremaining: 12m 47s\n",
      "413:\tlearn: 0.7872699\ttotal: 4m 52s\tremaining: 12m 46s\n",
      "414:\tlearn: 0.7873224\ttotal: 4m 52s\tremaining: 12m 45s\n",
      "415:\tlearn: 0.7871901\ttotal: 4m 53s\tremaining: 12m 45s\n",
      "416:\tlearn: 0.7871979\ttotal: 4m 54s\tremaining: 12m 44s\n",
      "417:\tlearn: 0.7872133\ttotal: 4m 55s\tremaining: 12m 43s\n",
      "418:\tlearn: 0.7871666\ttotal: 4m 55s\tremaining: 12m 43s\n",
      "419:\tlearn: 0.7872883\ttotal: 4m 56s\tremaining: 12m 42s\n",
      "420:\tlearn: 0.7873970\ttotal: 4m 57s\tremaining: 12m 41s\n",
      "421:\tlearn: 0.7874160\ttotal: 4m 57s\tremaining: 12m 40s\n",
      "422:\tlearn: 0.7874358\ttotal: 4m 58s\tremaining: 12m 40s\n",
      "423:\tlearn: 0.7873826\ttotal: 4m 59s\tremaining: 12m 39s\n",
      "424:\tlearn: 0.7874518\ttotal: 4m 59s\tremaining: 12m 38s\n",
      "425:\tlearn: 0.7874769\ttotal: 5m\tremaining: 12m 37s\n",
      "426:\tlearn: 0.7874865\ttotal: 5m 1s\tremaining: 12m 37s\n",
      "427:\tlearn: 0.7874922\ttotal: 5m 2s\tremaining: 12m 36s\n",
      "428:\tlearn: 0.7874519\ttotal: 5m 2s\tremaining: 12m 35s\n",
      "429:\tlearn: 0.7875558\ttotal: 5m 3s\tremaining: 12m 35s\n",
      "430:\tlearn: 0.7876118\ttotal: 5m 4s\tremaining: 12m 34s\n",
      "431:\tlearn: 0.7876703\ttotal: 5m 4s\tremaining: 12m 33s\n",
      "432:\tlearn: 0.7876069\ttotal: 5m 5s\tremaining: 12m 32s\n",
      "433:\tlearn: 0.7876390\ttotal: 5m 6s\tremaining: 12m 32s\n",
      "434:\tlearn: 0.7877620\ttotal: 5m 6s\tremaining: 12m 31s\n",
      "435:\tlearn: 0.7878701\ttotal: 5m 7s\tremaining: 12m 30s\n",
      "436:\tlearn: 0.7878903\ttotal: 5m 8s\tremaining: 12m 29s\n",
      "437:\tlearn: 0.7879884\ttotal: 5m 9s\tremaining: 12m 29s\n",
      "438:\tlearn: 0.7879966\ttotal: 5m 9s\tremaining: 12m 28s\n",
      "439:\tlearn: 0.7880430\ttotal: 5m 10s\tremaining: 12m 27s\n",
      "440:\tlearn: 0.7880324\ttotal: 5m 11s\tremaining: 12m 27s\n",
      "441:\tlearn: 0.7880398\ttotal: 5m 11s\tremaining: 12m 26s\n",
      "442:\tlearn: 0.7880361\ttotal: 5m 12s\tremaining: 12m 25s\n",
      "443:\tlearn: 0.7881139\ttotal: 5m 13s\tremaining: 12m 24s\n",
      "444:\tlearn: 0.7881130\ttotal: 5m 13s\tremaining: 12m 24s\n",
      "445:\tlearn: 0.7881912\ttotal: 5m 14s\tremaining: 12m 23s\n",
      "446:\tlearn: 0.7881698\ttotal: 5m 15s\tremaining: 12m 22s\n",
      "447:\tlearn: 0.7882106\ttotal: 5m 15s\tremaining: 12m 22s\n",
      "448:\tlearn: 0.7882090\ttotal: 5m 16s\tremaining: 12m 21s\n",
      "449:\tlearn: 0.7881501\ttotal: 5m 17s\tremaining: 12m 20s\n",
      "450:\tlearn: 0.7882023\ttotal: 5m 18s\tremaining: 12m 19s\n",
      "451:\tlearn: 0.7882278\ttotal: 5m 18s\tremaining: 12m 19s\n",
      "452:\tlearn: 0.7883510\ttotal: 5m 19s\tremaining: 12m 18s\n",
      "453:\tlearn: 0.7883435\ttotal: 5m 20s\tremaining: 12m 17s\n",
      "454:\tlearn: 0.7883452\ttotal: 5m 20s\tremaining: 12m 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455:\tlearn: 0.7884248\ttotal: 5m 21s\tremaining: 12m 16s\n",
      "456:\tlearn: 0.7885619\ttotal: 5m 22s\tremaining: 12m 15s\n",
      "457:\tlearn: 0.7886240\ttotal: 5m 22s\tremaining: 12m 14s\n",
      "458:\tlearn: 0.7886417\ttotal: 5m 23s\tremaining: 12m 14s\n",
      "459:\tlearn: 0.7886769\ttotal: 5m 24s\tremaining: 12m 13s\n",
      "460:\tlearn: 0.7886554\ttotal: 5m 25s\tremaining: 12m 12s\n",
      "461:\tlearn: 0.7887618\ttotal: 5m 25s\tremaining: 12m 11s\n",
      "462:\tlearn: 0.7887021\ttotal: 5m 26s\tremaining: 12m 11s\n",
      "463:\tlearn: 0.7886979\ttotal: 5m 27s\tremaining: 12m 10s\n",
      "464:\tlearn: 0.7886487\ttotal: 5m 27s\tremaining: 12m 9s\n",
      "465:\tlearn: 0.7886102\ttotal: 5m 28s\tremaining: 12m 8s\n",
      "466:\tlearn: 0.7886344\ttotal: 5m 29s\tremaining: 12m 8s\n",
      "467:\tlearn: 0.7886299\ttotal: 5m 29s\tremaining: 12m 7s\n",
      "468:\tlearn: 0.7886164\ttotal: 5m 30s\tremaining: 12m 6s\n",
      "469:\tlearn: 0.7885904\ttotal: 5m 31s\tremaining: 12m 5s\n",
      "470:\tlearn: 0.7886346\ttotal: 5m 31s\tremaining: 12m 5s\n",
      "471:\tlearn: 0.7885959\ttotal: 5m 32s\tremaining: 12m 4s\n",
      "472:\tlearn: 0.7886678\ttotal: 5m 33s\tremaining: 12m 3s\n",
      "473:\tlearn: 0.7887406\ttotal: 5m 33s\tremaining: 12m 2s\n",
      "474:\tlearn: 0.7886950\ttotal: 5m 34s\tremaining: 12m 2s\n",
      "475:\tlearn: 0.7886793\ttotal: 5m 35s\tremaining: 12m 1s\n",
      "476:\tlearn: 0.7888338\ttotal: 5m 36s\tremaining: 12m\n",
      "477:\tlearn: 0.7888070\ttotal: 5m 36s\tremaining: 11m 59s\n",
      "478:\tlearn: 0.7889099\ttotal: 5m 37s\tremaining: 11m 59s\n",
      "479:\tlearn: 0.7889245\ttotal: 5m 38s\tremaining: 11m 58s\n",
      "480:\tlearn: 0.7889097\ttotal: 5m 38s\tremaining: 11m 57s\n",
      "481:\tlearn: 0.7890099\ttotal: 5m 39s\tremaining: 11m 57s\n",
      "482:\tlearn: 0.7890880\ttotal: 5m 40s\tremaining: 11m 56s\n",
      "483:\tlearn: 0.7892760\ttotal: 5m 40s\tremaining: 11m 55s\n",
      "484:\tlearn: 0.7892944\ttotal: 5m 41s\tremaining: 11m 55s\n",
      "485:\tlearn: 0.7892946\ttotal: 5m 42s\tremaining: 11m 54s\n",
      "486:\tlearn: 0.7892957\ttotal: 5m 43s\tremaining: 11m 53s\n",
      "487:\tlearn: 0.7893376\ttotal: 5m 43s\tremaining: 11m 52s\n",
      "488:\tlearn: 0.7892985\ttotal: 5m 44s\tremaining: 11m 52s\n",
      "489:\tlearn: 0.7893504\ttotal: 5m 45s\tremaining: 11m 51s\n",
      "490:\tlearn: 0.7893690\ttotal: 5m 45s\tremaining: 11m 50s\n",
      "491:\tlearn: 0.7893317\ttotal: 5m 46s\tremaining: 11m 49s\n",
      "492:\tlearn: 0.7893304\ttotal: 5m 47s\tremaining: 11m 49s\n",
      "493:\tlearn: 0.7892578\ttotal: 5m 47s\tremaining: 11m 48s\n",
      "494:\tlearn: 0.7893443\ttotal: 5m 48s\tremaining: 11m 47s\n",
      "495:\tlearn: 0.7894235\ttotal: 5m 49s\tremaining: 11m 46s\n",
      "496:\tlearn: 0.7894595\ttotal: 5m 49s\tremaining: 11m 46s\n",
      "497:\tlearn: 0.7894989\ttotal: 5m 50s\tremaining: 11m 45s\n",
      "498:\tlearn: 0.7894960\ttotal: 5m 51s\tremaining: 11m 44s\n",
      "499:\tlearn: 0.7895210\ttotal: 5m 52s\tremaining: 11m 44s\n",
      "500:\tlearn: 0.7895765\ttotal: 5m 52s\tremaining: 11m 43s\n",
      "501:\tlearn: 0.7896555\ttotal: 5m 53s\tremaining: 11m 42s\n",
      "502:\tlearn: 0.7897194\ttotal: 5m 54s\tremaining: 11m 41s\n",
      "503:\tlearn: 0.7896474\ttotal: 5m 54s\tremaining: 11m 41s\n",
      "504:\tlearn: 0.7896488\ttotal: 5m 55s\tremaining: 11m 40s\n",
      "505:\tlearn: 0.7897962\ttotal: 5m 56s\tremaining: 11m 39s\n",
      "506:\tlearn: 0.7897697\ttotal: 5m 56s\tremaining: 11m 39s\n",
      "507:\tlearn: 0.7898163\ttotal: 5m 57s\tremaining: 11m 38s\n",
      "508:\tlearn: 0.7898877\ttotal: 5m 58s\tremaining: 11m 37s\n",
      "509:\tlearn: 0.7898597\ttotal: 5m 59s\tremaining: 11m 37s\n",
      "510:\tlearn: 0.7898496\ttotal: 5m 59s\tremaining: 11m 36s\n",
      "511:\tlearn: 0.7899124\ttotal: 6m\tremaining: 11m 35s\n",
      "512:\tlearn: 0.7900217\ttotal: 6m 1s\tremaining: 11m 34s\n",
      "513:\tlearn: 0.7900007\ttotal: 6m 1s\tremaining: 11m 34s\n",
      "514:\tlearn: 0.7900471\ttotal: 6m 2s\tremaining: 11m 33s\n",
      "515:\tlearn: 0.7900479\ttotal: 6m 3s\tremaining: 11m 32s\n",
      "516:\tlearn: 0.7900580\ttotal: 6m 3s\tremaining: 11m 32s\n",
      "517:\tlearn: 0.7901142\ttotal: 6m 4s\tremaining: 11m 31s\n",
      "518:\tlearn: 0.7900999\ttotal: 6m 5s\tremaining: 11m 30s\n",
      "519:\tlearn: 0.7901630\ttotal: 6m 6s\tremaining: 11m 29s\n",
      "520:\tlearn: 0.7901482\ttotal: 6m 6s\tremaining: 11m 29s\n",
      "521:\tlearn: 0.7901434\ttotal: 6m 7s\tremaining: 11m 28s\n",
      "522:\tlearn: 0.7900599\ttotal: 6m 8s\tremaining: 11m 27s\n",
      "523:\tlearn: 0.7901699\ttotal: 6m 8s\tremaining: 11m 27s\n",
      "524:\tlearn: 0.7903292\ttotal: 6m 9s\tremaining: 11m 26s\n",
      "525:\tlearn: 0.7902534\ttotal: 6m 10s\tremaining: 11m 25s\n",
      "526:\tlearn: 0.7902165\ttotal: 6m 11s\tremaining: 11m 24s\n",
      "527:\tlearn: 0.7902448\ttotal: 6m 11s\tremaining: 11m 24s\n",
      "528:\tlearn: 0.7904042\ttotal: 6m 12s\tremaining: 11m 23s\n",
      "529:\tlearn: 0.7903580\ttotal: 6m 13s\tremaining: 11m 22s\n",
      "530:\tlearn: 0.7904794\ttotal: 6m 13s\tremaining: 11m 22s\n",
      "531:\tlearn: 0.7904693\ttotal: 6m 14s\tremaining: 11m 21s\n",
      "532:\tlearn: 0.7905906\ttotal: 6m 15s\tremaining: 11m 20s\n",
      "533:\tlearn: 0.7906411\ttotal: 6m 15s\tremaining: 11m 20s\n",
      "534:\tlearn: 0.7906940\ttotal: 6m 16s\tremaining: 11m 19s\n",
      "535:\tlearn: 0.7906218\ttotal: 6m 17s\tremaining: 11m 18s\n",
      "536:\tlearn: 0.7906112\ttotal: 6m 18s\tremaining: 11m 17s\n",
      "537:\tlearn: 0.7905952\ttotal: 6m 18s\tremaining: 11m 17s\n",
      "538:\tlearn: 0.7906520\ttotal: 6m 19s\tremaining: 11m 16s\n",
      "539:\tlearn: 0.7907029\ttotal: 6m 20s\tremaining: 11m 15s\n",
      "540:\tlearn: 0.7907989\ttotal: 6m 20s\tremaining: 11m 15s\n",
      "541:\tlearn: 0.7907761\ttotal: 6m 21s\tremaining: 11m 14s\n",
      "542:\tlearn: 0.7908279\ttotal: 6m 22s\tremaining: 11m 13s\n",
      "543:\tlearn: 0.7908466\ttotal: 6m 22s\tremaining: 11m 13s\n",
      "544:\tlearn: 0.7908656\ttotal: 6m 23s\tremaining: 11m 12s\n",
      "545:\tlearn: 0.7909728\ttotal: 6m 24s\tremaining: 11m 11s\n",
      "546:\tlearn: 0.7909576\ttotal: 6m 25s\tremaining: 11m 10s\n",
      "547:\tlearn: 0.7909545\ttotal: 6m 25s\tremaining: 11m 10s\n",
      "548:\tlearn: 0.7909611\ttotal: 6m 26s\tremaining: 11m 9s\n",
      "549:\tlearn: 0.7909448\ttotal: 6m 27s\tremaining: 11m 8s\n",
      "550:\tlearn: 0.7909839\ttotal: 6m 27s\tremaining: 11m 8s\n",
      "551:\tlearn: 0.7909816\ttotal: 6m 28s\tremaining: 11m 7s\n",
      "552:\tlearn: 0.7910412\ttotal: 6m 29s\tremaining: 11m 6s\n",
      "553:\tlearn: 0.7910926\ttotal: 6m 29s\tremaining: 11m 5s\n",
      "554:\tlearn: 0.7911156\ttotal: 6m 30s\tremaining: 11m 5s\n",
      "555:\tlearn: 0.7911441\ttotal: 6m 31s\tremaining: 11m 4s\n",
      "556:\tlearn: 0.7911619\ttotal: 6m 32s\tremaining: 11m 3s\n",
      "557:\tlearn: 0.7911502\ttotal: 6m 32s\tremaining: 11m 3s\n",
      "558:\tlearn: 0.7912068\ttotal: 6m 33s\tremaining: 11m 2s\n",
      "559:\tlearn: 0.7911571\ttotal: 6m 34s\tremaining: 11m 1s\n",
      "560:\tlearn: 0.7912483\ttotal: 6m 34s\tremaining: 11m\n",
      "561:\tlearn: 0.7913969\ttotal: 6m 35s\tremaining: 11m\n",
      "562:\tlearn: 0.7913133\ttotal: 6m 36s\tremaining: 10m 59s\n",
      "563:\tlearn: 0.7913702\ttotal: 6m 36s\tremaining: 10m 58s\n",
      "564:\tlearn: 0.7915161\ttotal: 6m 37s\tremaining: 10m 58s\n",
      "565:\tlearn: 0.7915317\ttotal: 6m 38s\tremaining: 10m 57s\n",
      "566:\tlearn: 0.7914422\ttotal: 6m 39s\tremaining: 10m 56s\n",
      "567:\tlearn: 0.7914534\ttotal: 6m 39s\tremaining: 10m 55s\n",
      "568:\tlearn: 0.7915395\ttotal: 6m 40s\tremaining: 10m 55s\n",
      "569:\tlearn: 0.7915448\ttotal: 6m 41s\tremaining: 10m 54s\n",
      "570:\tlearn: 0.7915673\ttotal: 6m 41s\tremaining: 10m 53s\n",
      "571:\tlearn: 0.7915305\ttotal: 6m 42s\tremaining: 10m 53s\n",
      "572:\tlearn: 0.7915742\ttotal: 6m 43s\tremaining: 10m 52s\n",
      "573:\tlearn: 0.7915794\ttotal: 6m 43s\tremaining: 10m 51s\n",
      "574:\tlearn: 0.7915745\ttotal: 6m 44s\tremaining: 10m 50s\n",
      "575:\tlearn: 0.7916040\ttotal: 6m 45s\tremaining: 10m 50s\n",
      "576:\tlearn: 0.7916425\ttotal: 6m 45s\tremaining: 10m 49s\n",
      "577:\tlearn: 0.7916779\ttotal: 6m 46s\tremaining: 10m 48s\n",
      "578:\tlearn: 0.7917757\ttotal: 6m 47s\tremaining: 10m 48s\n",
      "579:\tlearn: 0.7917418\ttotal: 6m 48s\tremaining: 10m 47s\n",
      "580:\tlearn: 0.7917416\ttotal: 6m 48s\tremaining: 10m 46s\n",
      "581:\tlearn: 0.7918390\ttotal: 6m 49s\tremaining: 10m 45s\n",
      "582:\tlearn: 0.7917796\ttotal: 6m 50s\tremaining: 10m 45s\n",
      "583:\tlearn: 0.7918874\ttotal: 6m 50s\tremaining: 10m 44s\n",
      "584:\tlearn: 0.7919328\ttotal: 6m 51s\tremaining: 10m 43s\n",
      "585:\tlearn: 0.7919879\ttotal: 6m 52s\tremaining: 10m 42s\n",
      "586:\tlearn: 0.7919378\ttotal: 6m 52s\tremaining: 10m 42s\n",
      "587:\tlearn: 0.7920510\ttotal: 6m 53s\tremaining: 10m 41s\n",
      "588:\tlearn: 0.7920232\ttotal: 6m 54s\tremaining: 10m 40s\n",
      "589:\tlearn: 0.7920666\ttotal: 6m 54s\tremaining: 10m 40s\n",
      "590:\tlearn: 0.7921177\ttotal: 6m 55s\tremaining: 10m 39s\n",
      "591:\tlearn: 0.7921510\ttotal: 6m 56s\tremaining: 10m 38s\n",
      "592:\tlearn: 0.7922521\ttotal: 6m 57s\tremaining: 10m 37s\n",
      "593:\tlearn: 0.7922661\ttotal: 6m 57s\tremaining: 10m 37s\n",
      "594:\tlearn: 0.7922744\ttotal: 6m 58s\tremaining: 10m 36s\n",
      "595:\tlearn: 0.7923426\ttotal: 6m 59s\tremaining: 10m 35s\n",
      "596:\tlearn: 0.7923149\ttotal: 6m 59s\tremaining: 10m 35s\n",
      "597:\tlearn: 0.7923377\ttotal: 7m\tremaining: 10m 34s\n",
      "598:\tlearn: 0.7922989\ttotal: 7m 1s\tremaining: 10m 33s\n",
      "599:\tlearn: 0.7923899\ttotal: 7m 2s\tremaining: 10m 33s\n",
      "600:\tlearn: 0.7923445\ttotal: 7m 2s\tremaining: 10m 32s\n",
      "601:\tlearn: 0.7923099\ttotal: 7m 3s\tremaining: 10m 31s\n",
      "602:\tlearn: 0.7923604\ttotal: 7m 4s\tremaining: 10m 30s\n",
      "603:\tlearn: 0.7924623\ttotal: 7m 4s\tremaining: 10m 30s\n",
      "604:\tlearn: 0.7924054\ttotal: 7m 5s\tremaining: 10m 29s\n",
      "605:\tlearn: 0.7925470\ttotal: 7m 6s\tremaining: 10m 28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606:\tlearn: 0.7925446\ttotal: 7m 6s\tremaining: 10m 28s\n",
      "607:\tlearn: 0.7925068\ttotal: 7m 7s\tremaining: 10m 27s\n",
      "608:\tlearn: 0.7925254\ttotal: 7m 8s\tremaining: 10m 26s\n",
      "609:\tlearn: 0.7925842\ttotal: 7m 9s\tremaining: 10m 26s\n",
      "610:\tlearn: 0.7926071\ttotal: 7m 9s\tremaining: 10m 25s\n",
      "611:\tlearn: 0.7926534\ttotal: 7m 10s\tremaining: 10m 24s\n",
      "612:\tlearn: 0.7927176\ttotal: 7m 11s\tremaining: 10m 23s\n",
      "613:\tlearn: 0.7926248\ttotal: 7m 11s\tremaining: 10m 23s\n",
      "614:\tlearn: 0.7927655\ttotal: 7m 12s\tremaining: 10m 22s\n",
      "615:\tlearn: 0.7926864\ttotal: 7m 13s\tremaining: 10m 21s\n",
      "616:\tlearn: 0.7927773\ttotal: 7m 14s\tremaining: 10m 21s\n",
      "617:\tlearn: 0.7927994\ttotal: 7m 14s\tremaining: 10m 20s\n",
      "618:\tlearn: 0.7929119\ttotal: 7m 15s\tremaining: 10m 19s\n",
      "619:\tlearn: 0.7927820\ttotal: 7m 16s\tremaining: 10m 19s\n",
      "620:\tlearn: 0.7928141\ttotal: 7m 16s\tremaining: 10m 18s\n",
      "621:\tlearn: 0.7928192\ttotal: 7m 17s\tremaining: 10m 17s\n",
      "622:\tlearn: 0.7927637\ttotal: 7m 18s\tremaining: 10m 16s\n",
      "623:\tlearn: 0.7928011\ttotal: 7m 18s\tremaining: 10m 16s\n",
      "624:\tlearn: 0.7928763\ttotal: 7m 19s\tremaining: 10m 15s\n",
      "625:\tlearn: 0.7929200\ttotal: 7m 20s\tremaining: 10m 14s\n",
      "626:\tlearn: 0.7929089\ttotal: 7m 21s\tremaining: 10m 14s\n",
      "627:\tlearn: 0.7929714\ttotal: 7m 21s\tremaining: 10m 13s\n",
      "628:\tlearn: 0.7930337\ttotal: 7m 22s\tremaining: 10m 12s\n",
      "629:\tlearn: 0.7930798\ttotal: 7m 23s\tremaining: 10m 12s\n",
      "630:\tlearn: 0.7930236\ttotal: 7m 23s\tremaining: 10m 11s\n",
      "631:\tlearn: 0.7930301\ttotal: 7m 24s\tremaining: 10m 10s\n",
      "632:\tlearn: 0.7930696\ttotal: 7m 25s\tremaining: 10m 9s\n",
      "633:\tlearn: 0.7930641\ttotal: 7m 26s\tremaining: 10m 9s\n",
      "634:\tlearn: 0.7931716\ttotal: 7m 26s\tremaining: 10m 8s\n",
      "635:\tlearn: 0.7931448\ttotal: 7m 27s\tremaining: 10m 7s\n",
      "636:\tlearn: 0.7931700\ttotal: 7m 28s\tremaining: 10m 7s\n",
      "637:\tlearn: 0.7932321\ttotal: 7m 28s\tremaining: 10m 6s\n",
      "638:\tlearn: 0.7932873\ttotal: 7m 29s\tremaining: 10m 5s\n",
      "639:\tlearn: 0.7932088\ttotal: 7m 30s\tremaining: 10m 4s\n",
      "640:\tlearn: 0.7931244\ttotal: 7m 30s\tremaining: 10m 4s\n",
      "641:\tlearn: 0.7932083\ttotal: 7m 31s\tremaining: 10m 3s\n",
      "642:\tlearn: 0.7931539\ttotal: 7m 32s\tremaining: 10m 2s\n",
      "643:\tlearn: 0.7932262\ttotal: 7m 33s\tremaining: 10m 2s\n",
      "644:\tlearn: 0.7933014\ttotal: 7m 33s\tremaining: 10m 1s\n",
      "645:\tlearn: 0.7932673\ttotal: 7m 34s\tremaining: 10m\n",
      "646:\tlearn: 0.7932784\ttotal: 7m 35s\tremaining: 10m\n",
      "647:\tlearn: 0.7933107\ttotal: 7m 35s\tremaining: 9m 59s\n",
      "648:\tlearn: 0.7933560\ttotal: 7m 36s\tremaining: 9m 58s\n",
      "649:\tlearn: 0.7933046\ttotal: 7m 37s\tremaining: 9m 57s\n",
      "650:\tlearn: 0.7933114\ttotal: 7m 37s\tremaining: 9m 57s\n",
      "651:\tlearn: 0.7933845\ttotal: 7m 38s\tremaining: 9m 56s\n",
      "652:\tlearn: 0.7935077\ttotal: 7m 39s\tremaining: 9m 55s\n",
      "653:\tlearn: 0.7934175\ttotal: 7m 40s\tremaining: 9m 55s\n",
      "654:\tlearn: 0.7935075\ttotal: 7m 40s\tremaining: 9m 54s\n",
      "655:\tlearn: 0.7934407\ttotal: 7m 41s\tremaining: 9m 53s\n",
      "656:\tlearn: 0.7935033\ttotal: 7m 42s\tremaining: 9m 52s\n",
      "657:\tlearn: 0.7935420\ttotal: 7m 42s\tremaining: 9m 52s\n",
      "658:\tlearn: 0.7935309\ttotal: 7m 43s\tremaining: 9m 51s\n",
      "659:\tlearn: 0.7934733\ttotal: 7m 44s\tremaining: 9m 50s\n",
      "660:\tlearn: 0.7935747\ttotal: 7m 44s\tremaining: 9m 50s\n",
      "661:\tlearn: 0.7935822\ttotal: 7m 45s\tremaining: 9m 49s\n",
      "662:\tlearn: 0.7936611\ttotal: 7m 46s\tremaining: 9m 48s\n",
      "663:\tlearn: 0.7937133\ttotal: 7m 47s\tremaining: 9m 47s\n",
      "664:\tlearn: 0.7937349\ttotal: 7m 47s\tremaining: 9m 47s\n",
      "665:\tlearn: 0.7937043\ttotal: 7m 48s\tremaining: 9m 46s\n",
      "666:\tlearn: 0.7937496\ttotal: 7m 49s\tremaining: 9m 45s\n",
      "667:\tlearn: 0.7937953\ttotal: 7m 49s\tremaining: 9m 45s\n",
      "668:\tlearn: 0.7938259\ttotal: 7m 50s\tremaining: 9m 44s\n",
      "669:\tlearn: 0.7938141\ttotal: 7m 51s\tremaining: 9m 43s\n",
      "670:\tlearn: 0.7937865\ttotal: 7m 51s\tremaining: 9m 43s\n",
      "671:\tlearn: 0.7939974\ttotal: 7m 52s\tremaining: 9m 42s\n",
      "672:\tlearn: 0.7939701\ttotal: 7m 53s\tremaining: 9m 41s\n",
      "673:\tlearn: 0.7940833\ttotal: 7m 54s\tremaining: 9m 40s\n",
      "674:\tlearn: 0.7940104\ttotal: 7m 54s\tremaining: 9m 40s\n",
      "675:\tlearn: 0.7940831\ttotal: 7m 55s\tremaining: 9m 39s\n",
      "676:\tlearn: 0.7940610\ttotal: 7m 56s\tremaining: 9m 38s\n",
      "677:\tlearn: 0.7940616\ttotal: 7m 56s\tremaining: 9m 38s\n",
      "678:\tlearn: 0.7940218\ttotal: 7m 57s\tremaining: 9m 37s\n",
      "679:\tlearn: 0.7940225\ttotal: 7m 58s\tremaining: 9m 36s\n",
      "680:\tlearn: 0.7940823\ttotal: 7m 58s\tremaining: 9m 35s\n",
      "681:\tlearn: 0.7940281\ttotal: 7m 59s\tremaining: 9m 35s\n",
      "682:\tlearn: 0.7940778\ttotal: 8m\tremaining: 9m 34s\n",
      "683:\tlearn: 0.7940895\ttotal: 8m\tremaining: 9m 33s\n",
      "684:\tlearn: 0.7941287\ttotal: 8m 1s\tremaining: 9m 33s\n",
      "685:\tlearn: 0.7941746\ttotal: 8m 2s\tremaining: 9m 32s\n",
      "686:\tlearn: 0.7941518\ttotal: 8m 3s\tremaining: 9m 31s\n",
      "687:\tlearn: 0.7942027\ttotal: 8m 3s\tremaining: 9m 30s\n",
      "688:\tlearn: 0.7941573\ttotal: 8m 4s\tremaining: 9m 30s\n",
      "689:\tlearn: 0.7942076\ttotal: 8m 5s\tremaining: 9m 29s\n",
      "690:\tlearn: 0.7942587\ttotal: 8m 5s\tremaining: 9m 28s\n",
      "691:\tlearn: 0.7942757\ttotal: 8m 6s\tremaining: 9m 28s\n",
      "692:\tlearn: 0.7942574\ttotal: 8m 7s\tremaining: 9m 27s\n",
      "693:\tlearn: 0.7943045\ttotal: 8m 7s\tremaining: 9m 26s\n",
      "694:\tlearn: 0.7943285\ttotal: 8m 8s\tremaining: 9m 25s\n",
      "695:\tlearn: 0.7944075\ttotal: 8m 9s\tremaining: 9m 25s\n",
      "696:\tlearn: 0.7944295\ttotal: 8m 10s\tremaining: 9m 24s\n",
      "697:\tlearn: 0.7944220\ttotal: 8m 10s\tremaining: 9m 23s\n",
      "698:\tlearn: 0.7944427\ttotal: 8m 11s\tremaining: 9m 23s\n",
      "699:\tlearn: 0.7944514\ttotal: 8m 12s\tremaining: 9m 22s\n",
      "700:\tlearn: 0.7945073\ttotal: 8m 12s\tremaining: 9m 21s\n",
      "701:\tlearn: 0.7944218\ttotal: 8m 13s\tremaining: 9m 20s\n",
      "702:\tlearn: 0.7945410\ttotal: 8m 14s\tremaining: 9m 20s\n",
      "703:\tlearn: 0.7946134\ttotal: 8m 14s\tremaining: 9m 19s\n",
      "704:\tlearn: 0.7946055\ttotal: 8m 15s\tremaining: 9m 18s\n",
      "705:\tlearn: 0.7946214\ttotal: 8m 16s\tremaining: 9m 18s\n",
      "706:\tlearn: 0.7947318\ttotal: 8m 16s\tremaining: 9m 17s\n",
      "707:\tlearn: 0.7946523\ttotal: 8m 17s\tremaining: 9m 16s\n",
      "708:\tlearn: 0.7946643\ttotal: 8m 18s\tremaining: 9m 16s\n",
      "709:\tlearn: 0.7947273\ttotal: 8m 19s\tremaining: 9m 15s\n",
      "710:\tlearn: 0.7946625\ttotal: 8m 19s\tremaining: 9m 14s\n",
      "711:\tlearn: 0.7946508\ttotal: 8m 20s\tremaining: 9m 13s\n",
      "712:\tlearn: 0.7947589\ttotal: 8m 21s\tremaining: 9m 13s\n",
      "713:\tlearn: 0.7948090\ttotal: 8m 21s\tremaining: 9m 12s\n",
      "714:\tlearn: 0.7948295\ttotal: 8m 22s\tremaining: 9m 11s\n",
      "715:\tlearn: 0.7949192\ttotal: 8m 23s\tremaining: 9m 11s\n",
      "716:\tlearn: 0.7949076\ttotal: 8m 23s\tremaining: 9m 10s\n",
      "717:\tlearn: 0.7948453\ttotal: 8m 24s\tremaining: 9m 9s\n",
      "718:\tlearn: 0.7948383\ttotal: 8m 25s\tremaining: 9m 8s\n",
      "719:\tlearn: 0.7949557\ttotal: 8m 26s\tremaining: 9m 8s\n",
      "720:\tlearn: 0.7949653\ttotal: 8m 26s\tremaining: 9m 7s\n",
      "721:\tlearn: 0.7949763\ttotal: 8m 27s\tremaining: 9m 6s\n",
      "722:\tlearn: 0.7949982\ttotal: 8m 28s\tremaining: 9m 6s\n",
      "723:\tlearn: 0.7950118\ttotal: 8m 28s\tremaining: 9m 5s\n",
      "724:\tlearn: 0.7950843\ttotal: 8m 29s\tremaining: 9m 4s\n",
      "725:\tlearn: 0.7951246\ttotal: 8m 30s\tremaining: 9m 3s\n",
      "726:\tlearn: 0.7951412\ttotal: 8m 30s\tremaining: 9m 3s\n",
      "727:\tlearn: 0.7951289\ttotal: 8m 31s\tremaining: 9m 2s\n",
      "728:\tlearn: 0.7951779\ttotal: 8m 32s\tremaining: 9m 1s\n",
      "729:\tlearn: 0.7952439\ttotal: 8m 32s\tremaining: 9m 1s\n",
      "730:\tlearn: 0.7952543\ttotal: 8m 33s\tremaining: 9m\n",
      "731:\tlearn: 0.7952757\ttotal: 8m 34s\tremaining: 8m 59s\n",
      "732:\tlearn: 0.7953255\ttotal: 8m 35s\tremaining: 8m 58s\n",
      "733:\tlearn: 0.7953106\ttotal: 8m 35s\tremaining: 8m 58s\n",
      "734:\tlearn: 0.7953282\ttotal: 8m 36s\tremaining: 8m 57s\n",
      "735:\tlearn: 0.7953569\ttotal: 8m 37s\tremaining: 8m 56s\n",
      "736:\tlearn: 0.7953685\ttotal: 8m 37s\tremaining: 8m 56s\n",
      "737:\tlearn: 0.7952471\ttotal: 8m 38s\tremaining: 8m 55s\n",
      "738:\tlearn: 0.7952909\ttotal: 8m 39s\tremaining: 8m 54s\n",
      "739:\tlearn: 0.7953470\ttotal: 8m 39s\tremaining: 8m 54s\n",
      "740:\tlearn: 0.7953645\ttotal: 8m 40s\tremaining: 8m 53s\n",
      "741:\tlearn: 0.7954161\ttotal: 8m 41s\tremaining: 8m 52s\n",
      "742:\tlearn: 0.7954205\ttotal: 8m 42s\tremaining: 8m 51s\n",
      "743:\tlearn: 0.7953310\ttotal: 8m 42s\tremaining: 8m 51s\n",
      "744:\tlearn: 0.7953974\ttotal: 8m 43s\tremaining: 8m 50s\n",
      "745:\tlearn: 0.7954537\ttotal: 8m 44s\tremaining: 8m 49s\n",
      "746:\tlearn: 0.7954397\ttotal: 8m 44s\tremaining: 8m 49s\n",
      "747:\tlearn: 0.7954953\ttotal: 8m 45s\tremaining: 8m 48s\n",
      "748:\tlearn: 0.7954101\ttotal: 8m 46s\tremaining: 8m 47s\n",
      "749:\tlearn: 0.7953909\ttotal: 8m 46s\tremaining: 8m 46s\n",
      "750:\tlearn: 0.7955692\ttotal: 8m 47s\tremaining: 8m 46s\n",
      "751:\tlearn: 0.7955446\ttotal: 8m 48s\tremaining: 8m 45s\n",
      "752:\tlearn: 0.7954446\ttotal: 8m 48s\tremaining: 8m 44s\n",
      "753:\tlearn: 0.7954289\ttotal: 8m 49s\tremaining: 8m 44s\n",
      "754:\tlearn: 0.7954898\ttotal: 8m 50s\tremaining: 8m 43s\n",
      "755:\tlearn: 0.7955005\ttotal: 8m 51s\tremaining: 8m 42s\n",
      "756:\tlearn: 0.7955730\ttotal: 8m 51s\tremaining: 8m 41s\n",
      "757:\tlearn: 0.7955636\ttotal: 8m 52s\tremaining: 8m 41s\n",
      "758:\tlearn: 0.7956471\ttotal: 8m 53s\tremaining: 8m 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759:\tlearn: 0.7956429\ttotal: 8m 53s\tremaining: 8m 39s\n",
      "760:\tlearn: 0.7957100\ttotal: 8m 54s\tremaining: 8m 39s\n",
      "761:\tlearn: 0.7956753\ttotal: 8m 55s\tremaining: 8m 38s\n",
      "762:\tlearn: 0.7958334\ttotal: 8m 55s\tremaining: 8m 37s\n",
      "763:\tlearn: 0.7958823\ttotal: 8m 56s\tremaining: 8m 36s\n",
      "764:\tlearn: 0.7958593\ttotal: 8m 57s\tremaining: 8m 36s\n",
      "765:\tlearn: 0.7959096\ttotal: 8m 58s\tremaining: 8m 35s\n",
      "766:\tlearn: 0.7959041\ttotal: 8m 58s\tremaining: 8m 34s\n",
      "767:\tlearn: 0.7958980\ttotal: 8m 59s\tremaining: 8m 34s\n",
      "768:\tlearn: 0.7958937\ttotal: 9m\tremaining: 8m 33s\n",
      "769:\tlearn: 0.7958768\ttotal: 9m\tremaining: 8m 32s\n",
      "770:\tlearn: 0.7958759\ttotal: 9m 1s\tremaining: 8m 31s\n",
      "771:\tlearn: 0.7958743\ttotal: 9m 2s\tremaining: 8m 31s\n",
      "772:\tlearn: 0.7959986\ttotal: 9m 2s\tremaining: 8m 30s\n",
      "773:\tlearn: 0.7961184\ttotal: 9m 3s\tremaining: 8m 29s\n",
      "774:\tlearn: 0.7960947\ttotal: 9m 4s\tremaining: 8m 29s\n",
      "775:\tlearn: 0.7960829\ttotal: 9m 4s\tremaining: 8m 28s\n",
      "776:\tlearn: 0.7960428\ttotal: 9m 5s\tremaining: 8m 27s\n",
      "777:\tlearn: 0.7961885\ttotal: 9m 6s\tremaining: 8m 27s\n",
      "778:\tlearn: 0.7962045\ttotal: 9m 7s\tremaining: 8m 26s\n",
      "779:\tlearn: 0.7962875\ttotal: 9m 7s\tremaining: 8m 25s\n",
      "780:\tlearn: 0.7963770\ttotal: 9m 8s\tremaining: 8m 24s\n",
      "781:\tlearn: 0.7963166\ttotal: 9m 9s\tremaining: 8m 24s\n",
      "782:\tlearn: 0.7962655\ttotal: 9m 9s\tremaining: 8m 23s\n",
      "783:\tlearn: 0.7962643\ttotal: 9m 10s\tremaining: 8m 22s\n",
      "784:\tlearn: 0.7963158\ttotal: 9m 11s\tremaining: 8m 22s\n",
      "785:\tlearn: 0.7963601\ttotal: 9m 11s\tremaining: 8m 21s\n",
      "786:\tlearn: 0.7963541\ttotal: 9m 12s\tremaining: 8m 20s\n",
      "787:\tlearn: 0.7963891\ttotal: 9m 13s\tremaining: 8m 19s\n",
      "788:\tlearn: 0.7963153\ttotal: 9m 14s\tremaining: 8m 19s\n",
      "789:\tlearn: 0.7963036\ttotal: 9m 14s\tremaining: 8m 18s\n",
      "790:\tlearn: 0.7963248\ttotal: 9m 15s\tremaining: 8m 17s\n",
      "791:\tlearn: 0.7963543\ttotal: 9m 16s\tremaining: 8m 17s\n",
      "792:\tlearn: 0.7963810\ttotal: 9m 16s\tremaining: 8m 16s\n",
      "793:\tlearn: 0.7963517\ttotal: 9m 17s\tremaining: 8m 15s\n",
      "794:\tlearn: 0.7963982\ttotal: 9m 18s\tremaining: 8m 15s\n",
      "795:\tlearn: 0.7964994\ttotal: 9m 18s\tremaining: 8m 14s\n",
      "796:\tlearn: 0.7964189\ttotal: 9m 19s\tremaining: 8m 13s\n",
      "797:\tlearn: 0.7964762\ttotal: 9m 20s\tremaining: 8m 12s\n",
      "798:\tlearn: 0.7965665\ttotal: 9m 21s\tremaining: 8m 12s\n",
      "799:\tlearn: 0.7965225\ttotal: 9m 21s\tremaining: 8m 11s\n",
      "800:\tlearn: 0.7966219\ttotal: 9m 22s\tremaining: 8m 10s\n",
      "801:\tlearn: 0.7966039\ttotal: 9m 23s\tremaining: 8m 10s\n",
      "802:\tlearn: 0.7967225\ttotal: 9m 23s\tremaining: 8m 9s\n",
      "803:\tlearn: 0.7966989\ttotal: 9m 24s\tremaining: 8m 8s\n",
      "804:\tlearn: 0.7967560\ttotal: 9m 25s\tremaining: 8m 7s\n",
      "805:\tlearn: 0.7966933\ttotal: 9m 25s\tremaining: 8m 7s\n",
      "806:\tlearn: 0.7967080\ttotal: 9m 26s\tremaining: 8m 6s\n",
      "807:\tlearn: 0.7967351\ttotal: 9m 27s\tremaining: 8m 5s\n",
      "808:\tlearn: 0.7967019\ttotal: 9m 27s\tremaining: 8m 5s\n",
      "809:\tlearn: 0.7966790\ttotal: 9m 28s\tremaining: 8m 4s\n",
      "810:\tlearn: 0.7966619\ttotal: 9m 29s\tremaining: 8m 3s\n",
      "811:\tlearn: 0.7967054\ttotal: 9m 30s\tremaining: 8m 3s\n",
      "812:\tlearn: 0.7967830\ttotal: 9m 30s\tremaining: 8m 2s\n",
      "813:\tlearn: 0.7968109\ttotal: 9m 31s\tremaining: 8m 1s\n",
      "814:\tlearn: 0.7968341\ttotal: 9m 32s\tremaining: 8m\n",
      "815:\tlearn: 0.7969009\ttotal: 9m 32s\tremaining: 8m\n",
      "816:\tlearn: 0.7968873\ttotal: 9m 33s\tremaining: 7m 59s\n",
      "817:\tlearn: 0.7968546\ttotal: 9m 34s\tremaining: 7m 58s\n",
      "818:\tlearn: 0.7968435\ttotal: 9m 34s\tremaining: 7m 58s\n",
      "819:\tlearn: 0.7968756\ttotal: 9m 35s\tremaining: 7m 57s\n",
      "820:\tlearn: 0.7968983\ttotal: 9m 36s\tremaining: 7m 56s\n",
      "821:\tlearn: 0.7968801\ttotal: 9m 36s\tremaining: 7m 55s\n",
      "822:\tlearn: 0.7969364\ttotal: 9m 37s\tremaining: 7m 55s\n",
      "823:\tlearn: 0.7970139\ttotal: 9m 38s\tremaining: 7m 54s\n",
      "824:\tlearn: 0.7969574\ttotal: 9m 39s\tremaining: 7m 53s\n",
      "825:\tlearn: 0.7969623\ttotal: 9m 39s\tremaining: 7m 53s\n",
      "826:\tlearn: 0.7969546\ttotal: 9m 40s\tremaining: 7m 52s\n",
      "827:\tlearn: 0.7969872\ttotal: 9m 41s\tremaining: 7m 51s\n",
      "828:\tlearn: 0.7969711\ttotal: 9m 41s\tremaining: 7m 50s\n",
      "829:\tlearn: 0.7970112\ttotal: 9m 42s\tremaining: 7m 50s\n",
      "830:\tlearn: 0.7970576\ttotal: 9m 43s\tremaining: 7m 49s\n",
      "831:\tlearn: 0.7969845\ttotal: 9m 43s\tremaining: 7m 48s\n",
      "832:\tlearn: 0.7970618\ttotal: 9m 44s\tremaining: 7m 48s\n",
      "833:\tlearn: 0.7970765\ttotal: 9m 45s\tremaining: 7m 47s\n",
      "834:\tlearn: 0.7970365\ttotal: 9m 46s\tremaining: 7m 46s\n",
      "835:\tlearn: 0.7970355\ttotal: 9m 46s\tremaining: 7m 46s\n",
      "836:\tlearn: 0.7971010\ttotal: 9m 47s\tremaining: 7m 45s\n",
      "837:\tlearn: 0.7970662\ttotal: 9m 48s\tremaining: 7m 44s\n",
      "838:\tlearn: 0.7971235\ttotal: 9m 48s\tremaining: 7m 43s\n",
      "839:\tlearn: 0.7971338\ttotal: 9m 49s\tremaining: 7m 43s\n",
      "840:\tlearn: 0.7971387\ttotal: 9m 50s\tremaining: 7m 42s\n",
      "841:\tlearn: 0.7972065\ttotal: 9m 50s\tremaining: 7m 41s\n",
      "842:\tlearn: 0.7972059\ttotal: 9m 51s\tremaining: 7m 41s\n",
      "843:\tlearn: 0.7972036\ttotal: 9m 52s\tremaining: 7m 40s\n",
      "844:\tlearn: 0.7972205\ttotal: 9m 52s\tremaining: 7m 39s\n",
      "845:\tlearn: 0.7972426\ttotal: 9m 53s\tremaining: 7m 38s\n",
      "846:\tlearn: 0.7972481\ttotal: 9m 54s\tremaining: 7m 38s\n",
      "847:\tlearn: 0.7973052\ttotal: 9m 55s\tremaining: 7m 37s\n",
      "848:\tlearn: 0.7972086\ttotal: 9m 55s\tremaining: 7m 36s\n",
      "849:\tlearn: 0.7972998\ttotal: 9m 56s\tremaining: 7m 36s\n",
      "850:\tlearn: 0.7973209\ttotal: 9m 57s\tremaining: 7m 35s\n",
      "851:\tlearn: 0.7974905\ttotal: 9m 57s\tremaining: 7m 34s\n",
      "852:\tlearn: 0.7974566\ttotal: 9m 58s\tremaining: 7m 33s\n",
      "853:\tlearn: 0.7974539\ttotal: 9m 59s\tremaining: 7m 33s\n",
      "854:\tlearn: 0.7975492\ttotal: 9m 59s\tremaining: 7m 32s\n",
      "855:\tlearn: 0.7975198\ttotal: 10m\tremaining: 7m 31s\n",
      "856:\tlearn: 0.7975930\ttotal: 10m 1s\tremaining: 7m 31s\n",
      "857:\tlearn: 0.7975697\ttotal: 10m 1s\tremaining: 7m 30s\n",
      "858:\tlearn: 0.7975807\ttotal: 10m 2s\tremaining: 7m 29s\n",
      "859:\tlearn: 0.7975927\ttotal: 10m 3s\tremaining: 7m 29s\n",
      "860:\tlearn: 0.7976639\ttotal: 10m 4s\tremaining: 7m 28s\n",
      "861:\tlearn: 0.7976248\ttotal: 10m 4s\tremaining: 7m 27s\n",
      "862:\tlearn: 0.7975395\ttotal: 10m 5s\tremaining: 7m 26s\n",
      "863:\tlearn: 0.7976419\ttotal: 10m 6s\tremaining: 7m 26s\n",
      "864:\tlearn: 0.7976870\ttotal: 10m 6s\tremaining: 7m 25s\n",
      "865:\tlearn: 0.7977131\ttotal: 10m 7s\tremaining: 7m 24s\n",
      "866:\tlearn: 0.7976891\ttotal: 10m 8s\tremaining: 7m 24s\n",
      "867:\tlearn: 0.7977006\ttotal: 10m 8s\tremaining: 7m 23s\n",
      "868:\tlearn: 0.7976764\ttotal: 10m 9s\tremaining: 7m 22s\n",
      "869:\tlearn: 0.7977478\ttotal: 10m 10s\tremaining: 7m 21s\n",
      "870:\tlearn: 0.7977195\ttotal: 10m 11s\tremaining: 7m 21s\n",
      "871:\tlearn: 0.7977305\ttotal: 10m 11s\tremaining: 7m 20s\n",
      "872:\tlearn: 0.7977171\ttotal: 10m 12s\tremaining: 7m 19s\n",
      "873:\tlearn: 0.7977169\ttotal: 10m 13s\tremaining: 7m 19s\n",
      "874:\tlearn: 0.7977668\ttotal: 10m 13s\tremaining: 7m 18s\n",
      "875:\tlearn: 0.7977718\ttotal: 10m 14s\tremaining: 7m 17s\n",
      "876:\tlearn: 0.7978108\ttotal: 10m 15s\tremaining: 7m 17s\n",
      "877:\tlearn: 0.7977759\ttotal: 10m 15s\tremaining: 7m 16s\n",
      "878:\tlearn: 0.7977826\ttotal: 10m 16s\tremaining: 7m 15s\n",
      "879:\tlearn: 0.7977558\ttotal: 10m 17s\tremaining: 7m 14s\n",
      "880:\tlearn: 0.7978334\ttotal: 10m 18s\tremaining: 7m 14s\n",
      "881:\tlearn: 0.7978605\ttotal: 10m 18s\tremaining: 7m 13s\n",
      "882:\tlearn: 0.7978254\ttotal: 10m 19s\tremaining: 7m 12s\n",
      "883:\tlearn: 0.7979029\ttotal: 10m 20s\tremaining: 7m 12s\n",
      "884:\tlearn: 0.7979767\ttotal: 10m 20s\tremaining: 7m 11s\n",
      "885:\tlearn: 0.7979199\ttotal: 10m 21s\tremaining: 7m 10s\n",
      "886:\tlearn: 0.7979987\ttotal: 10m 22s\tremaining: 7m 10s\n",
      "887:\tlearn: 0.7979913\ttotal: 10m 23s\tremaining: 7m 9s\n",
      "888:\tlearn: 0.7979862\ttotal: 10m 23s\tremaining: 7m 8s\n",
      "889:\tlearn: 0.7979732\ttotal: 10m 24s\tremaining: 7m 7s\n",
      "890:\tlearn: 0.7980411\ttotal: 10m 25s\tremaining: 7m 7s\n",
      "891:\tlearn: 0.7980066\ttotal: 10m 25s\tremaining: 7m 6s\n",
      "892:\tlearn: 0.7980227\ttotal: 10m 26s\tremaining: 7m 5s\n",
      "893:\tlearn: 0.7980376\ttotal: 10m 27s\tremaining: 7m 5s\n",
      "894:\tlearn: 0.7979761\ttotal: 10m 27s\tremaining: 7m 4s\n",
      "895:\tlearn: 0.7980712\ttotal: 10m 28s\tremaining: 7m 3s\n",
      "896:\tlearn: 0.7980931\ttotal: 10m 29s\tremaining: 7m 3s\n",
      "897:\tlearn: 0.7980805\ttotal: 10m 29s\tremaining: 7m 2s\n",
      "898:\tlearn: 0.7980841\ttotal: 10m 30s\tremaining: 7m 1s\n",
      "899:\tlearn: 0.7980586\ttotal: 10m 31s\tremaining: 7m\n",
      "900:\tlearn: 0.7981335\ttotal: 10m 32s\tremaining: 7m\n",
      "901:\tlearn: 0.7981388\ttotal: 10m 32s\tremaining: 6m 59s\n",
      "902:\tlearn: 0.7981332\ttotal: 10m 33s\tremaining: 6m 58s\n",
      "903:\tlearn: 0.7980424\ttotal: 10m 34s\tremaining: 6m 58s\n",
      "904:\tlearn: 0.7980878\ttotal: 10m 34s\tremaining: 6m 57s\n",
      "905:\tlearn: 0.7981152\ttotal: 10m 35s\tremaining: 6m 56s\n",
      "906:\tlearn: 0.7982612\ttotal: 10m 36s\tremaining: 6m 55s\n",
      "907:\tlearn: 0.7982944\ttotal: 10m 36s\tremaining: 6m 55s\n",
      "908:\tlearn: 0.7983162\ttotal: 10m 37s\tremaining: 6m 54s\n",
      "909:\tlearn: 0.7984129\ttotal: 10m 38s\tremaining: 6m 53s\n",
      "910:\tlearn: 0.7984019\ttotal: 10m 38s\tremaining: 6m 53s\n",
      "911:\tlearn: 0.7984021\ttotal: 10m 39s\tremaining: 6m 52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912:\tlearn: 0.7984756\ttotal: 10m 40s\tremaining: 6m 51s\n",
      "913:\tlearn: 0.7985418\ttotal: 10m 40s\tremaining: 6m 50s\n",
      "914:\tlearn: 0.7985433\ttotal: 10m 41s\tremaining: 6m 50s\n",
      "915:\tlearn: 0.7985306\ttotal: 10m 42s\tremaining: 6m 49s\n",
      "916:\tlearn: 0.7985640\ttotal: 10m 43s\tremaining: 6m 48s\n",
      "917:\tlearn: 0.7985415\ttotal: 10m 43s\tremaining: 6m 48s\n",
      "918:\tlearn: 0.7985470\ttotal: 10m 44s\tremaining: 6m 47s\n",
      "919:\tlearn: 0.7985262\ttotal: 10m 45s\tremaining: 6m 46s\n",
      "920:\tlearn: 0.7985532\ttotal: 10m 45s\tremaining: 6m 46s\n",
      "921:\tlearn: 0.7985182\ttotal: 10m 46s\tremaining: 6m 45s\n",
      "922:\tlearn: 0.7985182\ttotal: 10m 47s\tremaining: 6m 44s\n",
      "923:\tlearn: 0.7985423\ttotal: 10m 47s\tremaining: 6m 43s\n",
      "924:\tlearn: 0.7985690\ttotal: 10m 48s\tremaining: 6m 43s\n",
      "925:\tlearn: 0.7985723\ttotal: 10m 49s\tremaining: 6m 42s\n",
      "926:\tlearn: 0.7985723\ttotal: 10m 50s\tremaining: 6m 41s\n",
      "927:\tlearn: 0.7985537\ttotal: 10m 50s\tremaining: 6m 41s\n",
      "928:\tlearn: 0.7985537\ttotal: 10m 51s\tremaining: 6m 40s\n",
      "929:\tlearn: 0.7985537\ttotal: 10m 52s\tremaining: 6m 39s\n",
      "930:\tlearn: 0.7985862\ttotal: 10m 52s\tremaining: 6m 38s\n",
      "931:\tlearn: 0.7986238\ttotal: 10m 53s\tremaining: 6m 38s\n",
      "932:\tlearn: 0.7986784\ttotal: 10m 54s\tremaining: 6m 37s\n",
      "933:\tlearn: 0.7987226\ttotal: 10m 54s\tremaining: 6m 36s\n",
      "934:\tlearn: 0.7987226\ttotal: 10m 55s\tremaining: 6m 36s\n",
      "935:\tlearn: 0.7987283\ttotal: 10m 56s\tremaining: 6m 35s\n",
      "936:\tlearn: 0.7987139\ttotal: 10m 56s\tremaining: 6m 34s\n",
      "937:\tlearn: 0.7987666\ttotal: 10m 57s\tremaining: 6m 33s\n",
      "938:\tlearn: 0.7987666\ttotal: 10m 58s\tremaining: 6m 33s\n",
      "939:\tlearn: 0.7987599\ttotal: 10m 58s\tremaining: 6m 32s\n",
      "940:\tlearn: 0.7986965\ttotal: 10m 59s\tremaining: 6m 31s\n",
      "941:\tlearn: 0.7986965\ttotal: 11m\tremaining: 6m 31s\n",
      "942:\tlearn: 0.7987511\ttotal: 11m\tremaining: 6m 30s\n",
      "943:\tlearn: 0.7987608\ttotal: 11m 1s\tremaining: 6m 29s\n",
      "944:\tlearn: 0.7987872\ttotal: 11m 2s\tremaining: 6m 28s\n",
      "945:\tlearn: 0.7987872\ttotal: 11m 2s\tremaining: 6m 28s\n",
      "946:\tlearn: 0.7987918\ttotal: 11m 3s\tremaining: 6m 27s\n",
      "947:\tlearn: 0.7987838\ttotal: 11m 4s\tremaining: 6m 26s\n",
      "948:\tlearn: 0.7988614\ttotal: 11m 4s\tremaining: 6m 26s\n",
      "949:\tlearn: 0.7988730\ttotal: 11m 5s\tremaining: 6m 25s\n",
      "950:\tlearn: 0.7988730\ttotal: 11m 6s\tremaining: 6m 24s\n",
      "951:\tlearn: 0.7988609\ttotal: 11m 6s\tremaining: 6m 23s\n",
      "952:\tlearn: 0.7988273\ttotal: 11m 7s\tremaining: 6m 23s\n",
      "953:\tlearn: 0.7988274\ttotal: 11m 8s\tremaining: 6m 22s\n",
      "954:\tlearn: 0.7988644\ttotal: 11m 8s\tremaining: 6m 21s\n",
      "955:\tlearn: 0.7988972\ttotal: 11m 9s\tremaining: 6m 21s\n",
      "956:\tlearn: 0.7988851\ttotal: 11m 10s\tremaining: 6m 20s\n",
      "957:\tlearn: 0.7988851\ttotal: 11m 10s\tremaining: 6m 19s\n",
      "958:\tlearn: 0.7987879\ttotal: 11m 11s\tremaining: 6m 18s\n",
      "959:\tlearn: 0.7987647\ttotal: 11m 12s\tremaining: 6m 18s\n",
      "960:\tlearn: 0.7988596\ttotal: 11m 13s\tremaining: 6m 17s\n",
      "961:\tlearn: 0.7988596\ttotal: 11m 13s\tremaining: 6m 16s\n",
      "962:\tlearn: 0.7989198\ttotal: 11m 14s\tremaining: 6m 16s\n",
      "963:\tlearn: 0.7989198\ttotal: 11m 14s\tremaining: 6m 15s\n",
      "964:\tlearn: 0.7989534\ttotal: 11m 15s\tremaining: 6m 14s\n",
      "965:\tlearn: 0.7990715\ttotal: 11m 16s\tremaining: 6m 13s\n",
      "966:\tlearn: 0.7991156\ttotal: 11m 17s\tremaining: 6m 13s\n",
      "967:\tlearn: 0.7991421\ttotal: 11m 17s\tremaining: 6m 12s\n",
      "968:\tlearn: 0.7990786\ttotal: 11m 18s\tremaining: 6m 11s\n",
      "969:\tlearn: 0.7990731\ttotal: 11m 19s\tremaining: 6m 11s\n",
      "970:\tlearn: 0.7990451\ttotal: 11m 19s\tremaining: 6m 10s\n",
      "971:\tlearn: 0.7990832\ttotal: 11m 20s\tremaining: 6m 9s\n",
      "972:\tlearn: 0.7991368\ttotal: 11m 21s\tremaining: 6m 8s\n",
      "973:\tlearn: 0.7991368\ttotal: 11m 21s\tremaining: 6m 8s\n",
      "974:\tlearn: 0.7991802\ttotal: 11m 22s\tremaining: 6m 7s\n",
      "975:\tlearn: 0.7991730\ttotal: 11m 23s\tremaining: 6m 6s\n",
      "976:\tlearn: 0.7991749\ttotal: 11m 23s\tremaining: 6m 6s\n",
      "977:\tlearn: 0.7992658\ttotal: 11m 24s\tremaining: 6m 5s\n",
      "978:\tlearn: 0.7992652\ttotal: 11m 25s\tremaining: 6m 4s\n",
      "979:\tlearn: 0.7992915\ttotal: 11m 25s\tremaining: 6m 3s\n",
      "980:\tlearn: 0.7992466\ttotal: 11m 26s\tremaining: 6m 3s\n",
      "981:\tlearn: 0.7992688\ttotal: 11m 27s\tremaining: 6m 2s\n",
      "982:\tlearn: 0.7993472\ttotal: 11m 28s\tremaining: 6m 1s\n",
      "983:\tlearn: 0.7994309\ttotal: 11m 28s\tremaining: 6m 1s\n",
      "984:\tlearn: 0.7995191\ttotal: 11m 29s\tremaining: 6m\n",
      "985:\tlearn: 0.7995414\ttotal: 11m 30s\tremaining: 5m 59s\n",
      "986:\tlearn: 0.7994627\ttotal: 11m 30s\tremaining: 5m 59s\n",
      "987:\tlearn: 0.7995228\ttotal: 11m 31s\tremaining: 5m 58s\n",
      "988:\tlearn: 0.7994876\ttotal: 11m 32s\tremaining: 5m 57s\n",
      "989:\tlearn: 0.7995364\ttotal: 11m 32s\tremaining: 5m 56s\n",
      "990:\tlearn: 0.7994966\ttotal: 11m 33s\tremaining: 5m 56s\n",
      "991:\tlearn: 0.7995273\ttotal: 11m 34s\tremaining: 5m 55s\n",
      "992:\tlearn: 0.7995273\ttotal: 11m 34s\tremaining: 5m 54s\n",
      "993:\tlearn: 0.7995876\ttotal: 11m 35s\tremaining: 5m 54s\n",
      "994:\tlearn: 0.7995934\ttotal: 11m 36s\tremaining: 5m 53s\n",
      "995:\tlearn: 0.7995531\ttotal: 11m 36s\tremaining: 5m 52s\n",
      "996:\tlearn: 0.7995230\ttotal: 11m 37s\tremaining: 5m 52s\n",
      "997:\tlearn: 0.7996080\ttotal: 11m 38s\tremaining: 5m 51s\n",
      "998:\tlearn: 0.7996251\ttotal: 11m 39s\tremaining: 5m 50s\n",
      "999:\tlearn: 0.7996251\ttotal: 11m 39s\tremaining: 5m 49s\n",
      "1000:\tlearn: 0.7996507\ttotal: 11m 40s\tremaining: 5m 49s\n",
      "1001:\tlearn: 0.7996815\ttotal: 11m 41s\tremaining: 5m 48s\n",
      "1002:\tlearn: 0.7996878\ttotal: 11m 41s\tremaining: 5m 47s\n",
      "1003:\tlearn: 0.7997598\ttotal: 11m 42s\tremaining: 5m 47s\n",
      "1004:\tlearn: 0.7997598\ttotal: 11m 43s\tremaining: 5m 46s\n",
      "1005:\tlearn: 0.7997354\ttotal: 11m 43s\tremaining: 5m 45s\n",
      "1006:\tlearn: 0.7997359\ttotal: 11m 44s\tremaining: 5m 44s\n",
      "1007:\tlearn: 0.7997692\ttotal: 11m 45s\tremaining: 5m 44s\n",
      "1008:\tlearn: 0.7997692\ttotal: 11m 45s\tremaining: 5m 43s\n",
      "1009:\tlearn: 0.7997841\ttotal: 11m 46s\tremaining: 5m 42s\n",
      "1010:\tlearn: 0.7998542\ttotal: 11m 47s\tremaining: 5m 42s\n",
      "1011:\tlearn: 0.7998361\ttotal: 11m 47s\tremaining: 5m 41s\n",
      "1012:\tlearn: 0.7998523\ttotal: 11m 48s\tremaining: 5m 40s\n",
      "1013:\tlearn: 0.7998008\ttotal: 11m 49s\tremaining: 5m 39s\n",
      "1014:\tlearn: 0.7998492\ttotal: 11m 50s\tremaining: 5m 39s\n",
      "1015:\tlearn: 0.7999038\ttotal: 11m 50s\tremaining: 5m 38s\n",
      "1016:\tlearn: 0.7999030\ttotal: 11m 51s\tremaining: 5m 37s\n",
      "1017:\tlearn: 0.7998263\ttotal: 11m 52s\tremaining: 5m 37s\n",
      "1018:\tlearn: 0.7998263\ttotal: 11m 52s\tremaining: 5m 36s\n",
      "1019:\tlearn: 0.7998263\ttotal: 11m 53s\tremaining: 5m 35s\n",
      "1020:\tlearn: 0.7998298\ttotal: 11m 54s\tremaining: 5m 35s\n",
      "1021:\tlearn: 0.7999109\ttotal: 11m 54s\tremaining: 5m 34s\n",
      "1022:\tlearn: 0.7999154\ttotal: 11m 55s\tremaining: 5m 33s\n",
      "1023:\tlearn: 0.7999290\ttotal: 11m 56s\tremaining: 5m 32s\n",
      "1024:\tlearn: 0.7999669\ttotal: 11m 56s\tremaining: 5m 32s\n",
      "1025:\tlearn: 0.7999669\ttotal: 11m 57s\tremaining: 5m 31s\n",
      "1026:\tlearn: 0.7999479\ttotal: 11m 58s\tremaining: 5m 30s\n",
      "1027:\tlearn: 0.8000353\ttotal: 11m 58s\tremaining: 5m 30s\n",
      "1028:\tlearn: 0.7999833\ttotal: 11m 59s\tremaining: 5m 29s\n",
      "1029:\tlearn: 0.8000208\ttotal: 12m\tremaining: 5m 28s\n",
      "1030:\tlearn: 0.7999961\ttotal: 12m\tremaining: 5m 27s\n",
      "1031:\tlearn: 0.8000453\ttotal: 12m 1s\tremaining: 5m 27s\n",
      "1032:\tlearn: 0.8000214\ttotal: 12m 2s\tremaining: 5m 26s\n",
      "1033:\tlearn: 0.8000214\ttotal: 12m 2s\tremaining: 5m 25s\n",
      "1034:\tlearn: 0.8000241\ttotal: 12m 3s\tremaining: 5m 25s\n",
      "1035:\tlearn: 0.8000674\ttotal: 12m 4s\tremaining: 5m 24s\n",
      "1036:\tlearn: 0.8000772\ttotal: 12m 5s\tremaining: 5m 23s\n",
      "1037:\tlearn: 0.8001341\ttotal: 12m 5s\tremaining: 5m 23s\n",
      "1038:\tlearn: 0.8001422\ttotal: 12m 6s\tremaining: 5m 22s\n",
      "1039:\tlearn: 0.8001422\ttotal: 12m 7s\tremaining: 5m 21s\n",
      "1040:\tlearn: 0.8000805\ttotal: 12m 7s\tremaining: 5m 20s\n",
      "1041:\tlearn: 0.8000021\ttotal: 12m 8s\tremaining: 5m 20s\n",
      "1042:\tlearn: 0.8000411\ttotal: 12m 9s\tremaining: 5m 19s\n",
      "1043:\tlearn: 0.8001028\ttotal: 12m 9s\tremaining: 5m 18s\n",
      "1044:\tlearn: 0.8001028\ttotal: 12m 10s\tremaining: 5m 18s\n",
      "1045:\tlearn: 0.8001180\ttotal: 12m 11s\tremaining: 5m 17s\n",
      "1046:\tlearn: 0.8001838\ttotal: 12m 11s\tremaining: 5m 16s\n",
      "1047:\tlearn: 0.8001831\ttotal: 12m 12s\tremaining: 5m 15s\n",
      "1048:\tlearn: 0.8002322\ttotal: 12m 13s\tremaining: 5m 15s\n",
      "1049:\tlearn: 0.8002322\ttotal: 12m 13s\tremaining: 5m 14s\n",
      "1050:\tlearn: 0.8002768\ttotal: 12m 14s\tremaining: 5m 13s\n",
      "1051:\tlearn: 0.8002768\ttotal: 12m 15s\tremaining: 5m 13s\n",
      "1052:\tlearn: 0.8002824\ttotal: 12m 15s\tremaining: 5m 12s\n",
      "1053:\tlearn: 0.8002752\ttotal: 12m 16s\tremaining: 5m 11s\n",
      "1054:\tlearn: 0.8002752\ttotal: 12m 17s\tremaining: 5m 10s\n",
      "1055:\tlearn: 0.8002506\ttotal: 12m 17s\tremaining: 5m 10s\n",
      "1056:\tlearn: 0.8002719\ttotal: 12m 18s\tremaining: 5m 9s\n",
      "1057:\tlearn: 0.8003102\ttotal: 12m 19s\tremaining: 5m 8s\n",
      "1058:\tlearn: 0.8003391\ttotal: 12m 19s\tremaining: 5m 8s\n",
      "1059:\tlearn: 0.8003138\ttotal: 12m 20s\tremaining: 5m 7s\n",
      "1060:\tlearn: 0.8003401\ttotal: 12m 21s\tremaining: 5m 6s\n",
      "1061:\tlearn: 0.8003099\ttotal: 12m 22s\tremaining: 5m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1062:\tlearn: 0.8003887\ttotal: 12m 22s\tremaining: 5m 5s\n",
      "1063:\tlearn: 0.8004148\ttotal: 12m 23s\tremaining: 5m 4s\n",
      "1064:\tlearn: 0.8004812\ttotal: 12m 24s\tremaining: 5m 3s\n",
      "1065:\tlearn: 0.8005209\ttotal: 12m 24s\tremaining: 5m 3s\n",
      "1066:\tlearn: 0.8005067\ttotal: 12m 25s\tremaining: 5m 2s\n",
      "1067:\tlearn: 0.8005068\ttotal: 12m 26s\tremaining: 5m 1s\n",
      "1068:\tlearn: 0.8005325\ttotal: 12m 26s\tremaining: 5m 1s\n",
      "1069:\tlearn: 0.8005325\ttotal: 12m 27s\tremaining: 5m\n",
      "1070:\tlearn: 0.8004915\ttotal: 12m 28s\tremaining: 4m 59s\n",
      "1071:\tlearn: 0.8005192\ttotal: 12m 28s\tremaining: 4m 58s\n",
      "1072:\tlearn: 0.8005416\ttotal: 12m 29s\tremaining: 4m 58s\n",
      "1073:\tlearn: 0.8005679\ttotal: 12m 30s\tremaining: 4m 57s\n",
      "1074:\tlearn: 0.8005436\ttotal: 12m 30s\tremaining: 4m 56s\n",
      "1075:\tlearn: 0.8005519\ttotal: 12m 31s\tremaining: 4m 56s\n",
      "1076:\tlearn: 0.8005546\ttotal: 12m 32s\tremaining: 4m 55s\n",
      "1077:\tlearn: 0.8005194\ttotal: 12m 32s\tremaining: 4m 54s\n",
      "1078:\tlearn: 0.8005626\ttotal: 12m 33s\tremaining: 4m 54s\n",
      "1079:\tlearn: 0.8005626\ttotal: 12m 34s\tremaining: 4m 53s\n",
      "1080:\tlearn: 0.8005340\ttotal: 12m 34s\tremaining: 4m 52s\n",
      "1081:\tlearn: 0.8005340\ttotal: 12m 35s\tremaining: 4m 51s\n",
      "1082:\tlearn: 0.8005269\ttotal: 12m 36s\tremaining: 4m 51s\n",
      "1083:\tlearn: 0.8005269\ttotal: 12m 36s\tremaining: 4m 50s\n",
      "1084:\tlearn: 0.8006507\ttotal: 12m 37s\tremaining: 4m 49s\n",
      "1085:\tlearn: 0.8006564\ttotal: 12m 38s\tremaining: 4m 49s\n",
      "1086:\tlearn: 0.8006564\ttotal: 12m 38s\tremaining: 4m 48s\n",
      "1087:\tlearn: 0.8006385\ttotal: 12m 39s\tremaining: 4m 47s\n",
      "1088:\tlearn: 0.8006527\ttotal: 12m 40s\tremaining: 4m 46s\n",
      "1089:\tlearn: 0.8005996\ttotal: 12m 40s\tremaining: 4m 46s\n",
      "1090:\tlearn: 0.8006820\ttotal: 12m 41s\tremaining: 4m 45s\n",
      "1091:\tlearn: 0.8006763\ttotal: 12m 42s\tremaining: 4m 44s\n",
      "1092:\tlearn: 0.8007036\ttotal: 12m 42s\tremaining: 4m 44s\n",
      "1093:\tlearn: 0.8007375\ttotal: 12m 43s\tremaining: 4m 43s\n",
      "1094:\tlearn: 0.8007582\ttotal: 12m 44s\tremaining: 4m 42s\n",
      "1095:\tlearn: 0.8007582\ttotal: 12m 44s\tremaining: 4m 41s\n",
      "1096:\tlearn: 0.8007999\ttotal: 12m 45s\tremaining: 4m 41s\n",
      "1097:\tlearn: 0.8007596\ttotal: 12m 46s\tremaining: 4m 40s\n",
      "1098:\tlearn: 0.8007596\ttotal: 12m 46s\tremaining: 4m 39s\n",
      "1099:\tlearn: 0.8008205\ttotal: 12m 47s\tremaining: 4m 39s\n",
      "1100:\tlearn: 0.8007751\ttotal: 12m 48s\tremaining: 4m 38s\n",
      "1101:\tlearn: 0.8008195\ttotal: 12m 49s\tremaining: 4m 37s\n",
      "1102:\tlearn: 0.8008195\ttotal: 12m 49s\tremaining: 4m 37s\n",
      "1103:\tlearn: 0.8008195\ttotal: 12m 50s\tremaining: 4m 36s\n",
      "1104:\tlearn: 0.8008342\ttotal: 12m 51s\tremaining: 4m 35s\n",
      "1105:\tlearn: 0.8008342\ttotal: 12m 51s\tremaining: 4m 34s\n",
      "1106:\tlearn: 0.8008093\ttotal: 12m 52s\tremaining: 4m 34s\n",
      "1107:\tlearn: 0.8008111\ttotal: 12m 53s\tremaining: 4m 33s\n",
      "1108:\tlearn: 0.8008782\ttotal: 12m 53s\tremaining: 4m 32s\n",
      "1109:\tlearn: 0.8008706\ttotal: 12m 54s\tremaining: 4m 32s\n",
      "1110:\tlearn: 0.8009691\ttotal: 12m 55s\tremaining: 4m 31s\n",
      "1111:\tlearn: 0.8010188\ttotal: 12m 55s\tremaining: 4m 30s\n",
      "1112:\tlearn: 0.8010231\ttotal: 12m 56s\tremaining: 4m 30s\n",
      "1113:\tlearn: 0.8010231\ttotal: 12m 57s\tremaining: 4m 29s\n",
      "1114:\tlearn: 0.8010060\ttotal: 12m 57s\tremaining: 4m 28s\n",
      "1115:\tlearn: 0.8010060\ttotal: 12m 58s\tremaining: 4m 27s\n",
      "1116:\tlearn: 0.8010161\ttotal: 12m 59s\tremaining: 4m 27s\n",
      "1117:\tlearn: 0.8010161\ttotal: 12m 59s\tremaining: 4m 26s\n",
      "1118:\tlearn: 0.8009642\ttotal: 13m\tremaining: 4m 25s\n",
      "1119:\tlearn: 0.8009562\ttotal: 13m 1s\tremaining: 4m 25s\n",
      "1120:\tlearn: 0.8010292\ttotal: 13m 1s\tremaining: 4m 24s\n",
      "1121:\tlearn: 0.8010833\ttotal: 13m 2s\tremaining: 4m 23s\n",
      "1122:\tlearn: 0.8010833\ttotal: 13m 3s\tremaining: 4m 22s\n",
      "1123:\tlearn: 0.8010993\ttotal: 13m 3s\tremaining: 4m 22s\n",
      "1124:\tlearn: 0.8011209\ttotal: 13m 4s\tremaining: 4m 21s\n",
      "1125:\tlearn: 0.8011529\ttotal: 13m 5s\tremaining: 4m 20s\n",
      "1126:\tlearn: 0.8011359\ttotal: 13m 5s\tremaining: 4m 20s\n",
      "1127:\tlearn: 0.8011006\ttotal: 13m 6s\tremaining: 4m 19s\n",
      "1128:\tlearn: 0.8011496\ttotal: 13m 7s\tremaining: 4m 18s\n",
      "1129:\tlearn: 0.8011496\ttotal: 13m 7s\tremaining: 4m 18s\n",
      "1130:\tlearn: 0.8011476\ttotal: 13m 8s\tremaining: 4m 17s\n",
      "1131:\tlearn: 0.8011558\ttotal: 13m 9s\tremaining: 4m 16s\n",
      "1132:\tlearn: 0.8011364\ttotal: 13m 10s\tremaining: 4m 15s\n",
      "1133:\tlearn: 0.8012032\ttotal: 13m 10s\tremaining: 4m 15s\n",
      "1134:\tlearn: 0.8011680\ttotal: 13m 11s\tremaining: 4m 14s\n",
      "1135:\tlearn: 0.8011950\ttotal: 13m 12s\tremaining: 4m 13s\n",
      "1136:\tlearn: 0.8011950\ttotal: 13m 12s\tremaining: 4m 13s\n",
      "1137:\tlearn: 0.8012184\ttotal: 13m 13s\tremaining: 4m 12s\n",
      "1138:\tlearn: 0.8012187\ttotal: 13m 14s\tremaining: 4m 11s\n",
      "1139:\tlearn: 0.8013120\ttotal: 13m 14s\tremaining: 4m 11s\n",
      "1140:\tlearn: 0.8013120\ttotal: 13m 15s\tremaining: 4m 10s\n",
      "1141:\tlearn: 0.8013075\ttotal: 13m 16s\tremaining: 4m 9s\n",
      "1142:\tlearn: 0.8013075\ttotal: 13m 16s\tremaining: 4m 8s\n",
      "1143:\tlearn: 0.8013068\ttotal: 13m 17s\tremaining: 4m 8s\n",
      "1144:\tlearn: 0.8013222\ttotal: 13m 18s\tremaining: 4m 7s\n",
      "1145:\tlearn: 0.8014000\ttotal: 13m 18s\tremaining: 4m 6s\n",
      "1146:\tlearn: 0.8013516\ttotal: 13m 19s\tremaining: 4m 6s\n",
      "1147:\tlearn: 0.8014350\ttotal: 13m 20s\tremaining: 4m 5s\n",
      "1148:\tlearn: 0.8014240\ttotal: 13m 20s\tremaining: 4m 4s\n",
      "1149:\tlearn: 0.8014198\ttotal: 13m 21s\tremaining: 4m 3s\n",
      "1150:\tlearn: 0.8013988\ttotal: 13m 22s\tremaining: 4m 3s\n",
      "1151:\tlearn: 0.8014208\ttotal: 13m 23s\tremaining: 4m 2s\n",
      "1152:\tlearn: 0.8014466\ttotal: 13m 23s\tremaining: 4m 1s\n",
      "1153:\tlearn: 0.8014397\ttotal: 13m 24s\tremaining: 4m 1s\n",
      "1154:\tlearn: 0.8014453\ttotal: 13m 25s\tremaining: 4m\n",
      "1155:\tlearn: 0.8014507\ttotal: 13m 25s\tremaining: 3m 59s\n",
      "1156:\tlearn: 0.8013888\ttotal: 13m 26s\tremaining: 3m 59s\n",
      "1157:\tlearn: 0.8013986\ttotal: 13m 27s\tremaining: 3m 58s\n",
      "1158:\tlearn: 0.8013986\ttotal: 13m 27s\tremaining: 3m 57s\n",
      "1159:\tlearn: 0.8013405\ttotal: 13m 28s\tremaining: 3m 56s\n",
      "1160:\tlearn: 0.8013797\ttotal: 13m 29s\tremaining: 3m 56s\n",
      "1161:\tlearn: 0.8015126\ttotal: 13m 29s\tremaining: 3m 55s\n",
      "1162:\tlearn: 0.8015126\ttotal: 13m 30s\tremaining: 3m 54s\n",
      "1163:\tlearn: 0.8015236\ttotal: 13m 31s\tremaining: 3m 54s\n",
      "1164:\tlearn: 0.8014820\ttotal: 13m 31s\tremaining: 3m 53s\n",
      "1165:\tlearn: 0.8014264\ttotal: 13m 32s\tremaining: 3m 52s\n",
      "1166:\tlearn: 0.8014031\ttotal: 13m 33s\tremaining: 3m 52s\n",
      "1167:\tlearn: 0.8014031\ttotal: 13m 33s\tremaining: 3m 51s\n",
      "1168:\tlearn: 0.8013922\ttotal: 13m 34s\tremaining: 3m 50s\n",
      "1169:\tlearn: 0.8013685\ttotal: 13m 35s\tremaining: 3m 49s\n",
      "1170:\tlearn: 0.8013685\ttotal: 13m 35s\tremaining: 3m 49s\n",
      "1171:\tlearn: 0.8013685\ttotal: 13m 36s\tremaining: 3m 48s\n",
      "1172:\tlearn: 0.8013685\ttotal: 13m 37s\tremaining: 3m 47s\n",
      "1173:\tlearn: 0.8013685\ttotal: 13m 37s\tremaining: 3m 47s\n",
      "1174:\tlearn: 0.8014221\ttotal: 13m 38s\tremaining: 3m 46s\n",
      "1175:\tlearn: 0.8014221\ttotal: 13m 39s\tremaining: 3m 45s\n",
      "1176:\tlearn: 0.8014468\ttotal: 13m 39s\tremaining: 3m 44s\n",
      "1177:\tlearn: 0.8014118\ttotal: 13m 40s\tremaining: 3m 44s\n",
      "1178:\tlearn: 0.8014895\ttotal: 13m 41s\tremaining: 3m 43s\n",
      "1179:\tlearn: 0.8014553\ttotal: 13m 41s\tremaining: 3m 42s\n",
      "1180:\tlearn: 0.8014846\ttotal: 13m 42s\tremaining: 3m 42s\n",
      "1181:\tlearn: 0.8014712\ttotal: 13m 43s\tremaining: 3m 41s\n",
      "1182:\tlearn: 0.8014783\ttotal: 13m 44s\tremaining: 3m 40s\n",
      "1183:\tlearn: 0.8015711\ttotal: 13m 44s\tremaining: 3m 40s\n",
      "1184:\tlearn: 0.8015418\ttotal: 13m 45s\tremaining: 3m 39s\n",
      "1185:\tlearn: 0.8016927\ttotal: 13m 46s\tremaining: 3m 38s\n",
      "1186:\tlearn: 0.8017196\ttotal: 13m 46s\tremaining: 3m 38s\n",
      "1187:\tlearn: 0.8017196\ttotal: 13m 47s\tremaining: 3m 37s\n",
      "1188:\tlearn: 0.8017189\ttotal: 13m 48s\tremaining: 3m 36s\n",
      "1189:\tlearn: 0.8017161\ttotal: 13m 48s\tremaining: 3m 35s\n",
      "1190:\tlearn: 0.8016573\ttotal: 13m 49s\tremaining: 3m 35s\n",
      "1191:\tlearn: 0.8017014\ttotal: 13m 50s\tremaining: 3m 34s\n",
      "1192:\tlearn: 0.8017397\ttotal: 13m 50s\tremaining: 3m 33s\n",
      "1193:\tlearn: 0.8017590\ttotal: 13m 51s\tremaining: 3m 33s\n",
      "1194:\tlearn: 0.8017590\ttotal: 13m 52s\tremaining: 3m 32s\n",
      "1195:\tlearn: 0.8017849\ttotal: 13m 52s\tremaining: 3m 31s\n",
      "1196:\tlearn: 0.8017447\ttotal: 13m 53s\tremaining: 3m 30s\n",
      "1197:\tlearn: 0.8017447\ttotal: 13m 54s\tremaining: 3m 30s\n",
      "1198:\tlearn: 0.8018442\ttotal: 13m 55s\tremaining: 3m 29s\n",
      "1199:\tlearn: 0.8018442\ttotal: 13m 55s\tremaining: 3m 28s\n",
      "1200:\tlearn: 0.8018723\ttotal: 13m 56s\tremaining: 3m 28s\n",
      "1201:\tlearn: 0.8018714\ttotal: 13m 57s\tremaining: 3m 27s\n",
      "1202:\tlearn: 0.8018925\ttotal: 13m 57s\tremaining: 3m 26s\n",
      "1203:\tlearn: 0.8018641\ttotal: 13m 58s\tremaining: 3m 26s\n",
      "1204:\tlearn: 0.8019013\ttotal: 13m 59s\tremaining: 3m 25s\n",
      "1205:\tlearn: 0.8019376\ttotal: 13m 59s\tremaining: 3m 24s\n",
      "1206:\tlearn: 0.8020196\ttotal: 14m\tremaining: 3m 24s\n",
      "1207:\tlearn: 0.8020196\ttotal: 14m 1s\tremaining: 3m 23s\n",
      "1208:\tlearn: 0.8020165\ttotal: 14m 1s\tremaining: 3m 22s\n",
      "1209:\tlearn: 0.8020096\ttotal: 14m 2s\tremaining: 3m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210:\tlearn: 0.8020096\ttotal: 14m 3s\tremaining: 3m 21s\n",
      "1211:\tlearn: 0.8020822\ttotal: 14m 3s\tremaining: 3m 20s\n",
      "1212:\tlearn: 0.8021139\ttotal: 14m 4s\tremaining: 3m 19s\n",
      "1213:\tlearn: 0.8021417\ttotal: 14m 5s\tremaining: 3m 19s\n",
      "1214:\tlearn: 0.8021862\ttotal: 14m 6s\tremaining: 3m 18s\n",
      "1215:\tlearn: 0.8022467\ttotal: 14m 6s\tremaining: 3m 17s\n",
      "1216:\tlearn: 0.8021708\ttotal: 14m 7s\tremaining: 3m 17s\n",
      "1217:\tlearn: 0.8021708\ttotal: 14m 8s\tremaining: 3m 16s\n",
      "1218:\tlearn: 0.8021643\ttotal: 14m 8s\tremaining: 3m 15s\n",
      "1219:\tlearn: 0.8021643\ttotal: 14m 9s\tremaining: 3m 14s\n",
      "1220:\tlearn: 0.8022238\ttotal: 14m 10s\tremaining: 3m 14s\n",
      "1221:\tlearn: 0.8022238\ttotal: 14m 10s\tremaining: 3m 13s\n",
      "1222:\tlearn: 0.8022120\ttotal: 14m 11s\tremaining: 3m 12s\n",
      "1223:\tlearn: 0.8022357\ttotal: 14m 12s\tremaining: 3m 12s\n",
      "1224:\tlearn: 0.8021870\ttotal: 14m 12s\tremaining: 3m 11s\n",
      "1225:\tlearn: 0.8022064\ttotal: 14m 13s\tremaining: 3m 10s\n",
      "1226:\tlearn: 0.8021640\ttotal: 14m 14s\tremaining: 3m 10s\n",
      "1227:\tlearn: 0.8021957\ttotal: 14m 14s\tremaining: 3m 9s\n",
      "1228:\tlearn: 0.8021957\ttotal: 14m 15s\tremaining: 3m 8s\n",
      "1229:\tlearn: 0.8022513\ttotal: 14m 16s\tremaining: 3m 7s\n",
      "1230:\tlearn: 0.8022943\ttotal: 14m 16s\tremaining: 3m 7s\n",
      "1231:\tlearn: 0.8022137\ttotal: 14m 17s\tremaining: 3m 6s\n",
      "1232:\tlearn: 0.8022608\ttotal: 14m 18s\tremaining: 3m 5s\n",
      "1233:\tlearn: 0.8022837\ttotal: 14m 18s\tremaining: 3m 5s\n",
      "1234:\tlearn: 0.8023034\ttotal: 14m 19s\tremaining: 3m 4s\n",
      "1235:\tlearn: 0.8023083\ttotal: 14m 20s\tremaining: 3m 3s\n",
      "1236:\tlearn: 0.8023368\ttotal: 14m 20s\tremaining: 3m 3s\n",
      "1237:\tlearn: 0.8023517\ttotal: 14m 21s\tremaining: 3m 2s\n",
      "1238:\tlearn: 0.8023828\ttotal: 14m 22s\tremaining: 3m 1s\n",
      "1239:\tlearn: 0.8024206\ttotal: 14m 23s\tremaining: 3m\n",
      "1240:\tlearn: 0.8024197\ttotal: 14m 23s\tremaining: 3m\n",
      "1241:\tlearn: 0.8024247\ttotal: 14m 24s\tremaining: 2m 59s\n",
      "1242:\tlearn: 0.8024424\ttotal: 14m 25s\tremaining: 2m 58s\n",
      "1243:\tlearn: 0.8024424\ttotal: 14m 25s\tremaining: 2m 58s\n",
      "1244:\tlearn: 0.8024749\ttotal: 14m 26s\tremaining: 2m 57s\n",
      "1245:\tlearn: 0.8025014\ttotal: 14m 27s\tremaining: 2m 56s\n",
      "1246:\tlearn: 0.8025048\ttotal: 14m 27s\tremaining: 2m 56s\n",
      "1247:\tlearn: 0.8024973\ttotal: 14m 28s\tremaining: 2m 55s\n",
      "1248:\tlearn: 0.8024843\ttotal: 14m 29s\tremaining: 2m 54s\n",
      "1249:\tlearn: 0.8024987\ttotal: 14m 30s\tremaining: 2m 54s\n",
      "1250:\tlearn: 0.8025075\ttotal: 14m 30s\tremaining: 2m 53s\n",
      "1251:\tlearn: 0.8024394\ttotal: 14m 31s\tremaining: 2m 52s\n",
      "1252:\tlearn: 0.8024394\ttotal: 14m 31s\tremaining: 2m 51s\n",
      "1253:\tlearn: 0.8024488\ttotal: 14m 32s\tremaining: 2m 51s\n",
      "1254:\tlearn: 0.8025022\ttotal: 14m 33s\tremaining: 2m 50s\n",
      "1255:\tlearn: 0.8024956\ttotal: 14m 34s\tremaining: 2m 49s\n",
      "1256:\tlearn: 0.8024982\ttotal: 14m 34s\tremaining: 2m 49s\n",
      "1257:\tlearn: 0.8024983\ttotal: 14m 35s\tremaining: 2m 48s\n",
      "1258:\tlearn: 0.8025141\ttotal: 14m 36s\tremaining: 2m 47s\n",
      "1259:\tlearn: 0.8025141\ttotal: 14m 36s\tremaining: 2m 46s\n",
      "1260:\tlearn: 0.8025141\ttotal: 14m 37s\tremaining: 2m 46s\n",
      "1261:\tlearn: 0.8025470\ttotal: 14m 37s\tremaining: 2m 45s\n",
      "1262:\tlearn: 0.8025470\ttotal: 14m 38s\tremaining: 2m 44s\n",
      "1263:\tlearn: 0.8026299\ttotal: 14m 39s\tremaining: 2m 44s\n",
      "1264:\tlearn: 0.8026299\ttotal: 14m 39s\tremaining: 2m 43s\n",
      "1265:\tlearn: 0.8025935\ttotal: 14m 40s\tremaining: 2m 42s\n",
      "1266:\tlearn: 0.8026141\ttotal: 14m 41s\tremaining: 2m 42s\n",
      "1267:\tlearn: 0.8026470\ttotal: 14m 42s\tremaining: 2m 41s\n",
      "1268:\tlearn: 0.8026516\ttotal: 14m 42s\tremaining: 2m 40s\n",
      "1269:\tlearn: 0.8026789\ttotal: 14m 43s\tremaining: 2m 39s\n",
      "1270:\tlearn: 0.8026552\ttotal: 14m 44s\tremaining: 2m 39s\n",
      "1271:\tlearn: 0.8026552\ttotal: 14m 44s\tremaining: 2m 38s\n",
      "1272:\tlearn: 0.8026592\ttotal: 14m 45s\tremaining: 2m 37s\n",
      "1273:\tlearn: 0.8025748\ttotal: 14m 46s\tremaining: 2m 37s\n",
      "1274:\tlearn: 0.8025784\ttotal: 14m 46s\tremaining: 2m 36s\n",
      "1275:\tlearn: 0.8025976\ttotal: 14m 47s\tremaining: 2m 35s\n",
      "1276:\tlearn: 0.8025976\ttotal: 14m 48s\tremaining: 2m 35s\n",
      "1277:\tlearn: 0.8026276\ttotal: 14m 48s\tremaining: 2m 34s\n",
      "1278:\tlearn: 0.8026418\ttotal: 14m 49s\tremaining: 2m 33s\n",
      "1279:\tlearn: 0.8027021\ttotal: 14m 50s\tremaining: 2m 32s\n",
      "1280:\tlearn: 0.8026719\ttotal: 14m 50s\tremaining: 2m 32s\n",
      "1281:\tlearn: 0.8026926\ttotal: 14m 51s\tremaining: 2m 31s\n",
      "1282:\tlearn: 0.8026904\ttotal: 14m 52s\tremaining: 2m 30s\n",
      "1283:\tlearn: 0.8026904\ttotal: 14m 52s\tremaining: 2m 30s\n",
      "1284:\tlearn: 0.8027342\ttotal: 14m 53s\tremaining: 2m 29s\n",
      "1285:\tlearn: 0.8028047\ttotal: 14m 54s\tremaining: 2m 28s\n",
      "1286:\tlearn: 0.8028047\ttotal: 14m 54s\tremaining: 2m 28s\n",
      "1287:\tlearn: 0.8028194\ttotal: 14m 55s\tremaining: 2m 27s\n",
      "1288:\tlearn: 0.8028224\ttotal: 14m 56s\tremaining: 2m 26s\n",
      "1289:\tlearn: 0.8028224\ttotal: 14m 56s\tremaining: 2m 26s\n",
      "1290:\tlearn: 0.8028224\ttotal: 14m 57s\tremaining: 2m 25s\n",
      "1291:\tlearn: 0.8028530\ttotal: 14m 58s\tremaining: 2m 24s\n",
      "1292:\tlearn: 0.8029185\ttotal: 14m 58s\tremaining: 2m 23s\n",
      "1293:\tlearn: 0.8028451\ttotal: 14m 59s\tremaining: 2m 23s\n",
      "1294:\tlearn: 0.8029233\ttotal: 15m\tremaining: 2m 22s\n",
      "1295:\tlearn: 0.8028837\ttotal: 15m\tremaining: 2m 21s\n",
      "1296:\tlearn: 0.8029282\ttotal: 15m 1s\tremaining: 2m 21s\n",
      "1297:\tlearn: 0.8028926\ttotal: 15m 2s\tremaining: 2m 20s\n",
      "1298:\tlearn: 0.8028570\ttotal: 15m 3s\tremaining: 2m 19s\n",
      "1299:\tlearn: 0.8029009\ttotal: 15m 3s\tremaining: 2m 19s\n",
      "1300:\tlearn: 0.8030177\ttotal: 15m 4s\tremaining: 2m 18s\n",
      "1301:\tlearn: 0.8029030\ttotal: 15m 5s\tremaining: 2m 17s\n",
      "1302:\tlearn: 0.8029098\ttotal: 15m 5s\tremaining: 2m 16s\n",
      "1303:\tlearn: 0.8029804\ttotal: 15m 6s\tremaining: 2m 16s\n",
      "1304:\tlearn: 0.8029940\ttotal: 15m 7s\tremaining: 2m 15s\n",
      "1305:\tlearn: 0.8029808\ttotal: 15m 7s\tremaining: 2m 14s\n",
      "1306:\tlearn: 0.8029915\ttotal: 15m 8s\tremaining: 2m 14s\n",
      "1307:\tlearn: 0.8029949\ttotal: 15m 9s\tremaining: 2m 13s\n",
      "1308:\tlearn: 0.8030046\ttotal: 15m 9s\tremaining: 2m 12s\n",
      "1309:\tlearn: 0.8030075\ttotal: 15m 10s\tremaining: 2m 12s\n",
      "1310:\tlearn: 0.8030075\ttotal: 15m 11s\tremaining: 2m 11s\n",
      "1311:\tlearn: 0.8030123\ttotal: 15m 11s\tremaining: 2m 10s\n",
      "1312:\tlearn: 0.8030331\ttotal: 15m 12s\tremaining: 2m 9s\n",
      "1313:\tlearn: 0.8030331\ttotal: 15m 13s\tremaining: 2m 9s\n",
      "1314:\tlearn: 0.8030416\ttotal: 15m 13s\tremaining: 2m 8s\n",
      "1315:\tlearn: 0.8030335\ttotal: 15m 14s\tremaining: 2m 7s\n",
      "1316:\tlearn: 0.8030877\ttotal: 15m 15s\tremaining: 2m 7s\n",
      "1317:\tlearn: 0.8030876\ttotal: 15m 15s\tremaining: 2m 6s\n",
      "1318:\tlearn: 0.8030971\ttotal: 15m 16s\tremaining: 2m 5s\n",
      "1319:\tlearn: 0.8031138\ttotal: 15m 17s\tremaining: 2m 5s\n",
      "1320:\tlearn: 0.8032159\ttotal: 15m 17s\tremaining: 2m 4s\n",
      "1321:\tlearn: 0.8032312\ttotal: 15m 18s\tremaining: 2m 3s\n",
      "1322:\tlearn: 0.8032333\ttotal: 15m 19s\tremaining: 2m 2s\n",
      "1323:\tlearn: 0.8032333\ttotal: 15m 19s\tremaining: 2m 2s\n",
      "1324:\tlearn: 0.8032361\ttotal: 15m 20s\tremaining: 2m 1s\n",
      "1325:\tlearn: 0.8032617\ttotal: 15m 21s\tremaining: 2m\n",
      "1326:\tlearn: 0.8033156\ttotal: 15m 21s\tremaining: 2m\n",
      "1327:\tlearn: 0.8033156\ttotal: 15m 22s\tremaining: 1m 59s\n",
      "1328:\tlearn: 0.8033898\ttotal: 15m 23s\tremaining: 1m 58s\n",
      "1329:\tlearn: 0.8033816\ttotal: 15m 23s\tremaining: 1m 58s\n",
      "1330:\tlearn: 0.8033816\ttotal: 15m 24s\tremaining: 1m 57s\n",
      "1331:\tlearn: 0.8034018\ttotal: 15m 25s\tremaining: 1m 56s\n",
      "1332:\tlearn: 0.8033888\ttotal: 15m 25s\tremaining: 1m 56s\n",
      "1333:\tlearn: 0.8033254\ttotal: 15m 26s\tremaining: 1m 55s\n",
      "1334:\tlearn: 0.8033409\ttotal: 15m 27s\tremaining: 1m 54s\n",
      "1335:\tlearn: 0.8032781\ttotal: 15m 28s\tremaining: 1m 53s\n",
      "1336:\tlearn: 0.8033218\ttotal: 15m 28s\tremaining: 1m 53s\n",
      "1337:\tlearn: 0.8033219\ttotal: 15m 29s\tremaining: 1m 52s\n",
      "1338:\tlearn: 0.8033310\ttotal: 15m 30s\tremaining: 1m 51s\n",
      "1339:\tlearn: 0.8033310\ttotal: 15m 30s\tremaining: 1m 51s\n",
      "1340:\tlearn: 0.8033310\ttotal: 15m 31s\tremaining: 1m 50s\n",
      "1341:\tlearn: 0.8033331\ttotal: 15m 32s\tremaining: 1m 49s\n",
      "1342:\tlearn: 0.8033331\ttotal: 15m 32s\tremaining: 1m 49s\n",
      "1343:\tlearn: 0.8033246\ttotal: 15m 33s\tremaining: 1m 48s\n",
      "1344:\tlearn: 0.8033248\ttotal: 15m 34s\tremaining: 1m 47s\n",
      "1345:\tlearn: 0.8033248\ttotal: 15m 34s\tremaining: 1m 46s\n",
      "1346:\tlearn: 0.8033684\ttotal: 15m 35s\tremaining: 1m 46s\n",
      "1347:\tlearn: 0.8033330\ttotal: 15m 36s\tremaining: 1m 45s\n",
      "1348:\tlearn: 0.8033370\ttotal: 15m 36s\tremaining: 1m 44s\n",
      "1349:\tlearn: 0.8033621\ttotal: 15m 37s\tremaining: 1m 44s\n",
      "1350:\tlearn: 0.8034336\ttotal: 15m 38s\tremaining: 1m 43s\n",
      "1351:\tlearn: 0.8034594\ttotal: 15m 38s\tremaining: 1m 42s\n",
      "1352:\tlearn: 0.8034450\ttotal: 15m 39s\tremaining: 1m 42s\n",
      "1353:\tlearn: 0.8034560\ttotal: 15m 40s\tremaining: 1m 41s\n",
      "1354:\tlearn: 0.8034044\ttotal: 15m 40s\tremaining: 1m 40s\n",
      "1355:\tlearn: 0.8034044\ttotal: 15m 41s\tremaining: 1m 39s\n",
      "1356:\tlearn: 0.8034044\ttotal: 15m 42s\tremaining: 1m 39s\n",
      "1357:\tlearn: 0.8034031\ttotal: 15m 42s\tremaining: 1m 38s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1358:\tlearn: 0.8034524\ttotal: 15m 43s\tremaining: 1m 37s\n",
      "1359:\tlearn: 0.8035009\ttotal: 15m 44s\tremaining: 1m 37s\n",
      "1360:\tlearn: 0.8035437\ttotal: 15m 44s\tremaining: 1m 36s\n",
      "1361:\tlearn: 0.8036100\ttotal: 15m 45s\tremaining: 1m 35s\n",
      "1362:\tlearn: 0.8036426\ttotal: 15m 46s\tremaining: 1m 35s\n",
      "1363:\tlearn: 0.8036426\ttotal: 15m 46s\tremaining: 1m 34s\n",
      "1364:\tlearn: 0.8036426\ttotal: 15m 47s\tremaining: 1m 33s\n",
      "1365:\tlearn: 0.8036517\ttotal: 15m 48s\tremaining: 1m 33s\n",
      "1366:\tlearn: 0.8037246\ttotal: 15m 48s\tremaining: 1m 32s\n",
      "1367:\tlearn: 0.8037165\ttotal: 15m 49s\tremaining: 1m 31s\n",
      "1368:\tlearn: 0.8037425\ttotal: 15m 50s\tremaining: 1m 30s\n",
      "1369:\tlearn: 0.8037448\ttotal: 15m 50s\tremaining: 1m 30s\n",
      "1370:\tlearn: 0.8037596\ttotal: 15m 51s\tremaining: 1m 29s\n",
      "1371:\tlearn: 0.8038252\ttotal: 15m 52s\tremaining: 1m 28s\n",
      "1372:\tlearn: 0.8037783\ttotal: 15m 52s\tremaining: 1m 28s\n",
      "1373:\tlearn: 0.8037783\ttotal: 15m 53s\tremaining: 1m 27s\n",
      "1374:\tlearn: 0.8037990\ttotal: 15m 54s\tremaining: 1m 26s\n",
      "1375:\tlearn: 0.8037971\ttotal: 15m 54s\tremaining: 1m 26s\n",
      "1376:\tlearn: 0.8038249\ttotal: 15m 55s\tremaining: 1m 25s\n",
      "1377:\tlearn: 0.8037960\ttotal: 15m 56s\tremaining: 1m 24s\n",
      "1378:\tlearn: 0.8038066\ttotal: 15m 57s\tremaining: 1m 23s\n",
      "1379:\tlearn: 0.8038066\ttotal: 15m 57s\tremaining: 1m 23s\n",
      "1380:\tlearn: 0.8038066\ttotal: 15m 58s\tremaining: 1m 22s\n",
      "1381:\tlearn: 0.8038384\ttotal: 15m 59s\tremaining: 1m 21s\n",
      "1382:\tlearn: 0.8038370\ttotal: 15m 59s\tremaining: 1m 21s\n",
      "1383:\tlearn: 0.8038362\ttotal: 16m\tremaining: 1m 20s\n",
      "1384:\tlearn: 0.8038177\ttotal: 16m 1s\tremaining: 1m 19s\n",
      "1385:\tlearn: 0.8039006\ttotal: 16m 1s\tremaining: 1m 19s\n",
      "1386:\tlearn: 0.8038875\ttotal: 16m 2s\tremaining: 1m 18s\n",
      "1387:\tlearn: 0.8038792\ttotal: 16m 3s\tremaining: 1m 17s\n",
      "1388:\tlearn: 0.8038609\ttotal: 16m 3s\tremaining: 1m 17s\n",
      "1389:\tlearn: 0.8038922\ttotal: 16m 4s\tremaining: 1m 16s\n",
      "1390:\tlearn: 0.8038922\ttotal: 16m 5s\tremaining: 1m 15s\n",
      "1391:\tlearn: 0.8039007\ttotal: 16m 5s\tremaining: 1m 14s\n",
      "1392:\tlearn: 0.8038709\ttotal: 16m 6s\tremaining: 1m 14s\n",
      "1393:\tlearn: 0.8039124\ttotal: 16m 7s\tremaining: 1m 13s\n",
      "1394:\tlearn: 0.8039276\ttotal: 16m 7s\tremaining: 1m 12s\n",
      "1395:\tlearn: 0.8039717\ttotal: 16m 8s\tremaining: 1m 12s\n",
      "1396:\tlearn: 0.8039877\ttotal: 16m 9s\tremaining: 1m 11s\n",
      "1397:\tlearn: 0.8039888\ttotal: 16m 10s\tremaining: 1m 10s\n",
      "1398:\tlearn: 0.8039926\ttotal: 16m 10s\tremaining: 1m 10s\n",
      "1399:\tlearn: 0.8039926\ttotal: 16m 11s\tremaining: 1m 9s\n",
      "1400:\tlearn: 0.8039733\ttotal: 16m 12s\tremaining: 1m 8s\n",
      "1401:\tlearn: 0.8039733\ttotal: 16m 12s\tremaining: 1m 7s\n",
      "1402:\tlearn: 0.8039708\ttotal: 16m 13s\tremaining: 1m 7s\n",
      "1403:\tlearn: 0.8040774\ttotal: 16m 14s\tremaining: 1m 6s\n",
      "1404:\tlearn: 0.8040431\ttotal: 16m 14s\tremaining: 1m 5s\n",
      "1405:\tlearn: 0.8040354\ttotal: 16m 15s\tremaining: 1m 5s\n",
      "1406:\tlearn: 0.8040354\ttotal: 16m 16s\tremaining: 1m 4s\n",
      "1407:\tlearn: 0.8040796\ttotal: 16m 16s\tremaining: 1m 3s\n",
      "1408:\tlearn: 0.8040796\ttotal: 16m 17s\tremaining: 1m 3s\n",
      "1409:\tlearn: 0.8041515\ttotal: 16m 18s\tremaining: 1m 2s\n",
      "1410:\tlearn: 0.8041535\ttotal: 16m 18s\tremaining: 1m 1s\n",
      "1411:\tlearn: 0.8041469\ttotal: 16m 19s\tremaining: 1m 1s\n",
      "1412:\tlearn: 0.8041574\ttotal: 16m 20s\tremaining: 1m\n",
      "1413:\tlearn: 0.8041389\ttotal: 16m 20s\tremaining: 59.7s\n",
      "1414:\tlearn: 0.8041939\ttotal: 16m 21s\tremaining: 59s\n",
      "1415:\tlearn: 0.8041533\ttotal: 16m 22s\tremaining: 58.3s\n",
      "1416:\tlearn: 0.8042154\ttotal: 16m 22s\tremaining: 57.6s\n",
      "1417:\tlearn: 0.8042073\ttotal: 16m 23s\tremaining: 56.9s\n",
      "1418:\tlearn: 0.8042073\ttotal: 16m 24s\tremaining: 56.2s\n",
      "1419:\tlearn: 0.8042181\ttotal: 16m 24s\tremaining: 55.5s\n",
      "1420:\tlearn: 0.8042101\ttotal: 16m 25s\tremaining: 54.8s\n",
      "1421:\tlearn: 0.8042408\ttotal: 16m 26s\tremaining: 54.1s\n",
      "1422:\tlearn: 0.8042494\ttotal: 16m 26s\tremaining: 53.4s\n",
      "1423:\tlearn: 0.8042494\ttotal: 16m 27s\tremaining: 52.7s\n",
      "1424:\tlearn: 0.8042494\ttotal: 16m 28s\tremaining: 52s\n",
      "1425:\tlearn: 0.8042494\ttotal: 16m 28s\tremaining: 51.3s\n",
      "1426:\tlearn: 0.8042494\ttotal: 16m 29s\tremaining: 50.6s\n",
      "1427:\tlearn: 0.8042494\ttotal: 16m 30s\tremaining: 49.9s\n",
      "1428:\tlearn: 0.8043452\ttotal: 16m 30s\tremaining: 49.2s\n",
      "1429:\tlearn: 0.8043720\ttotal: 16m 31s\tremaining: 48.5s\n",
      "1430:\tlearn: 0.8044203\ttotal: 16m 32s\tremaining: 47.8s\n",
      "1431:\tlearn: 0.8044147\ttotal: 16m 32s\tremaining: 47.1s\n",
      "1432:\tlearn: 0.8044147\ttotal: 16m 33s\tremaining: 46.4s\n",
      "1433:\tlearn: 0.8044795\ttotal: 16m 34s\tremaining: 45.8s\n",
      "1434:\tlearn: 0.8044795\ttotal: 16m 34s\tremaining: 45.1s\n",
      "1435:\tlearn: 0.8044782\ttotal: 16m 35s\tremaining: 44.4s\n",
      "1436:\tlearn: 0.8044220\ttotal: 16m 36s\tremaining: 43.7s\n",
      "1437:\tlearn: 0.8044220\ttotal: 16m 36s\tremaining: 43s\n",
      "1438:\tlearn: 0.8044492\ttotal: 16m 37s\tremaining: 42.3s\n",
      "1439:\tlearn: 0.8044492\ttotal: 16m 37s\tremaining: 41.6s\n",
      "1440:\tlearn: 0.8044492\ttotal: 16m 38s\tremaining: 40.9s\n",
      "1441:\tlearn: 0.8044492\ttotal: 16m 39s\tremaining: 40.2s\n",
      "1442:\tlearn: 0.8044700\ttotal: 16m 39s\tremaining: 39.5s\n",
      "1443:\tlearn: 0.8044700\ttotal: 16m 40s\tremaining: 38.8s\n",
      "1444:\tlearn: 0.8044216\ttotal: 16m 41s\tremaining: 38.1s\n",
      "1445:\tlearn: 0.8044537\ttotal: 16m 41s\tremaining: 37.4s\n",
      "1446:\tlearn: 0.8044561\ttotal: 16m 42s\tremaining: 36.7s\n",
      "1447:\tlearn: 0.8045186\ttotal: 16m 43s\tremaining: 36s\n",
      "1448:\tlearn: 0.8045346\ttotal: 16m 44s\tremaining: 35.3s\n",
      "1449:\tlearn: 0.8045346\ttotal: 16m 44s\tremaining: 34.6s\n",
      "1450:\tlearn: 0.8045510\ttotal: 16m 45s\tremaining: 33.9s\n",
      "1451:\tlearn: 0.8045510\ttotal: 16m 45s\tremaining: 33.3s\n",
      "1452:\tlearn: 0.8045770\ttotal: 16m 46s\tremaining: 32.6s\n",
      "1453:\tlearn: 0.8045770\ttotal: 16m 47s\tremaining: 31.9s\n",
      "1454:\tlearn: 0.8045859\ttotal: 16m 47s\tremaining: 31.2s\n",
      "1455:\tlearn: 0.8045708\ttotal: 16m 48s\tremaining: 30.5s\n",
      "1456:\tlearn: 0.8045739\ttotal: 16m 49s\tremaining: 29.8s\n",
      "1457:\tlearn: 0.8045739\ttotal: 16m 49s\tremaining: 29.1s\n",
      "1458:\tlearn: 0.8045835\ttotal: 16m 50s\tremaining: 28.4s\n",
      "1459:\tlearn: 0.8045835\ttotal: 16m 51s\tremaining: 27.7s\n",
      "1460:\tlearn: 0.8046034\ttotal: 16m 51s\tremaining: 27s\n",
      "1461:\tlearn: 0.8045686\ttotal: 16m 52s\tremaining: 26.3s\n",
      "1462:\tlearn: 0.8045957\ttotal: 16m 53s\tremaining: 25.6s\n",
      "1463:\tlearn: 0.8046043\ttotal: 16m 54s\tremaining: 24.9s\n",
      "1464:\tlearn: 0.8046043\ttotal: 16m 54s\tremaining: 24.2s\n",
      "1465:\tlearn: 0.8045959\ttotal: 16m 55s\tremaining: 23.5s\n",
      "1466:\tlearn: 0.8046444\ttotal: 16m 56s\tremaining: 22.9s\n",
      "1467:\tlearn: 0.8046985\ttotal: 16m 56s\tremaining: 22.2s\n",
      "1468:\tlearn: 0.8047233\ttotal: 16m 57s\tremaining: 21.5s\n",
      "1469:\tlearn: 0.8047101\ttotal: 16m 58s\tremaining: 20.8s\n",
      "1470:\tlearn: 0.8046867\ttotal: 16m 58s\tremaining: 20.1s\n",
      "1471:\tlearn: 0.8047253\ttotal: 16m 59s\tremaining: 19.4s\n",
      "1472:\tlearn: 0.8046951\ttotal: 17m\tremaining: 18.7s\n",
      "1473:\tlearn: 0.8047157\ttotal: 17m\tremaining: 18s\n",
      "1474:\tlearn: 0.8047214\ttotal: 17m 1s\tremaining: 17.3s\n",
      "1475:\tlearn: 0.8046474\ttotal: 17m 2s\tremaining: 16.6s\n",
      "1476:\tlearn: 0.8046474\ttotal: 17m 2s\tremaining: 15.9s\n",
      "1477:\tlearn: 0.8047569\ttotal: 17m 3s\tremaining: 15.2s\n",
      "1478:\tlearn: 0.8047342\ttotal: 17m 4s\tremaining: 14.5s\n",
      "1479:\tlearn: 0.8047038\ttotal: 17m 4s\tremaining: 13.8s\n",
      "1480:\tlearn: 0.8047637\ttotal: 17m 5s\tremaining: 13.2s\n",
      "1481:\tlearn: 0.8047600\ttotal: 17m 6s\tremaining: 12.5s\n",
      "1482:\tlearn: 0.8047665\ttotal: 17m 6s\tremaining: 11.8s\n",
      "1483:\tlearn: 0.8047665\ttotal: 17m 7s\tremaining: 11.1s\n",
      "1484:\tlearn: 0.8047665\ttotal: 17m 8s\tremaining: 10.4s\n",
      "1485:\tlearn: 0.8047761\ttotal: 17m 8s\tremaining: 9.69s\n",
      "1486:\tlearn: 0.8047761\ttotal: 17m 9s\tremaining: 9s\n",
      "1487:\tlearn: 0.8047724\ttotal: 17m 10s\tremaining: 8.31s\n",
      "1488:\tlearn: 0.8047645\ttotal: 17m 10s\tremaining: 7.62s\n",
      "1489:\tlearn: 0.8047390\ttotal: 17m 11s\tremaining: 6.92s\n",
      "1490:\tlearn: 0.8047212\ttotal: 17m 12s\tremaining: 6.23s\n",
      "1491:\tlearn: 0.8047152\ttotal: 17m 12s\tremaining: 5.54s\n",
      "1492:\tlearn: 0.8047152\ttotal: 17m 13s\tremaining: 4.84s\n",
      "1493:\tlearn: 0.8047087\ttotal: 17m 14s\tremaining: 4.15s\n",
      "1494:\tlearn: 0.8047926\ttotal: 17m 14s\tremaining: 3.46s\n",
      "1495:\tlearn: 0.8047903\ttotal: 17m 15s\tremaining: 2.77s\n",
      "1496:\tlearn: 0.8048184\ttotal: 17m 16s\tremaining: 2.08s\n",
      "1497:\tlearn: 0.8048777\ttotal: 17m 16s\tremaining: 1.38s\n",
      "1498:\tlearn: 0.8048777\ttotal: 17m 17s\tremaining: 692ms\n",
      "1499:\tlearn: 0.8048907\ttotal: 17m 18s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x2651de32520>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(**cat_params, cat_features=cat_feat)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1a2b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X['cat_01'] = np.concatenate(pred_score_val)[:, 1]\n",
    "meta_X_test['cat_01'] = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'cat_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "92f5aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.815\n",
      "f1 test: 0.807\n",
      "roc-auc train: 0.965\n",
      "roc-auc test: 0.961\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(cat_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d143a2",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f0aee97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 1 amex 0.784\n",
      "---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 2 amex 0.776\n",
      "---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 3 amex 0.785\n",
      "---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 4 amex 0.786\n",
      "---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold: 5 amex 0.789\n",
      "---\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.858659446060356, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.858659446060356\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    }
   ],
   "source": [
    "pred_val = []\n",
    "pred_score_val = []\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_FOLDS)\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "    X_train_, X_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "    y_train_, y_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "    model = LGBMClassifier(**lg_params, n_jobs=-1)\n",
    "    model.fit(X_train_,\n",
    "              y_train_,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric=custom_lg_amex_metric,\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_score_val = model.predict_proba(X_val)\n",
    "\n",
    "    print(\"Fold:\", fold + 1,\n",
    "          \"amex %.3f\" % amex_metric(y_val.values, y_score_val[:, 1]))\n",
    "    print(\"---\")\n",
    "\n",
    "    # holdout list\n",
    "    pred_val.append(y_pred_val)\n",
    "    pred_score_val.append(y_score_val)\n",
    "\n",
    "model = LGBMClassifier(**lg_params, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "meta_X['lgb_01'] = np.concatenate(pred_score_val)[:, 1]\n",
    "meta_X_test['lgb_01'] = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'lgb_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0defa6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.808\n",
      "f1 test: 0.805\n",
      "roc-auc train: 0.962\n",
      "roc-auc test: 0.960\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(lgb_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064762ef",
   "metadata": {},
   "source": [
    "#### Final model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9221ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_01</th>\n",
       "      <th>lgb_01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938353</td>\n",
       "      <td>0.019090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012066</td>\n",
       "      <td>0.889008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.015307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034886</td>\n",
       "      <td>0.005202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075366</td>\n",
       "      <td>0.997805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344179</th>\n",
       "      <td>0.025993</td>\n",
       "      <td>0.201998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344180</th>\n",
       "      <td>0.632716</td>\n",
       "      <td>0.040039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344181</th>\n",
       "      <td>0.991914</td>\n",
       "      <td>0.856492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344182</th>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344183</th>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.005272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344184 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat_01    lgb_01\n",
       "0       0.938353  0.019090\n",
       "1       0.012066  0.889008\n",
       "2       0.002914  0.015307\n",
       "3       0.034886  0.005202\n",
       "4       0.075366  0.997805\n",
       "...          ...       ...\n",
       "344179  0.025993  0.201998\n",
       "344180  0.632716  0.040039\n",
       "344181  0.991914  0.856492\n",
       "344182  0.001866  0.003952\n",
       "344183  0.003982  0.005272\n",
       "\n",
       "[344184 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5f27b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=10)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_clf = LogisticRegression(random_state=RAND)\n",
    "final_clf.fit(meta_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c5f96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model_1.sav'\n",
    "pickle.dump(final_clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "deb6e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = final_clf.predict(meta_X_test)\n",
    "y_proba_final = final_clf.predict_proba(meta_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3572961",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = metrics.append(\n",
    "    get_metrics(y_test.values,\n",
    "                y_pred_final,\n",
    "                y_proba_final,\n",
    "                name='StackingClassifier_hand_tune'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acd01d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Logloss</th>\n",
       "      <th>amex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression_Baseline</td>\n",
       "      <td>0.883787</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.722824</td>\n",
       "      <td>0.893998</td>\n",
       "      <td>0.799350</td>\n",
       "      <td>0.282031</td>\n",
       "      <td>0.764476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest_Baseline</td>\n",
       "      <td>0.892451</td>\n",
       "      <td>0.953522</td>\n",
       "      <td>0.816657</td>\n",
       "      <td>0.753896</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.264326</td>\n",
       "      <td>0.757461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_Baseline</td>\n",
       "      <td>0.884022</td>\n",
       "      <td>0.957920</td>\n",
       "      <td>0.717815</td>\n",
       "      <td>0.909718</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.260512</td>\n",
       "      <td>0.776851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM_Baseline</td>\n",
       "      <td>0.881181</td>\n",
       "      <td>0.959101</td>\n",
       "      <td>0.708026</td>\n",
       "      <td>0.920860</td>\n",
       "      <td>0.800538</td>\n",
       "      <td>0.261274</td>\n",
       "      <td>0.783520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_Baseline</td>\n",
       "      <td>0.887884</td>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.725380</td>\n",
       "      <td>0.912445</td>\n",
       "      <td>0.808230</td>\n",
       "      <td>0.253600</td>\n",
       "      <td>0.784212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_Optuna</td>\n",
       "      <td>0.884388</td>\n",
       "      <td>0.960060</td>\n",
       "      <td>0.714857</td>\n",
       "      <td>0.920793</td>\n",
       "      <td>0.804861</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>0.786262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBM_Optuna</td>\n",
       "      <td>0.883953</td>\n",
       "      <td>0.959533</td>\n",
       "      <td>0.714821</td>\n",
       "      <td>0.918100</td>\n",
       "      <td>0.803808</td>\n",
       "      <td>0.258686</td>\n",
       "      <td>0.783749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>StackingClassifier_hand_tune</td>\n",
       "      <td>0.900531</td>\n",
       "      <td>0.959923</td>\n",
       "      <td>0.785815</td>\n",
       "      <td>0.846602</td>\n",
       "      <td>0.815076</td>\n",
       "      <td>0.233997</td>\n",
       "      <td>0.784980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  Accuracy   ROC_AUC  Precision    Recall  \\\n",
       "0   LogisticRegression_Baseline  0.883787  0.954230   0.722824  0.893998   \n",
       "1         RandomForest_Baseline  0.892451  0.953522   0.816657  0.753896   \n",
       "2              XGBoost_Baseline  0.884022  0.957920   0.717815  0.909718   \n",
       "3                 LGBM_Baseline  0.881181  0.959101   0.708026  0.920860   \n",
       "4             CatBoost_Baseline  0.887884  0.959946   0.725380  0.912445   \n",
       "5               CatBoost_Optuna  0.884388  0.960060   0.714857  0.920793   \n",
       "6                   LGBM_Optuna  0.883953  0.959533   0.714821  0.918100   \n",
       "0  StackingClassifier_hand_tune  0.900531  0.959923   0.785815  0.846602   \n",
       "\n",
       "         f1   Logloss      amex  \n",
       "0  0.799350  0.282031  0.764476  \n",
       "1  0.784023  0.264326  0.757461  \n",
       "2  0.802453  0.260512  0.776851  \n",
       "3  0.800538  0.261274  0.783520  \n",
       "4  0.808230  0.253600  0.784212  \n",
       "5  0.804861  0.258429  0.786262  \n",
       "6  0.803808  0.258686  0.783749  \n",
       "0  0.815076  0.233997  0.784980  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef0a9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 train: 0.808\n",
      "f1 test: 0.815\n",
      "roc-auc train: 0.957\n",
      "roc-auc test: 0.960\n"
     ]
    }
   ],
   "source": [
    "check_overfitting(final_clf, meta_X, y_train, meta_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e9e7e",
   "metadata": {},
   "source": [
    "Стекинг моделей дал лишь небольшее улучшение метрики соревнования по сравнению с бейзлайном, но показал лучший результат по logloss, f1. \n",
    "\n",
    "По метрике соревнования лидирует CatBoost с подобранными параметрами."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
